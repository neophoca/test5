{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0c9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load libs from root\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ab2ca-dba2-4007-a0e8-9d9cb9f3606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: setuptools in /home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages (60.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f2ded20>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/setuptools/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f2df0e0>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/setuptools/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f2df380>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/setuptools/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f2df5c0>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/setuptools/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f2df800>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/setuptools/\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages (0.45.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f3ac350>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/wheel/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f3ac5f0>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/wheel/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f3ac860>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/wheel/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f3acad0>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/wheel/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f679f3acd40>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/wheel/\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 60.2.0\n",
      "    Uninstalling setuptools-60.2.0:\n",
      "      Successfully uninstalled setuptools-60.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openxlab 0.1.3 requires setuptools~=60.2.0, but you have setuptools 80.9.0 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.3 which is incompatible.\n",
      "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.27.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed setuptools-80.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"setuptools\", \"wheel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a78a46",
   "metadata": {},
   "source": [
    "# Train basic Mask R-CNN \n",
    "\n",
    "Trains **one baseline model** (Mask R-CNN + R50-FPN, ImageNet backbone) on **Dataset B (instance masks)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eada100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import cfg\n",
    "from datasets.loader import DataModule, DataConfig\n",
    "from models.models import build_model\n",
    "from train.trainer_v2 import Trainer, TrainConfig\n",
    "from train.eval import Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a717e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "num_classes: 25\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_NAME = \"maskrcnn_r50_fpn\"\n",
    "NUM_CLASSES = int(cfg.num_classes)   # 1 + 24\n",
    "\n",
    "TRACKING_URI = \"file:///media/sdb1/mlflow\"\n",
    "EXPERIMENT = \"B_basic_\"\n",
    "\n",
    "WEIGHTS_DIR = Path(\"../weights\")\n",
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"device:\", DEVICE)\n",
    "print(\"num_classes:\", NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c906055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B train: 475 | B val: 52 | B test: 67\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(DataConfig(val_frac=0.1,batch_size=4,num_workers=4,))\n",
    "b_train, b_val = dm.make_loaders_b()\n",
    "b_test = dm.make_loader_b_test()\n",
    "\n",
    "print(\"B train:\", len(dm.ds_b_train), \"| B val:\", len(dm.ds_b_val), \"| B test:\", len(dm.ds_b_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6db98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_model():\n",
    "    return build_model2(MODEL_NAME,NUM_CLASSES, \n",
    "                        weights_backbone=True, #imagenet pretrain\n",
    "                        trainable_backbone_layers=3, \n",
    "    ).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3e7214-ecbe-4ff3-8856-5625df84696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, json, tempfile, os\n",
    "import torch, mlflow\n",
    "\n",
    "def _as_scalar(x):\n",
    "    if isinstance(x, (float, int)): return float(x)\n",
    "    if torch.is_tensor(x): x = x.detach().cpu().numpy()\n",
    "    if isinstance(x, np.ndarray):\n",
    "        if x.size == 1: return float(x.reshape(-1)[0])\n",
    "        return None\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        if len(x) == 1 and isinstance(x[0], (float, int)): return float(x[0])\n",
    "        return None\n",
    "    try: return float(x)\n",
    "    except Exception: return None\n",
    "\n",
    "def mlflow_log_metrics_safe(d, prefix=\"\", step=None, log_arrays_as_artifact=True):\n",
    "    scalars, arrays = {}, {}\n",
    "    for k, v in d.items():\n",
    "        s = _as_scalar(v)\n",
    "        if s is not None: scalars[f\"{prefix}{k}\"] = s\n",
    "        else:\n",
    "            if torch.is_tensor(v): vv = v.detach().cpu().tolist()\n",
    "            elif hasattr(v, \"tolist\"): vv = v.tolist()\n",
    "            else: vv = v\n",
    "            arrays[k] = vv\n",
    "            if isinstance(vv, list) and len(vv) and all(isinstance(t, (int, float)) for t in vv):\n",
    "                scalars[f\"{prefix}{k}_mean\"] = float(np.mean(vv))\n",
    "                scalars[f\"{prefix}{k}_p50\"] = float(np.median(vv))\n",
    "    if scalars: mlflow.log_metrics(scalars, step=step)\n",
    "    if arrays and log_arrays_as_artifact:\n",
    "        if hasattr(mlflow, \"log_dict\"): mlflow.log_dict(arrays, \"metrics_arrays.json\")\n",
    "        else:\n",
    "            fd, path = tempfile.mkstemp(suffix=\".json\"); os.close(fd)\n",
    "            with open(path, \"w\") as f: json.dump(arrays, f)\n",
    "            mlflow.log_artifact(path); os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480a06b4-507a-4564-8afa-6b4bbee13ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:177: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "[I 2025-12-25 15:37:49,613] A new study created in memory with name: no-name-fcb7d3e2-f113-4b5d-aa75-86ac49694f30\n",
      "/home/neoph/dev/Train/Jupyter/KaryoTest/train/trainer_v2.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=bool(train_conf.amp and self.device.type == \"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 2.3721\n",
      "[epoch 001/010] step 100/119 loss 1.7528\n",
      "[epoch 001/010] step 119/119 loss 1.7653\n",
      "[epoch 002/010] step 50/119 loss 1.3551\n",
      "[epoch 002/010] step 100/119 loss 1.2925\n",
      "[epoch 002/010] step 119/119 loss 1.4147\n",
      "[epoch 003/010] step 50/119 loss 1.4519\n",
      "[epoch 003/010] step 100/119 loss 1.2412\n",
      "[epoch 003/010] step 119/119 loss 1.3432\n",
      "[epoch 004/010] step 50/119 loss 1.1074\n",
      "[epoch 004/010] step 100/119 loss 1.1730\n",
      "[epoch 004/010] step 119/119 loss 1.0041\n",
      "[epoch 005/010] step 50/119 loss 1.0520\n",
      "[epoch 005/010] step 100/119 loss 1.0774\n",
      "[epoch 005/010] step 119/119 loss 1.1593\n",
      "[epoch 006/010] step 50/119 loss 0.9516\n",
      "[epoch 006/010] step 100/119 loss 1.1604\n",
      "[epoch 006/010] step 119/119 loss 0.9429\n",
      "[epoch 007/010] step 50/119 loss 0.9839\n",
      "[epoch 007/010] step 100/119 loss 1.0365\n",
      "[epoch 007/010] step 119/119 loss 1.0394\n",
      "[epoch 008/010] step 50/119 loss 0.9611\n",
      "[epoch 008/010] step 100/119 loss 0.9923\n",
      "[epoch 008/010] step 119/119 loss 1.0653\n",
      "[epoch 009/010] step 50/119 loss 0.7998\n",
      "[epoch 009/010] step 100/119 loss 0.8839\n",
      "[epoch 009/010] step 119/119 loss 0.9127\n",
      "[epoch 010/010] step 50/119 loss 0.8988\n",
      "[epoch 010/010] step 100/119 loss 0.7569\n",
      "[epoch 010/010] step 119/119 loss 0.8683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 15:46:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 15:46:56,216] Trial 0 finished with value: 0.3826360001053386 and parameters: {'optimizer': 'adamw', 'lr': 0.0007441632389160641, 'weight_decay': 6.251373574521755e-05, 'scheduler': 'none'}. Best is trial 0 with value: 0.3826360001053386.\n",
      "/home/neoph/dev/Train/Jupyter/KaryoTest/train/trainer_v2.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=bool(train_conf.amp and self.device.type == \"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.5905\n",
      "[epoch 001/010] step 100/119 loss 1.3825\n",
      "[epoch 001/010] step 119/119 loss 1.3198\n",
      "[epoch 002/010] step 50/119 loss 1.1596\n",
      "[epoch 002/010] step 100/119 loss 1.1180\n",
      "[epoch 002/010] step 119/119 loss 0.9739\n",
      "[epoch 003/010] step 50/119 loss 1.2946\n",
      "[epoch 003/010] step 100/119 loss 1.1327\n",
      "[epoch 003/010] step 119/119 loss 1.1002\n",
      "[epoch 004/010] step 50/119 loss 1.0851\n",
      "[epoch 004/010] step 100/119 loss 0.8740\n",
      "[epoch 004/010] step 119/119 loss 1.0095\n",
      "[epoch 005/010] step 50/119 loss 0.8741\n",
      "[epoch 005/010] step 100/119 loss 1.0486\n",
      "[epoch 005/010] step 119/119 loss 1.0549\n",
      "[epoch 006/010] step 50/119 loss 1.1199\n",
      "[epoch 006/010] step 100/119 loss 0.8156\n",
      "[epoch 006/010] step 119/119 loss 0.9949\n",
      "[epoch 007/010] step 50/119 loss 0.8328\n",
      "[epoch 007/010] step 100/119 loss 0.7793\n",
      "[epoch 007/010] step 119/119 loss 0.6326\n",
      "[epoch 008/010] step 50/119 loss 0.6064\n",
      "[epoch 008/010] step 100/119 loss 0.8620\n",
      "[epoch 008/010] step 119/119 loss 0.5600\n",
      "[epoch 009/010] step 50/119 loss 0.5927\n",
      "[epoch 009/010] step 100/119 loss 0.6291\n",
      "[epoch 009/010] step 119/119 loss 0.7347\n",
      "[epoch 010/010] step 50/119 loss 0.7874\n",
      "[epoch 010/010] step 100/119 loss 0.6567\n",
      "[epoch 010/010] step 119/119 loss 0.7877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 15:55:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 15:56:00,681] Trial 1 finished with value: 0.3821212564715687 and parameters: {'optimizer': 'adamw', 'lr': 0.0004591898870587331, 'weight_decay': 0.000133112160807369, 'scheduler': 'cosine', 'warmup_iters': 0, 'ema_decay': 0.999}. Best is trial 0 with value: 0.3826360001053386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4904\n",
      "[epoch 001/010] step 100/119 loss 1.1771\n",
      "[epoch 001/010] step 119/119 loss 1.1921\n",
      "[epoch 002/010] step 50/119 loss 1.3907\n",
      "[epoch 002/010] step 100/119 loss 1.2247\n",
      "[epoch 002/010] step 119/119 loss 1.2583\n",
      "[epoch 003/010] step 50/119 loss 1.0627\n",
      "[epoch 003/010] step 100/119 loss 1.0679\n",
      "[epoch 003/010] step 119/119 loss 1.4234\n",
      "[epoch 004/010] step 50/119 loss 1.0610\n",
      "[epoch 004/010] step 100/119 loss 0.9086\n",
      "[epoch 004/010] step 119/119 loss 1.0954\n",
      "[epoch 005/010] step 50/119 loss 0.9871\n",
      "[epoch 005/010] step 100/119 loss 0.8733\n",
      "[epoch 005/010] step 119/119 loss 0.8704\n",
      "[epoch 006/010] step 50/119 loss 0.7983\n",
      "[epoch 006/010] step 100/119 loss 0.8162\n",
      "[epoch 006/010] step 119/119 loss 0.7662\n",
      "[epoch 007/010] step 50/119 loss 0.8433\n",
      "[epoch 007/010] step 100/119 loss 0.7738\n",
      "[epoch 007/010] step 119/119 loss 0.7774\n",
      "[epoch 008/010] step 50/119 loss 0.6927\n",
      "[epoch 008/010] step 100/119 loss 0.6597\n",
      "[epoch 008/010] step 119/119 loss 0.6821\n",
      "[epoch 009/010] step 50/119 loss 0.6896\n",
      "[epoch 009/010] step 100/119 loss 0.6013\n",
      "[epoch 009/010] step 119/119 loss 0.7916\n",
      "[epoch 010/010] step 50/119 loss 0.7589\n",
      "[epoch 010/010] step 100/119 loss 0.6576\n",
      "[epoch 010/010] step 119/119 loss 0.6168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:04:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:04:55,332] Trial 2 finished with value: 0.4035825230630872 and parameters: {'optimizer': 'adamw', 'lr': 0.0002460208061014163, 'weight_decay': 7.4763120622522945e-06, 'scheduler': 'none'}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4631\n",
      "[epoch 001/010] step 100/119 loss 1.2561\n",
      "[epoch 001/010] step 119/119 loss 1.3802\n",
      "[epoch 002/010] step 50/119 loss 1.1909\n",
      "[epoch 002/010] step 100/119 loss 1.1663\n",
      "[epoch 002/010] step 119/119 loss 1.0146\n",
      "[epoch 003/010] step 50/119 loss 1.1468\n",
      "[epoch 003/010] step 100/119 loss 0.9409\n",
      "[epoch 003/010] step 119/119 loss 1.0901\n",
      "[epoch 004/010] step 50/119 loss 1.2061\n",
      "[epoch 004/010] step 100/119 loss 0.7852\n",
      "[epoch 004/010] step 119/119 loss 1.0534\n",
      "[epoch 005/010] step 50/119 loss 0.9064\n",
      "[epoch 005/010] step 100/119 loss 0.7901\n",
      "[epoch 005/010] step 119/119 loss 0.7880\n",
      "[epoch 006/010] step 50/119 loss 0.8379\n",
      "[epoch 006/010] step 100/119 loss 0.8101\n",
      "[epoch 006/010] step 119/119 loss 0.6621\n",
      "[epoch 007/010] step 50/119 loss 0.7281\n",
      "[epoch 007/010] step 100/119 loss 0.6386\n",
      "[epoch 007/010] step 119/119 loss 0.8835\n",
      "[epoch 008/010] step 50/119 loss 0.6132\n",
      "[epoch 008/010] step 100/119 loss 0.5800\n",
      "[epoch 008/010] step 119/119 loss 0.6473\n",
      "[epoch 009/010] step 50/119 loss 0.5239\n",
      "[epoch 009/010] step 100/119 loss 0.6516\n",
      "[epoch 009/010] step 119/119 loss 0.7465\n",
      "[epoch 010/010] step 50/119 loss 0.4846\n",
      "[epoch 010/010] step 100/119 loss 0.6810\n",
      "[epoch 010/010] step 119/119 loss 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:13:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:13:52,017] Trial 3 finished with value: 0.3905406904471475 and parameters: {'optimizer': 'adamw', 'lr': 0.00026891899484442807, 'weight_decay': 0.0002267398652378039, 'scheduler': 'cosine', 'warmup_iters': 0, 'ema_decay': 0.0}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 3.2759\n",
      "[epoch 001/010] step 100/119 loss 2.6084\n",
      "[epoch 001/010] step 119/119 loss 2.3519\n",
      "[epoch 002/010] step 50/119 loss 2.2711\n",
      "[epoch 002/010] step 100/119 loss 1.9929\n",
      "[epoch 002/010] step 119/119 loss 1.6640\n",
      "[epoch 003/010] step 50/119 loss 1.7741\n",
      "[epoch 003/010] step 100/119 loss 1.8768\n",
      "[epoch 003/010] step 119/119 loss 1.6977\n",
      "[epoch 004/010] step 50/119 loss 1.6969\n",
      "[epoch 004/010] step 100/119 loss 1.5086\n",
      "[epoch 004/010] step 119/119 loss 1.4445\n",
      "[epoch 005/010] step 50/119 loss 1.4400\n",
      "[epoch 005/010] step 100/119 loss 1.2956\n",
      "[epoch 005/010] step 119/119 loss 1.4740\n",
      "[epoch 006/010] step 50/119 loss 1.3436\n",
      "[epoch 006/010] step 100/119 loss 1.4818\n",
      "[epoch 006/010] step 119/119 loss 1.4061\n",
      "[epoch 007/010] step 50/119 loss 1.3850\n",
      "[epoch 007/010] step 100/119 loss 1.7041\n",
      "[epoch 007/010] step 119/119 loss 1.3558\n",
      "[epoch 008/010] step 50/119 loss 1.5382\n",
      "[epoch 008/010] step 100/119 loss 1.2831\n",
      "[epoch 008/010] step 119/119 loss 1.5568\n",
      "[epoch 009/010] step 50/119 loss 1.2084\n",
      "[epoch 009/010] step 100/119 loss 1.6009\n",
      "[epoch 009/010] step 119/119 loss 1.2915\n",
      "[epoch 010/010] step 50/119 loss 1.1473\n",
      "[epoch 010/010] step 100/119 loss 1.1663\n",
      "[epoch 010/010] step 119/119 loss 1.3109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:22:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:22:43,272] Trial 4 finished with value: 0.33506872165874363 and parameters: {'optimizer': 'adamw', 'lr': 0.0017618561667189323, 'weight_decay': 0.0002661901888489054, 'scheduler': 'none'}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 6.0290\n",
      "[epoch 001/010] step 100/119 loss 4.9099\n",
      "[epoch 001/010] step 119/119 loss 4.3436\n",
      "[epoch 002/010] step 50/119 loss 3.3767\n",
      "[epoch 002/010] step 100/119 loss 3.0152\n",
      "[epoch 002/010] step 119/119 loss 2.8712\n",
      "[epoch 003/010] step 50/119 loss 2.9087\n",
      "[epoch 003/010] step 100/119 loss 2.6403\n",
      "[epoch 003/010] step 119/119 loss 2.5925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:24:41,573] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.7509\n",
      "[epoch 001/010] step 100/119 loss 1.3077\n",
      "[epoch 001/010] step 119/119 loss 1.3144\n",
      "[epoch 002/010] step 50/119 loss 1.1498\n",
      "[epoch 002/010] step 100/119 loss 1.2004\n",
      "[epoch 002/010] step 119/119 loss 1.1948\n",
      "[epoch 003/010] step 50/119 loss 1.1347\n",
      "[epoch 003/010] step 100/119 loss 1.1237\n",
      "[epoch 003/010] step 119/119 loss 1.0477\n",
      "[epoch 004/010] step 50/119 loss 0.9902\n",
      "[epoch 004/010] step 100/119 loss 0.8476\n",
      "[epoch 004/010] step 119/119 loss 0.8080\n",
      "[epoch 005/010] step 50/119 loss 0.9992\n",
      "[epoch 005/010] step 100/119 loss 1.0956\n",
      "[epoch 005/010] step 119/119 loss 0.9784\n",
      "[epoch 006/010] step 50/119 loss 0.9185\n",
      "[epoch 006/010] step 100/119 loss 0.9805\n",
      "[epoch 006/010] step 119/119 loss 0.9071\n",
      "[epoch 007/010] step 50/119 loss 0.7091\n",
      "[epoch 007/010] step 100/119 loss 0.7452\n",
      "[epoch 007/010] step 119/119 loss 0.7298\n",
      "[epoch 008/010] step 50/119 loss 0.8704\n",
      "[epoch 008/010] step 100/119 loss 0.7657\n",
      "[epoch 008/010] step 119/119 loss 0.8064\n",
      "[epoch 009/010] step 50/119 loss 0.7785\n",
      "[epoch 009/010] step 100/119 loss 0.7546\n",
      "[epoch 009/010] step 119/119 loss 0.8907\n",
      "[epoch 010/010] step 50/119 loss 0.7313\n",
      "[epoch 010/010] step 100/119 loss 0.6956\n",
      "[epoch 010/010] step 119/119 loss 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:33:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:33:29,493] Trial 6 finished with value: 0.39255241529546736 and parameters: {'optimizer': 'sgd', 'lr': 0.01825823043920025, 'weight_decay': 0.00021154290797261214, 'scheduler': 'none'}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4586\n",
      "[epoch 001/010] step 100/119 loss 1.4013\n",
      "[epoch 001/010] step 119/119 loss 1.2614\n",
      "[epoch 002/010] step 50/119 loss 1.1484\n",
      "[epoch 002/010] step 100/119 loss 1.2132\n",
      "[epoch 002/010] step 119/119 loss 1.3357\n",
      "[epoch 003/010] step 50/119 loss 0.9937\n",
      "[epoch 003/010] step 100/119 loss 1.0187\n",
      "[epoch 003/010] step 119/119 loss 1.0542\n",
      "[epoch 004/010] step 50/119 loss 0.8610\n",
      "[epoch 004/010] step 100/119 loss 0.9149\n",
      "[epoch 004/010] step 119/119 loss 0.8333\n",
      "[epoch 005/010] step 50/119 loss 0.8542\n",
      "[epoch 005/010] step 100/119 loss 0.8743\n",
      "[epoch 005/010] step 119/119 loss 1.1418\n",
      "[epoch 006/010] step 50/119 loss 0.7563\n",
      "[epoch 006/010] step 100/119 loss 0.8133\n",
      "[epoch 006/010] step 119/119 loss 0.7323\n",
      "[epoch 007/010] step 50/119 loss 0.7902\n",
      "[epoch 007/010] step 100/119 loss 0.7954\n",
      "[epoch 007/010] step 119/119 loss 0.9311\n",
      "[epoch 008/010] step 50/119 loss 0.9163\n",
      "[epoch 008/010] step 100/119 loss 0.7932\n",
      "[epoch 008/010] step 119/119 loss 0.7256\n",
      "[epoch 009/010] step 50/119 loss 0.7709\n",
      "[epoch 009/010] step 100/119 loss 0.8397\n",
      "[epoch 009/010] step 119/119 loss 0.7470\n",
      "[epoch 010/010] step 50/119 loss 0.8423\n",
      "[epoch 010/010] step 100/119 loss 0.6216\n",
      "[epoch 010/010] step 119/119 loss 0.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:42:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:42:22,494] Trial 7 finished with value: 0.39311500146249423 and parameters: {'optimizer': 'adamw', 'lr': 6.930112765148073e-05, 'weight_decay': 3.87211803217458e-06, 'scheduler': 'cosine', 'warmup_iters': 0, 'ema_decay': 0.0}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.5002\n",
      "[epoch 001/010] step 100/119 loss 1.3649\n",
      "[epoch 001/010] step 119/119 loss 1.1524\n",
      "[epoch 002/010] step 50/119 loss 1.1306\n",
      "[epoch 002/010] step 100/119 loss 0.9801\n",
      "[epoch 002/010] step 119/119 loss 1.0913\n",
      "[epoch 003/010] step 50/119 loss 1.0715\n",
      "[epoch 003/010] step 100/119 loss 1.1599\n",
      "[epoch 003/010] step 119/119 loss 0.8509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:44:20,141] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 2.7440\n",
      "[epoch 001/010] step 100/119 loss 2.0355\n",
      "[epoch 001/010] step 119/119 loss 1.8517\n",
      "[epoch 002/010] step 50/119 loss 1.6787\n",
      "[epoch 002/010] step 100/119 loss 1.5201\n",
      "[epoch 002/010] step 119/119 loss 1.3180\n",
      "[epoch 003/010] step 50/119 loss 1.4025\n",
      "[epoch 003/010] step 100/119 loss 1.4837\n",
      "[epoch 003/010] step 119/119 loss 1.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:46:16,375] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 2.4778\n",
      "[epoch 001/010] step 100/119 loss 1.8320\n",
      "[epoch 001/010] step 119/119 loss 1.4574\n",
      "[epoch 002/010] step 50/119 loss 1.5947\n",
      "[epoch 002/010] step 100/119 loss 1.1885\n",
      "[epoch 002/010] step 119/119 loss 1.1096\n",
      "[epoch 003/010] step 50/119 loss 1.3191\n",
      "[epoch 003/010] step 100/119 loss 1.2692\n",
      "[epoch 003/010] step 119/119 loss 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:48:12,052] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 4.4185\n",
      "[epoch 001/010] step 100/119 loss 2.6798\n",
      "[epoch 001/010] step 119/119 loss 2.5610\n",
      "[epoch 002/010] step 50/119 loss 2.0319\n",
      "[epoch 002/010] step 100/119 loss 1.8234\n",
      "[epoch 002/010] step 119/119 loss 1.7691\n",
      "[epoch 003/010] step 50/119 loss 1.7399\n",
      "[epoch 003/010] step 100/119 loss 1.2743\n",
      "[epoch 003/010] step 119/119 loss 1.3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:50:09,050] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.3806\n",
      "[epoch 001/010] step 100/119 loss 1.3837\n",
      "[epoch 001/010] step 119/119 loss 1.1585\n",
      "[epoch 002/010] step 50/119 loss 1.1053\n",
      "[epoch 002/010] step 100/119 loss 1.0575\n",
      "[epoch 002/010] step 119/119 loss 1.2151\n",
      "[epoch 003/010] step 50/119 loss 1.0699\n",
      "[epoch 003/010] step 100/119 loss 1.0195\n",
      "[epoch 003/010] step 119/119 loss 1.0005\n",
      "[epoch 004/010] step 50/119 loss 0.9435\n",
      "[epoch 004/010] step 100/119 loss 1.0374\n",
      "[epoch 004/010] step 119/119 loss 0.7979\n",
      "[epoch 005/010] step 50/119 loss 0.7776\n",
      "[epoch 005/010] step 100/119 loss 0.8599\n",
      "[epoch 005/010] step 119/119 loss 0.5874\n",
      "[epoch 006/010] step 50/119 loss 0.8446\n",
      "[epoch 006/010] step 100/119 loss 0.8130\n",
      "[epoch 006/010] step 119/119 loss 0.7697\n",
      "[epoch 007/010] step 50/119 loss 0.6390\n",
      "[epoch 007/010] step 100/119 loss 0.9655\n",
      "[epoch 007/010] step 119/119 loss 0.6951\n",
      "[epoch 008/010] step 50/119 loss 0.5661\n",
      "[epoch 008/010] step 100/119 loss 0.5509\n",
      "[epoch 008/010] step 119/119 loss 0.8986\n",
      "[epoch 009/010] step 50/119 loss 0.4751\n",
      "[epoch 009/010] step 100/119 loss 0.5627\n",
      "[epoch 009/010] step 119/119 loss 0.5494\n",
      "[epoch 010/010] step 50/119 loss 0.5466\n",
      "[epoch 010/010] step 100/119 loss 0.5788\n",
      "[epoch 010/010] step 119/119 loss 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 16:58:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 16:59:03,362] Trial 12 finished with value: 0.39755849516839487 and parameters: {'optimizer': 'adamw', 'lr': 0.0001634795977671513, 'weight_decay': 7.203821205189785e-06, 'scheduler': 'cosine', 'warmup_iters': 0, 'ema_decay': 0.0}. Best is trial 2 with value: 0.4035825230630872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.3843\n",
      "[epoch 001/010] step 100/119 loss 1.2635\n",
      "[epoch 001/010] step 119/119 loss 1.2498\n",
      "[epoch 002/010] step 50/119 loss 1.0521\n",
      "[epoch 002/010] step 100/119 loss 1.1498\n",
      "[epoch 002/010] step 119/119 loss 1.1341\n",
      "[epoch 003/010] step 50/119 loss 1.0424\n",
      "[epoch 003/010] step 100/119 loss 1.1175\n",
      "[epoch 003/010] step 119/119 loss 0.9751\n",
      "[epoch 004/010] step 50/119 loss 1.1446\n",
      "[epoch 004/010] step 100/119 loss 0.9563\n",
      "[epoch 004/010] step 119/119 loss 0.7523\n",
      "[epoch 005/010] step 50/119 loss 0.9754\n",
      "[epoch 005/010] step 100/119 loss 0.9162\n",
      "[epoch 005/010] step 119/119 loss 0.7876\n",
      "[epoch 006/010] step 50/119 loss 0.7608\n",
      "[epoch 006/010] step 100/119 loss 0.9139\n",
      "[epoch 006/010] step 119/119 loss 0.9096\n",
      "[epoch 007/010] step 50/119 loss 0.8037\n",
      "[epoch 007/010] step 100/119 loss 0.7067\n",
      "[epoch 007/010] step 119/119 loss 0.7814\n",
      "[epoch 008/010] step 50/119 loss 0.6148\n",
      "[epoch 008/010] step 100/119 loss 0.6515\n",
      "[epoch 008/010] step 119/119 loss 0.7593\n",
      "[epoch 009/010] step 50/119 loss 0.8804\n",
      "[epoch 009/010] step 100/119 loss 0.6432\n",
      "[epoch 009/010] step 119/119 loss 0.5682\n",
      "[epoch 010/010] step 50/119 loss 0.6320\n",
      "[epoch 010/010] step 100/119 loss 0.6501\n",
      "[epoch 010/010] step 119/119 loss 0.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 17:07:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 17:07:57,431] Trial 13 finished with value: 0.4038958720252052 and parameters: {'optimizer': 'adamw', 'lr': 0.0001615751321784009, 'weight_decay': 1.341899467024904e-05, 'scheduler': 'none'}. Best is trial 13 with value: 0.4038958720252052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 2.3725\n",
      "[epoch 001/010] step 100/119 loss 2.0371\n",
      "[epoch 001/010] step 119/119 loss 1.9319\n",
      "[epoch 002/010] step 50/119 loss 1.6612\n",
      "[epoch 002/010] step 100/119 loss 1.3922\n",
      "[epoch 002/010] step 119/119 loss 1.4936\n",
      "[epoch 003/010] step 50/119 loss 1.5091\n",
      "[epoch 003/010] step 100/119 loss 1.2831\n",
      "[epoch 003/010] step 119/119 loss 1.3152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 17:09:52,663] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4948\n",
      "[epoch 001/010] step 100/119 loss 1.2137\n",
      "[epoch 001/010] step 119/119 loss 1.0703\n",
      "[epoch 002/010] step 50/119 loss 1.2544\n",
      "[epoch 002/010] step 100/119 loss 1.1132\n",
      "[epoch 002/010] step 119/119 loss 1.0096\n",
      "[epoch 003/010] step 50/119 loss 1.0580\n",
      "[epoch 003/010] step 100/119 loss 1.0173\n",
      "[epoch 003/010] step 119/119 loss 1.1806\n",
      "[epoch 004/010] step 50/119 loss 1.1569\n",
      "[epoch 004/010] step 100/119 loss 0.8121\n",
      "[epoch 004/010] step 119/119 loss 1.0076\n",
      "[epoch 005/010] step 50/119 loss 0.8589\n",
      "[epoch 005/010] step 100/119 loss 0.9320\n",
      "[epoch 005/010] step 119/119 loss 0.8230\n",
      "[epoch 006/010] step 50/119 loss 0.8962\n",
      "[epoch 006/010] step 100/119 loss 0.7757\n",
      "[epoch 006/010] step 119/119 loss 0.6635\n",
      "[epoch 007/010] step 50/119 loss 0.9018\n",
      "[epoch 007/010] step 100/119 loss 0.7855\n",
      "[epoch 007/010] step 119/119 loss 0.7445\n",
      "[epoch 008/010] step 50/119 loss 0.8863\n",
      "[epoch 008/010] step 100/119 loss 0.5810\n",
      "[epoch 008/010] step 119/119 loss 0.7625\n",
      "[epoch 009/010] step 50/119 loss 0.7480\n",
      "[epoch 009/010] step 100/119 loss 0.7195\n",
      "[epoch 009/010] step 119/119 loss 0.7347\n",
      "[epoch 010/010] step 50/119 loss 0.6587\n",
      "[epoch 010/010] step 100/119 loss 0.6751\n",
      "[epoch 010/010] step 119/119 loss 0.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 17:18:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 17:18:43,109] Trial 15 finished with value: 0.4031790329098913 and parameters: {'optimizer': 'adamw', 'lr': 0.00015230664888236258, 'weight_decay': 2.0115570409364703e-05, 'scheduler': 'none'}. Best is trial 13 with value: 0.4038958720252052.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4162\n",
      "[epoch 001/010] step 100/119 loss 1.2481\n",
      "[epoch 001/010] step 119/119 loss 1.1899\n",
      "[epoch 002/010] step 50/119 loss 1.3947\n",
      "[epoch 002/010] step 100/119 loss 1.2336\n",
      "[epoch 002/010] step 119/119 loss 1.2775\n",
      "[epoch 003/010] step 50/119 loss 1.1048\n",
      "[epoch 003/010] step 100/119 loss 1.0767\n",
      "[epoch 003/010] step 119/119 loss 0.9053\n",
      "[epoch 004/010] step 50/119 loss 0.8872\n",
      "[epoch 004/010] step 100/119 loss 0.7165\n",
      "[epoch 004/010] step 119/119 loss 0.8585\n",
      "[epoch 005/010] step 50/119 loss 0.9946\n",
      "[epoch 005/010] step 100/119 loss 0.8834\n",
      "[epoch 005/010] step 119/119 loss 0.8209\n",
      "[epoch 006/010] step 50/119 loss 0.7779\n",
      "[epoch 006/010] step 100/119 loss 0.8284\n",
      "[epoch 006/010] step 119/119 loss 0.7842\n",
      "[epoch 007/010] step 50/119 loss 0.7959\n",
      "[epoch 007/010] step 100/119 loss 0.7670\n",
      "[epoch 007/010] step 119/119 loss 0.8676\n",
      "[epoch 008/010] step 50/119 loss 0.6513\n",
      "[epoch 008/010] step 100/119 loss 0.7059\n",
      "[epoch 008/010] step 119/119 loss 0.9668\n",
      "[epoch 009/010] step 50/119 loss 0.7985\n",
      "[epoch 009/010] step 100/119 loss 0.5960\n",
      "[epoch 009/010] step 119/119 loss 0.5623\n",
      "[epoch 010/010] step 50/119 loss 0.7637\n",
      "[epoch 010/010] step 100/119 loss 0.7604\n",
      "[epoch 010/010] step 119/119 loss 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 17:27:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "[I 2025-12-25 17:27:34,447] Trial 16 finished with value: 0.41107649962940734 and parameters: {'optimizer': 'adamw', 'lr': 0.00016401195178940758, 'weight_decay': 1.0719427741859864e-06, 'scheduler': 'none'}. Best is trial 16 with value: 0.41107649962940734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.4462\n",
      "[epoch 001/010] step 100/119 loss 1.4563\n",
      "[epoch 001/010] step 119/119 loss 1.5130\n",
      "[epoch 002/010] step 50/119 loss 1.2899\n",
      "[epoch 002/010] step 100/119 loss 1.0445\n",
      "[epoch 002/010] step 119/119 loss 1.2512\n",
      "[epoch 003/010] step 50/119 loss 1.1332\n",
      "[epoch 003/010] step 100/119 loss 1.0655\n",
      "[epoch 003/010] step 119/119 loss 0.9526\n",
      "[epoch 004/010] step 50/119 loss 0.8921\n",
      "[epoch 004/010] step 100/119 loss 0.8884\n",
      "[epoch 004/010] step 119/119 loss 0.7525\n",
      "[epoch 005/010] step 50/119 loss 0.8766\n",
      "[epoch 005/010] step 100/119 loss 0.8597\n",
      "[epoch 005/010] step 119/119 loss 0.8147\n",
      "[epoch 006/010] step 50/119 loss 0.8098\n",
      "[epoch 006/010] step 100/119 loss 0.8790\n",
      "[epoch 006/010] step 119/119 loss 0.6886\n",
      "[epoch 007/010] step 50/119 loss 0.6548\n",
      "[epoch 007/010] step 100/119 loss 0.7286\n",
      "[epoch 007/010] step 119/119 loss 0.9080\n",
      "[epoch 008/010] step 50/119 loss 0.6557\n",
      "[epoch 008/010] step 100/119 loss 0.9337\n",
      "[epoch 008/010] step 119/119 loss 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 17:32:46,835] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 2.4474\n",
      "[epoch 001/010] step 100/119 loss 1.9317\n",
      "[epoch 001/010] step 119/119 loss 1.8297\n",
      "[epoch 002/010] step 50/119 loss 1.5097\n",
      "[epoch 002/010] step 100/119 loss 1.2604\n",
      "[epoch 002/010] step 119/119 loss 1.6049\n",
      "[epoch 003/010] step 50/119 loss 1.3750\n",
      "[epoch 003/010] step 100/119 loss 1.2916\n",
      "[epoch 003/010] step 119/119 loss 1.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 17:34:42,096] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/119 loss 1.6429\n",
      "[epoch 001/010] step 100/119 loss 1.3642\n",
      "[epoch 001/010] step 119/119 loss 1.2726\n",
      "[epoch 002/010] step 50/119 loss 1.1934\n",
      "[epoch 002/010] step 100/119 loss 0.9797\n",
      "[epoch 002/010] step 119/119 loss 1.1162\n",
      "[epoch 003/010] step 50/119 loss 1.3150\n",
      "[epoch 003/010] step 100/119 loss 1.1078\n",
      "[epoch 003/010] step 119/119 loss 1.0718\n",
      "[epoch 004/010] step 50/119 loss 1.0127\n",
      "[epoch 004/010] step 100/119 loss 0.8183\n",
      "[epoch 004/010] step 119/119 loss 0.9948\n",
      "[epoch 005/010] step 50/119 loss 1.0414\n",
      "[epoch 005/010] step 100/119 loss 0.9222\n",
      "[epoch 005/010] step 119/119 loss 0.9529\n",
      "[epoch 006/010] step 50/119 loss 0.7814\n",
      "[epoch 006/010] step 100/119 loss 0.8675\n",
      "[epoch 006/010] step 119/119 loss 1.0225\n",
      "[epoch 007/010] step 50/119 loss 0.7282\n",
      "[epoch 007/010] step 100/119 loss 0.9318\n",
      "[epoch 007/010] step 119/119 loss 0.8351\n",
      "[epoch 008/010] step 50/119 loss 0.7528\n",
      "[epoch 008/010] step 100/119 loss 0.7258\n",
      "[epoch 008/010] step 119/119 loss 1.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 17:39:53,076] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_value(AJI)= 0.41107649962940734\n",
      "best_params= {'optimizer': 'adamw', 'lr': 0.00016401195178940758, 'weight_decay': 1.0719427741859864e-06, 'scheduler': 'none'}\n"
     ]
    }
   ],
   "source": [
    "# Optuna search (10-epoch trials)\n",
    "import sys, time, math\n",
    "import optuna\n",
    "import mlflow.pytorch\n",
    "\n",
    "EPOCHS = \n",
    "10 #this is for search only \n",
    "N_TRIALS = 20\n",
    "EXPERIMENT_NAME = \"karyo_basic_optuna\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "ev = Evaluator(device=DEVICE)\n",
    "\n",
    "def _make_optimizer(model, opt_name, lr, weight_decay, momentum):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if opt_name == \"sgd\": \n",
    "        return torch.optim.SGD(params, lr=float(lr), momentum=float(momentum), weight_decay=float(weight_decay))\n",
    "    if opt_name == \"adamw\": \n",
    "        return torch.optim.AdamW(params, lr=float(lr), weight_decay=float(weight_decay))\n",
    "    raise ValueError(f\"unknown optimizer: {opt_name}\")\n",
    "\n",
    "def _get_aji(metrics_dict):\n",
    "    for k, v in metrics_dict.items():\n",
    "        if \"aji\" in str(k).lower(): return float(v)\n",
    "    raise KeyError(f\"AJI key not found; keys={list(metrics_dict.keys())}\")\n",
    "\n",
    "def objective(trial):\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adamw\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-3, 2e-2, log=True) if opt_name == \"sgd\" else trial.suggest_float(\"lr\", 5e-5, 2e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    scheduler = trial.suggest_categorical(\"scheduler\", [\"none\", \"cosine\"])\n",
    "    warmup_iters = trial.suggest_categorical(\"warmup_iters\", [0, 1000]) if scheduler != \"none\" else 0\n",
    "    ema_decay = trial.suggest_categorical(\"ema_decay\", [0.0, 0.999]) if scheduler != \"none\" else 0.0\n",
    "    momentum = 0.9 if opt_name == \"sgd\" else 0.0\n",
    "\n",
    "    model = build_model(MODEL_NAME, NUM_CLASSES).to(DEVICE)\n",
    "    conf = TrainConfig(\n",
    "        num_epochs=int(EPOCHS),\n",
    "        batch_size=int(getattr(cfg, \"batch_size\", 4)) if \"cfg\" in globals() else 4, \n",
    "        num_workers=int(getattr(cfg, \"num_workers\", 4)) if \"cfg\" in globals() else 4, \n",
    "        lr=float(lr), weight_decay=float(weight_decay), momentum=float(momentum if opt_name == \"sgd\" else 0.9), \n",
    "        print_every=50, \n",
    "        tracking_uri=TRACKING_URI, amp=True, grad_clip=1.0, \n",
    "        ema_decay=float(ema_decay), \n",
    "        warmup_iters=int(warmup_iters), \n",
    "        scheduler=str(scheduler), min_lr=1e-6, \n",
    "        freeze_bn=True)\n",
    "\n",
    "    trainer = Trainer(model, conf)\n",
    "    trainer.optimizer = _make_optimizer(model, opt_name, lr, weight_decay, momentum)\n",
    "    trainer._init_schedulers(steps_per_epoch=len(b_train))\n",
    "\n",
    "    run_name = f\"trial_{trial.number:03d}_{opt_name}_lr{lr:.2g}_wd{weight_decay:.1g}_{scheduler}_ema{ema_decay}\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\"trial\": int(trial.number), \"optimizer\": opt_name, \"lr\": float(lr), \"weight_decay\": float(weight_decay), \"momentum\": float(momentum), \"scheduler\": scheduler, \"warmup_iters\": int(warmup_iters), \"ema_decay\": float(ema_decay), \"epochs\": int(EPOCHS), \"model_name\": str(MODEL_NAME)})\n",
    "\n",
    "        for epoch in range(int(EPOCHS)):\n",
    "            t0 = time.perf_counter()\n",
    "            train_loss = trainer.train_one_epoch(b_train, epoch)\n",
    "            val_loss = trainer._eval_with_ema(b_val)\n",
    "            lr_now = float(trainer.optimizer.param_groups[0][\"lr\"])\n",
    "            trainer._sched_epoch_step()\n",
    "            mlflow.log_metrics({\"train_loss\": float(train_loss), \"val_loss\": float(val_loss), \"lr\": float(lr_now), \"epoch_sec\": float(time.perf_counter() - t0)}, step=int(epoch))\n",
    "            trial.report(-float(val_loss), step=int(epoch))\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        masks_b = ev.metrics_masks(model, b_test, num_classes=NUM_CLASSES)\n",
    "        aji = _get_aji(masks_b)\n",
    "        mlflow_log_metrics_safe(masks_b, prefix=\"b_test_\", step=None)\n",
    "        #mlflow.log_metrics({f\"b_test_{k}\": float(v) for k, v in masks_b.items()})\n",
    "        mlflow.log_metric(\"objective_AJI\", float(aji))\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "        return float(aji)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42), pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2, interval_steps=1))\n",
    "study.optimize(objective, n_trials=int(N_TRIALS))\n",
    "\n",
    "print(\"best_value(AJI)=\", study.best_value)\n",
    "print(\"best_params=\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baadbae9-6a75-4fae-bf1f-f7f19bfce553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_769253/1583732997.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  out.loc[out[\"optimizer\"].str.lower() != \"sgd\", \"momentum\"] = \"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mAP50</th>\n",
       "      <th>lr</th>\n",
       "      <th>wd</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866164</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>7.48e-06</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.815360</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1.07e-06</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.813263</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>2.01e-05</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803080</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>7.2e-06</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.797136</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>1.34e-05</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.741104</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.704362</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.690413</td>\n",
       "      <td>6.93e-05</td>\n",
       "      <td>3.87e-06</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.679184</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>6.25e-05</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.264928</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.183792</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>7.48e-06</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.145832</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093293</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>6.25e-05</td>\n",
       "      <td>adamw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mAP50        lr        wd optimizer momentum\n",
       "0   0.866164  0.000246  7.48e-06     adamw         \n",
       "1   0.815360  0.000164  1.07e-06     adamw         \n",
       "2   0.813263  0.000152  2.01e-05     adamw         \n",
       "3   0.803080  0.000163   7.2e-06     adamw         \n",
       "4   0.797136  0.000162  1.34e-05     adamw         \n",
       "5   0.790847  0.000269  0.000227     adamw         \n",
       "6   0.741104    0.0183  0.000212       sgd      0.9\n",
       "7   0.704362  0.000459  0.000133     adamw         \n",
       "8   0.690413  6.93e-05  3.87e-06     adamw         \n",
       "9   0.679184  0.000744  6.25e-05     adamw         \n",
       "10  0.264928   0.00176  0.000266     adamw         \n",
       "11  0.183792  0.000246  7.48e-06     adamw         \n",
       "12  0.145832  0.000459  0.000133     adamw         \n",
       "13  0.093293  0.000744  6.25e-05     adamw         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if exp is None: raise RuntimeError(f\"MLflow experiment not found: {EXPERIMENT_NAME}\")\n",
    "\n",
    "runs = mlflow.search_runs([exp.experiment_id], max_results=2000)\n",
    "\n",
    "name_col = next((c for c in [\"run_name\", \"tags.mlflow.runName\", \"tags.mlflow.run_name\"] if c in runs.columns), None)\n",
    "if name_col is None: name_col = \"run_id\"\n",
    "\n",
    "cols = [name_col, \"metrics.b_test_mAP50\", \"params.optimizer\", \"params.lr\", \"params.weight_decay\", \"params.momentum\"]\n",
    "cols = [c for c in cols if c in runs.columns]\n",
    "df = runs[cols].copy()\n",
    "\n",
    "df = df[df[\"metrics.b_test_mAP50\"].notna()].copy()\n",
    "df[\"metrics.b_test_mAP50\"] = pd.to_numeric(df[\"metrics.b_test_mAP50\"], errors=\"coerce\")\n",
    "for c in [\"params.lr\", \"params.weight_decay\", \"params.momentum\"]:\n",
    "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    \"mAP50\": df[\"metrics.b_test_mAP50\"].astype(float),\n",
    "    \"lr\": df.get(\"params.lr\", pd.Series([None]*len(df))),\n",
    "    \"wd\": df.get(\"params.weight_decay\", pd.Series([None]*len(df))),\n",
    "    \"optimizer\": df.get(\"params.optimizer\", pd.Series([\"\"]*len(df))).astype(str),\n",
    "    \"momentum\": df.get(\"params.momentum\", pd.Series([None]*len(df))),\n",
    "})\n",
    "\n",
    "out.loc[out[\"optimizer\"].str.lower() != \"sgd\", \"momentum\"] = \"\"\n",
    "out[\"lr\"] = out[\"lr\"].map(lambda x: f\"{float(x):.3g}\" if x is not None and x != \"\" and pd.notna(x) else \"\")\n",
    "out[\"wd\"] = out[\"wd\"].map(lambda x: f\"{float(x):.3g}\" if x is not None and x != \"\" and pd.notna(x) else \"\")\n",
    "out[\"momentum\"] = out[\"momentum\"].map(lambda x: f\"{float(x):.3g}\" if x is not None and x != \"\" and pd.notna(x) else \"\")\n",
    "\n",
    "out = out.sort_values(\"mAP50\", ascending=False).reset_index(drop=True)\n",
    "display(out.head(50))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c74f6c6-3ec1-4077-9c6f-568fa800c2af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/Jupyter/KaryoTest/train/trainer_v2.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=bool(train_conf.amp and self.device.type == \"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/040] step 50/119 loss 1.4433\n",
      "[epoch 001/040] step 100/119 loss 1.1993\n",
      "[epoch 001/040] step 119/119 loss 1.4526\n",
      "[epoch 001/040] train=1.6869 val=1.2408\n",
      "[epoch 002/040] step 50/119 loss 1.1471\n",
      "[epoch 002/040] step 100/119 loss 1.0001\n",
      "[epoch 002/040] step 119/119 loss 1.2928\n",
      "[epoch 002/040] train=1.1918 val=1.1336\n",
      "[epoch 003/040] step 50/119 loss 1.0857\n",
      "[epoch 003/040] step 100/119 loss 1.0921\n",
      "[epoch 003/040] step 119/119 loss 1.0237\n",
      "[epoch 003/040] train=1.0596 val=1.0067\n",
      "[epoch 004/040] step 50/119 loss 0.9541\n",
      "[epoch 004/040] step 100/119 loss 0.9192\n",
      "[epoch 004/040] step 119/119 loss 0.9223\n",
      "[epoch 004/040] train=0.9818 val=0.9620\n",
      "[epoch 005/040] step 50/119 loss 1.0336\n",
      "[epoch 005/040] step 100/119 loss 0.7592\n",
      "[epoch 005/040] step 119/119 loss 0.9446\n",
      "[epoch 005/040] train=0.9058 val=0.8871\n",
      "[epoch 006/040] step 50/119 loss 0.8981\n",
      "[epoch 006/040] step 100/119 loss 0.7994\n",
      "[epoch 006/040] step 119/119 loss 0.8711\n",
      "[epoch 006/040] train=0.8400 val=0.8538\n",
      "[epoch 007/040] step 50/119 loss 0.8248\n",
      "[epoch 007/040] step 100/119 loss 0.7939\n",
      "[epoch 007/040] step 119/119 loss 0.7717\n",
      "[epoch 007/040] train=0.7985 val=0.8164\n",
      "[epoch 008/040] step 50/119 loss 0.7363\n",
      "[epoch 008/040] step 100/119 loss 0.6812\n",
      "[epoch 008/040] step 119/119 loss 0.8608\n",
      "[epoch 008/040] train=0.7458 val=0.7852\n",
      "[epoch 009/040] step 50/119 loss 0.6754\n",
      "[epoch 009/040] step 100/119 loss 0.7046\n",
      "[epoch 009/040] step 119/119 loss 0.6864\n",
      "[epoch 009/040] train=0.7196 val=0.7122\n",
      "[epoch 010/040] step 50/119 loss 0.7492\n",
      "[epoch 010/040] step 100/119 loss 0.5641\n",
      "[epoch 010/040] step 119/119 loss 0.6693\n",
      "[epoch 010/040] train=0.6960 val=0.7080\n",
      "[epoch 011/040] step 50/119 loss 0.5978\n",
      "[epoch 011/040] step 100/119 loss 0.5690\n",
      "[epoch 011/040] step 119/119 loss 0.4869\n",
      "[epoch 011/040] train=0.6699 val=0.6966\n",
      "[epoch 012/040] step 50/119 loss 0.7939\n",
      "[epoch 012/040] step 100/119 loss 0.8899\n",
      "[epoch 012/040] step 119/119 loss 0.7296\n",
      "[epoch 012/040] train=0.6408 val=0.6595\n",
      "[epoch 013/040] step 50/119 loss 0.6607\n",
      "[epoch 013/040] step 100/119 loss 0.6144\n",
      "[epoch 013/040] step 119/119 loss 0.6183\n",
      "[epoch 013/040] train=0.6295 val=0.6746\n",
      "[epoch 014/040] step 50/119 loss 0.5419\n",
      "[epoch 014/040] step 100/119 loss 0.5181\n",
      "[epoch 014/040] step 119/119 loss 0.7024\n",
      "[epoch 014/040] train=0.6169 val=0.6680\n",
      "[epoch 015/040] step 50/119 loss 0.6310\n",
      "[epoch 015/040] step 100/119 loss 0.5195\n",
      "[epoch 015/040] step 119/119 loss 0.5856\n",
      "[epoch 015/040] train=0.6007 val=0.6475\n",
      "[epoch 016/040] step 50/119 loss 0.5302\n",
      "[epoch 016/040] step 100/119 loss 0.5940\n",
      "[epoch 016/040] step 119/119 loss 0.5754\n",
      "[epoch 016/040] train=0.5774 val=0.6383\n",
      "[epoch 017/040] step 50/119 loss 0.6163\n",
      "[epoch 017/040] step 100/119 loss 0.6019\n",
      "[epoch 017/040] step 119/119 loss 0.5074\n",
      "[epoch 017/040] train=0.5762 val=0.6161\n",
      "[epoch 018/040] step 50/119 loss 0.5243\n",
      "[epoch 018/040] step 100/119 loss 0.7414\n",
      "[epoch 018/040] step 119/119 loss 0.5143\n",
      "[epoch 018/040] train=0.5676 val=0.6263\n",
      "[epoch 019/040] step 50/119 loss 0.5061\n",
      "[epoch 019/040] step 100/119 loss 0.4807\n",
      "[epoch 019/040] step 119/119 loss 0.6497\n",
      "[epoch 019/040] train=0.5533 val=0.5978\n",
      "[epoch 020/040] step 50/119 loss 0.5055\n",
      "[epoch 020/040] step 100/119 loss 0.5697\n",
      "[epoch 020/040] step 119/119 loss 0.5184\n",
      "[epoch 020/040] train=0.5521 val=0.6001\n",
      "[epoch 021/040] step 50/119 loss 0.5281\n",
      "[epoch 021/040] step 100/119 loss 0.5528\n",
      "[epoch 021/040] step 119/119 loss 0.4256\n",
      "[epoch 021/040] train=0.5331 val=0.5991\n",
      "[epoch 022/040] step 50/119 loss 0.7248\n",
      "[epoch 022/040] step 100/119 loss 0.5463\n",
      "[epoch 022/040] step 119/119 loss 0.5110\n",
      "[epoch 022/040] train=0.5343 val=0.5903\n",
      "[epoch 023/040] step 50/119 loss 0.5955\n",
      "[epoch 023/040] step 100/119 loss 0.3927\n",
      "[epoch 023/040] step 119/119 loss 0.4527\n",
      "[epoch 023/040] train=0.5179 val=0.6161\n",
      "[epoch 024/040] step 50/119 loss 0.4379\n",
      "[epoch 024/040] step 100/119 loss 0.6719\n",
      "[epoch 024/040] step 119/119 loss 0.4935\n",
      "[epoch 024/040] train=0.5144 val=0.5886\n",
      "[epoch 025/040] step 50/119 loss 0.5441\n",
      "[epoch 025/040] step 100/119 loss 0.6009\n",
      "[epoch 025/040] step 119/119 loss 0.4278\n",
      "[epoch 025/040] train=0.5107 val=0.5793\n",
      "[epoch 026/040] step 50/119 loss 0.4593\n",
      "[epoch 026/040] step 100/119 loss 0.5053\n",
      "[epoch 026/040] step 119/119 loss 0.4276\n",
      "[epoch 026/040] train=0.5020 val=0.5504\n",
      "[epoch 027/040] step 50/119 loss 0.5538\n",
      "[epoch 027/040] step 100/119 loss 0.4511\n",
      "[epoch 027/040] step 119/119 loss 0.5220\n",
      "[epoch 027/040] train=0.4937 val=0.5636\n",
      "[epoch 028/040] step 50/119 loss 0.5250\n",
      "[epoch 028/040] step 100/119 loss 0.4343\n",
      "[epoch 028/040] step 119/119 loss 0.4100\n",
      "[epoch 028/040] train=0.4912 val=0.5723\n",
      "[epoch 029/040] step 50/119 loss 0.6068\n",
      "[epoch 029/040] step 100/119 loss 0.4915\n",
      "[epoch 029/040] step 119/119 loss 0.5027\n",
      "[epoch 029/040] train=0.4860 val=0.5785\n",
      "[epoch 030/040] step 50/119 loss 0.4038\n",
      "[epoch 030/040] step 100/119 loss 0.4087\n",
      "[epoch 030/040] step 119/119 loss 0.3060\n",
      "[epoch 030/040] train=0.4851 val=0.5643\n",
      "[epoch 031/040] step 50/119 loss 0.4559\n",
      "[epoch 031/040] step 100/119 loss 0.5251\n",
      "[epoch 031/040] step 119/119 loss 0.4854\n",
      "[epoch 031/040] train=0.4779 val=0.5600\n",
      "[epoch 032/040] step 50/119 loss 0.5370\n",
      "[epoch 032/040] step 100/119 loss 0.6696\n",
      "[epoch 032/040] step 119/119 loss 0.3686\n",
      "[epoch 032/040] train=0.4733 val=0.5698\n",
      "[epoch 033/040] step 50/119 loss 0.3783\n",
      "[epoch 033/040] step 100/119 loss 0.5598\n",
      "[epoch 033/040] step 119/119 loss 0.5391\n",
      "[epoch 033/040] train=0.4673 val=0.5761\n",
      "[epoch 034/040] step 50/119 loss 0.5151\n",
      "[epoch 034/040] step 100/119 loss 0.3968\n",
      "[epoch 034/040] step 119/119 loss 0.4490\n",
      "[epoch 034/040] train=0.4732 val=0.5504\n",
      "[epoch 035/040] step 50/119 loss 0.4074\n",
      "[epoch 035/040] step 100/119 loss 0.4814\n",
      "[epoch 035/040] step 119/119 loss 0.5476\n",
      "[epoch 035/040] train=0.4622 val=0.6137\n",
      "[epoch 036/040] step 50/119 loss 0.5108\n",
      "[epoch 036/040] step 100/119 loss 0.4040\n",
      "[epoch 036/040] step 119/119 loss 0.4236\n",
      "[epoch 036/040] train=0.4583 val=0.5348\n",
      "[epoch 037/040] step 50/119 loss 0.4130\n",
      "[epoch 037/040] step 100/119 loss 0.4251\n",
      "[epoch 037/040] step 119/119 loss 0.4517\n",
      "[epoch 037/040] train=0.4616 val=0.5490\n",
      "[epoch 038/040] step 50/119 loss 0.3769\n",
      "[epoch 038/040] step 100/119 loss 0.4913\n",
      "[epoch 038/040] step 119/119 loss 0.5494\n",
      "[epoch 038/040] train=0.4574 val=0.5749\n",
      "[epoch 039/040] step 50/119 loss 0.4219\n",
      "[epoch 039/040] step 100/119 loss 0.3743\n",
      "[epoch 039/040] step 119/119 loss 0.5278\n",
      "[epoch 039/040] train=0.4469 val=0.5455\n",
      "[epoch 040/040] step 50/119 loss 0.4889\n",
      "[epoch 040/040] step 100/119 loss 0.3786\n",
      "[epoch 040/040] step 119/119 loss 0.4691\n",
      "[epoch 040/040] train=0.4475 val=0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 20:01:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: final_best_map50_adamw_lr0.000246_wd7.48e-06_ep40\n"
     ]
    }
   ],
   "source": [
    "FINAL_EPOCHS = 40\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "runs = mlflow.search_runs([exp.experiment_id], order_by=[\"metrics.b_test_mAP50 DESC\"], max_results=2000)\n",
    "runs = runs[runs[\"metrics.b_test_mAP50\"].notna()].copy()\n",
    "best = runs.iloc[0]\n",
    "\n",
    "opt = str(best.get(\"params.optimizer\", \"sgd\")).lower()\n",
    "lr = float(best.get(\"params.lr\"))\n",
    "wd = float(best.get(\"params.weight_decay\"))\n",
    "mom = float(best.get(\"params.momentum\", 0.9)) if opt == \"sgd\" else 0.0\n",
    "\n",
    "b_train = b_train if \"b_train\" in globals() else dm.make_loader_b_train()\n",
    "b_val = b_val if \"b_val\" in globals() else dm.make_loader_b_val()\n",
    "b_test = b_test if \"b_test\" in globals() else dm.make_loader_b_test()\n",
    "ev = ev if \"ev\" in globals() else Evaluator(device=DEVICE)\n",
    "\n",
    "model = build_model(MODEL_NAME, NUM_CLASSES).to(DEVICE)\n",
    "conf = TrainConfig(num_epochs=FINAL_EPOCHS, batch_size=4, num_workers=4, lr=lr, weight_decay=wd, momentum=mom if opt == \"sgd\" else 0.9, print_every=50, \n",
    "                   tracking_uri=TRACKING_URI, amp=True, grad_clip=1.0, ema_decay=0.0, warmup_iters=0, scheduler=\"none\", min_lr=1e-6, freeze_bn=True)\n",
    "\n",
    "trainer = Trainer(model, conf)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "trainer.optimizer = torch.optim.SGD(params, lr=lr, momentum=mom, weight_decay=wd) if opt == \"sgd\" else torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
    "trainer._init_schedulers(steps_per_epoch=len(b_train))\n",
    "\n",
    "run_name = f\"final_best_map50_{opt}_lr{lr:.3g}_wd{wd:.3g}_ep{FINAL_EPOCHS}\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    mlflow.log_params({\"source\": \"best_by_b_test_mAP50\", \"optimizer\": opt, \"lr\": lr, \"weight_decay\": wd, \"momentum\": mom, \"epochs\": FINAL_EPOCHS, \"model_name\": str(MODEL_NAME), \"best_trial_run_id\": str(best.get(\"run_id\", \"\")), \"best_trial_b_test_mAP50\": float(best[\"metrics.b_test_mAP50\"])})\n",
    "    for epoch in range(FINAL_EPOCHS):\n",
    "        train_loss = trainer.train_one_epoch(b_train, epoch)\n",
    "        val_loss = trainer._eval_with_ema(b_val)\n",
    "        mlflow.log_metrics({\"train_loss\": float(train_loss), \"val_loss\": float(val_loss)}, step=epoch)\n",
    "        print(f\"[epoch {epoch + 1:03d}/{FINAL_EPOCHS:03d}] train={float(train_loss):.4f} val={float(val_loss):.4f}\")\n",
    "    m = ev.metrics_masks(model, b_test, num_classes=NUM_CLASSES)\n",
    "    mlflow.log_metric(\"b_test_mAP50\", float(m[\"mAP50\"]))\n",
    "    mlflow.log_metric(\"b_test_AJI\", float(m[\"AJI\"]))\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "print(\"done:\", run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ddda14-6d40-40d9-b237-9778a96cc762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: _optuna.pth\n"
     ]
    }
   ],
   "source": [
    "ckpt_a =\"_optuna.pth\"\n",
    "torch.save(model.state_dict(), ckpt_a)\n",
    "print(\"saved:\", ckpt_a) #mlflow saves checkpoints also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da35b8b6-81aa-4837-9824-689db58fccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50/AP50 candidates: ['metrics.b_test_mAP50']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics.objective_AJI</th>\n",
       "      <th>metrics.b_test_AJI</th>\n",
       "      <th>metrics.b_test_mAP50_or_AP50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.411076</td>\n",
       "      <td>0.411076</td>\n",
       "      <td>0.815360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.403896</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>0.797136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.403583</td>\n",
       "      <td>0.403583</td>\n",
       "      <td>0.866164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403179</td>\n",
       "      <td>0.403179</td>\n",
       "      <td>0.813263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.397558</td>\n",
       "      <td>0.397558</td>\n",
       "      <td>0.803080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.393115</td>\n",
       "      <td>0.393115</td>\n",
       "      <td>0.690413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.392552</td>\n",
       "      <td>0.392552</td>\n",
       "      <td>0.741104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.390541</td>\n",
       "      <td>0.390541</td>\n",
       "      <td>0.790847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.382636</td>\n",
       "      <td>0.382636</td>\n",
       "      <td>0.679184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.382121</td>\n",
       "      <td>0.382121</td>\n",
       "      <td>0.704362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.335069</td>\n",
       "      <td>0.335069</td>\n",
       "      <td>0.264928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.320754</td>\n",
       "      <td>0.320754</td>\n",
       "      <td>0.183792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.290708</td>\n",
       "      <td>0.290708</td>\n",
       "      <td>0.145832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.270942</td>\n",
       "      <td>0.270942</td>\n",
       "      <td>0.093293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    metrics.objective_AJI  metrics.b_test_AJI  metrics.b_test_mAP50_or_AP50\n",
       "0                0.411076            0.411076                      0.815360\n",
       "1                0.403896            0.403896                      0.797136\n",
       "2                0.403583            0.403583                      0.866164\n",
       "3                0.403179            0.403179                      0.813263\n",
       "4                0.397558            0.397558                      0.803080\n",
       "5                0.393115            0.393115                      0.690413\n",
       "6                0.392552            0.392552                      0.741104\n",
       "7                0.390541            0.390541                      0.790847\n",
       "8                0.382636            0.382636                      0.679184\n",
       "9                0.382121            0.382121                      0.704362\n",
       "10               0.335069            0.335069                      0.264928\n",
       "11               0.320754            0.320754                      0.183792\n",
       "12               0.290708            0.290708                      0.145832\n",
       "13               0.270942            0.270942                      0.093293\n",
       "14                    NaN                 NaN                           NaN\n",
       "15                    NaN                 NaN                           NaN\n",
       "16                    NaN                 NaN                           NaN\n",
       "17                    NaN                 NaN                           NaN\n",
       "18                    NaN                 NaN                           NaN\n",
       "19                    NaN                 NaN                           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial mAP50/AP50 = 0.8153602480888367\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if exp is None: raise RuntimeError(f\"MLflow experiment not found: {EXPERIMENT_NAME}\")\n",
    "\n",
    "runs = mlflow.search_runs([exp.experiment_id], order_by=[\"metrics.objective_AJI DESC\"], max_results=500)\n",
    "\n",
    "# find candidate mAP50 metric columns that were logged from metrics_masks()\n",
    "metric_cols = [c for c in runs.columns if c.startswith(\"metrics.\")]\n",
    "cand = [c for c in metric_cols if (\"map50\" in c.lower()) or (re.search(r\"\\bap50\\b\", c.lower()) is not None)]\n",
    "print(\"mAP50/AP50 candidates:\", cand)\n",
    "\n",
    "# pick the best-looking one (prefer b_test_*)\n",
    "map_col = next((c for c in cand if \"b_test_\" in c.lower()), None) or (cand[0] if cand else None)\n",
    "if map_col is None: raise RuntimeError(\"No mAP50/AP50 metric found in MLflow. (It may not be produced by metrics_masks().)\")\n",
    "\n",
    "show_cols = [c for c in [\"run_name\", \"metrics.objective_AJI\", \"metrics.b_test_AJI\", map_col] if c in runs.columns]\n",
    "df = runs[show_cols].copy()\n",
    "df.rename(columns={map_col: \"metrics.b_test_mAP50_or_AP50\"}, inplace=True)\n",
    "\n",
    "display(df.head(20))\n",
    "print(\"best trial mAP50/AP50 =\", float(df.iloc[0][\"metrics.b_test_mAP50_or_AP50\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
