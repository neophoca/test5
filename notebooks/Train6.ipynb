{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424d6e82-8c48-4970-8a97-703b6385b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1 + 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f410a5-3715-4000-b3dc-b1726f2e754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from models.models import build_model     \n",
    "from datasets.loader import DataModule, DataConfig  \n",
    "from train.trainer import Trainer, TrainConfig  \n",
    "from train.eval import Evaluator             \n",
    "from datasets.base import collate_bb\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = 25\n",
    "B_CKPT = \"./weights/maskrcnn_B_ep40.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f974f7-7f87-476b-aebb-9673010e8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_EPOCHS = 3\n",
    "FINETUNE_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "LR_WARMUP = 1e-4\n",
    "LR_FINETUNE = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "FREEZE_MASK_HEAD_IN_FINETUNE = True\n",
    "\n",
    "dm = DataModule(DataConfig(val_frac=0.1, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS), with_masks = False)\n",
    "b_train_loader, b_val_loader = dm.make_loaders_b()\n",
    "a_train_box = dm.ds_a_train\n",
    "a_val_box   = dm.ds_a_val\n",
    "ab_train_ds = ConcatDataset([a_train_box, dm.ds_b_train])\n",
    "ab_val_ds   = ConcatDataset([a_val_box, dm.ds_b_val])\n",
    "\n",
    "ab_train_loader = DataLoader(ab_train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_bb)\n",
    "ab_val_loader = DataLoader(ab_val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_bb)\n",
    "\n",
    "b_test_loader = dm.make_loader_b_test()\n",
    "c_test_loader = dm.make_loader_c_test()\n",
    "d_test_loader = dm.make_loader_d_test()\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///media/sdb1/mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a576b-a6eb-4928-8a85-e37ddf6f3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\"maskrcnn_attfpn\", NUM_CLASSES).to(DEVICE)\n",
    "sd = torch.load(B_CKPT, map_location=\"cpu\")\n",
    "model.load_state_dict(sd, strict=False)\n",
    "\n",
    "\n",
    "def allow_missing_masks(model):\n",
    "    orig_forward = model.forward\n",
    "    def forward(images, targets=None):\n",
    "        if model.training and targets is not None and not all((\"masks\" in t) for t in targets):\n",
    "            rh = model.roi_heads\n",
    "            saved = (rh.mask_roi_pool, rh.mask_head, rh.mask_predictor)\n",
    "            try:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = None, None, None\n",
    "                return orig_forward(images, targets)\n",
    "            finally:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = saved\n",
    "        return orig_forward(images, targets)\n",
    "    model.forward = forward\n",
    "    return model\n",
    "allow_missing_masks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c13918-00f5-4827-a234-e1c28d62a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def req(mod, flag: bool):\n",
    "    for p in mod.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "req(model, False)\n",
    "req(model.backbone.ca, True)\n",
    "req(model.backbone.sa, True)\n",
    "\n",
    "conf = TrainConfig()\n",
    "conf.num_epochs = WARMUP_EPOCHS\n",
    "conf.batch_size = BATCH_SIZE\n",
    "conf.num_workers = NUM_WORKERS\n",
    "conf.lr = LR_WARMUP\n",
    "conf.weight_decay = WEIGHT_DECAY\n",
    "conf.momentum = MOMENTUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f7baba-f9bc-4eb0-a762-ad7b20ad4f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/003] step 50/119 loss 1.0387\n",
      "[epoch 001/003] step 100/119 loss 0.9133\n",
      "[epoch 001/003] step 119/119 loss 1.1002\n",
      "epoch 001/003  train=1.1486  val=1.1030\n",
      "[epoch 002/003] step 50/119 loss 1.0594\n",
      "[epoch 002/003] step 100/119 loss 0.9256\n",
      "[epoch 002/003] step 119/119 loss 1.0038\n",
      "epoch 002/003  train=0.9435  val=1.0371\n",
      "[epoch 003/003] step 50/119 loss 0.8514\n",
      "[epoch 003/003] step 100/119 loss 0.9803\n",
      "[epoch 003/003] step 119/119 loss 0.9091\n",
      "epoch 003/003  train=0.8965  val=1.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/12 13:03:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, conf)\n",
    "hist_warm = trainer.run(b_train_loader, b_val_loader, experiment_name=\"Att_Train6\")\n",
    "\n",
    "req(model, True)\n",
    "if FREEZE_MASK_HEAD_IN_FINETUNE:\n",
    "    req(model.roi_heads.mask_head, False)\n",
    "    req(model.roi_heads.mask_predictor, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23f7165-2c15-439a-808e-edd452d03e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eabd2ab-58f3-4392-a5b4-ba6af69d749a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/1244 loss 1.0411\n",
      "[epoch 001/010] step 100/1244 loss 1.1805\n",
      "[epoch 001/010] step 150/1244 loss 0.8446\n",
      "[epoch 001/010] step 200/1244 loss 0.7666\n",
      "[epoch 001/010] step 250/1244 loss 0.8738\n",
      "[epoch 001/010] step 300/1244 loss 1.0213\n",
      "[epoch 001/010] step 350/1244 loss 0.7507\n",
      "[epoch 001/010] step 400/1244 loss 0.9404\n",
      "[epoch 001/010] step 450/1244 loss 0.7451\n",
      "[epoch 001/010] step 500/1244 loss 0.8671\n",
      "[epoch 001/010] step 550/1244 loss 0.8172\n",
      "[epoch 001/010] step 600/1244 loss 0.7147\n",
      "[epoch 001/010] step 650/1244 loss 0.9449\n",
      "[epoch 001/010] step 700/1244 loss 0.7148\n",
      "[epoch 001/010] step 750/1244 loss 0.6044\n",
      "[epoch 001/010] step 800/1244 loss 0.6489\n",
      "[epoch 001/010] step 850/1244 loss 0.5952\n",
      "[epoch 001/010] step 900/1244 loss 0.6872\n",
      "[epoch 001/010] step 950/1244 loss 0.5851\n",
      "[epoch 001/010] step 1000/1244 loss 0.8295\n",
      "[epoch 001/010] step 1050/1244 loss 0.7705\n",
      "[epoch 001/010] step 1100/1244 loss 0.7502\n",
      "[epoch 001/010] step 1150/1244 loss 0.7296\n",
      "[epoch 001/010] step 1200/1244 loss 0.6376\n",
      "[epoch 001/010] step 1244/1244 loss 0.5533\n",
      "epoch 001/010  train=0.7999  val=0.7404\n",
      "[epoch 002/010] step 50/1244 loss 0.5019\n",
      "[epoch 002/010] step 100/1244 loss 0.8160\n",
      "[epoch 002/010] step 150/1244 loss 0.7424\n",
      "[epoch 002/010] step 200/1244 loss 0.5702\n",
      "[epoch 002/010] step 250/1244 loss 0.5456\n",
      "[epoch 002/010] step 300/1244 loss 0.7671\n",
      "[epoch 002/010] step 350/1244 loss 0.6371\n",
      "[epoch 002/010] step 400/1244 loss 0.7974\n",
      "[epoch 002/010] step 450/1244 loss 0.7866\n",
      "[epoch 002/010] step 500/1244 loss 0.6542\n",
      "[epoch 002/010] step 550/1244 loss 0.7401\n",
      "[epoch 002/010] step 600/1244 loss 0.6461\n",
      "[epoch 002/010] step 650/1244 loss 0.7256\n",
      "[epoch 002/010] step 700/1244 loss 0.5563\n",
      "[epoch 002/010] step 750/1244 loss 0.5348\n",
      "[epoch 002/010] step 800/1244 loss 0.6100\n",
      "[epoch 002/010] step 850/1244 loss 0.6240\n",
      "[epoch 002/010] step 900/1244 loss 0.6093\n",
      "[epoch 002/010] step 950/1244 loss 0.7836\n",
      "[epoch 002/010] step 1000/1244 loss 0.6801\n",
      "[epoch 002/010] step 1050/1244 loss 0.4527\n",
      "[epoch 002/010] step 1100/1244 loss 0.6460\n",
      "[epoch 002/010] step 1150/1244 loss 0.5121\n",
      "[epoch 002/010] step 1200/1244 loss 0.6630\n",
      "[epoch 002/010] step 1244/1244 loss 0.7437\n",
      "epoch 002/010  train=0.6569  val=0.7102\n",
      "[epoch 003/010] step 50/1244 loss 0.7303\n",
      "[epoch 003/010] step 100/1244 loss 0.5729\n",
      "[epoch 003/010] step 150/1244 loss 0.6946\n",
      "[epoch 003/010] step 200/1244 loss 0.4265\n",
      "[epoch 003/010] step 250/1244 loss 0.5336\n",
      "[epoch 003/010] step 300/1244 loss 0.6134\n",
      "[epoch 003/010] step 350/1244 loss 0.8094\n",
      "[epoch 003/010] step 400/1244 loss 0.5246\n",
      "[epoch 003/010] step 450/1244 loss 0.6003\n",
      "[epoch 003/010] step 500/1244 loss 0.5248\n",
      "[epoch 003/010] step 550/1244 loss 0.5898\n",
      "[epoch 003/010] step 600/1244 loss 0.5321\n",
      "[epoch 003/010] step 650/1244 loss 0.4682\n",
      "[epoch 003/010] step 700/1244 loss 0.6272\n",
      "[epoch 003/010] step 750/1244 loss 0.4384\n",
      "[epoch 003/010] step 800/1244 loss 0.4625\n",
      "[epoch 003/010] step 850/1244 loss 0.4719\n",
      "[epoch 003/010] step 900/1244 loss 0.6167\n",
      "[epoch 003/010] step 950/1244 loss 0.5749\n",
      "[epoch 003/010] step 1000/1244 loss 0.6714\n",
      "[epoch 003/010] step 1050/1244 loss 0.4207\n",
      "[epoch 003/010] step 1100/1244 loss 0.7077\n",
      "[epoch 003/010] step 1150/1244 loss 0.6782\n",
      "[epoch 003/010] step 1200/1244 loss 0.4966\n",
      "[epoch 003/010] step 1244/1244 loss 0.4747\n",
      "epoch 003/010  train=0.6102  val=0.6406\n",
      "[epoch 004/010] step 50/1244 loss 0.6945\n",
      "[epoch 004/010] step 100/1244 loss 0.5456\n",
      "[epoch 004/010] step 150/1244 loss 0.4638\n",
      "[epoch 004/010] step 200/1244 loss 0.5631\n",
      "[epoch 004/010] step 250/1244 loss 0.6060\n",
      "[epoch 004/010] step 300/1244 loss 0.7654\n",
      "[epoch 004/010] step 350/1244 loss 0.5296\n",
      "[epoch 004/010] step 400/1244 loss 0.6961\n",
      "[epoch 004/010] step 450/1244 loss 0.6704\n",
      "[epoch 004/010] step 500/1244 loss 0.5349\n",
      "[epoch 004/010] step 550/1244 loss 0.4927\n",
      "[epoch 004/010] step 600/1244 loss 0.4991\n",
      "[epoch 004/010] step 650/1244 loss 0.3808\n",
      "[epoch 004/010] step 700/1244 loss 0.5128\n",
      "[epoch 004/010] step 750/1244 loss 0.5911\n",
      "[epoch 004/010] step 800/1244 loss 0.4515\n",
      "[epoch 004/010] step 850/1244 loss 0.5979\n",
      "[epoch 004/010] step 900/1244 loss 0.5750\n",
      "[epoch 004/010] step 950/1244 loss 0.6498\n",
      "[epoch 004/010] step 1000/1244 loss 0.5153\n",
      "[epoch 004/010] step 1050/1244 loss 0.6139\n",
      "[epoch 004/010] step 1100/1244 loss 0.6077\n",
      "[epoch 004/010] step 1150/1244 loss 0.5415\n",
      "[epoch 004/010] step 1200/1244 loss 0.5657\n",
      "[epoch 004/010] step 1244/1244 loss 0.5908\n",
      "epoch 004/010  train=0.5797  val=0.6461\n",
      "[epoch 005/010] step 50/1244 loss 0.5076\n",
      "[epoch 005/010] step 100/1244 loss 0.6899\n",
      "[epoch 005/010] step 150/1244 loss 0.5867\n",
      "[epoch 005/010] step 200/1244 loss 0.5612\n",
      "[epoch 005/010] step 250/1244 loss 0.4417\n",
      "[epoch 005/010] step 300/1244 loss 0.6796\n",
      "[epoch 005/010] step 350/1244 loss 0.4497\n",
      "[epoch 005/010] step 400/1244 loss 0.7303\n",
      "[epoch 005/010] step 450/1244 loss 0.5136\n",
      "[epoch 005/010] step 500/1244 loss 0.4285\n",
      "[epoch 005/010] step 550/1244 loss 0.7473\n",
      "[epoch 005/010] step 600/1244 loss 0.6154\n",
      "[epoch 005/010] step 650/1244 loss 0.4792\n",
      "[epoch 005/010] step 700/1244 loss 0.5314\n",
      "[epoch 005/010] step 750/1244 loss 0.4815\n",
      "[epoch 005/010] step 800/1244 loss 0.4678\n",
      "[epoch 005/010] step 850/1244 loss 0.6429\n",
      "[epoch 005/010] step 900/1244 loss 0.5748\n",
      "[epoch 005/010] step 950/1244 loss 0.5545\n",
      "[epoch 005/010] step 1000/1244 loss 0.6066\n",
      "[epoch 005/010] step 1050/1244 loss 0.5305\n",
      "[epoch 005/010] step 1100/1244 loss 0.4960\n",
      "[epoch 005/010] step 1150/1244 loss 0.6528\n",
      "[epoch 005/010] step 1200/1244 loss 0.4664\n",
      "[epoch 005/010] step 1244/1244 loss 0.5366\n",
      "epoch 005/010  train=0.5534  val=0.6158\n",
      "[epoch 006/010] step 50/1244 loss 0.4434\n",
      "[epoch 006/010] step 100/1244 loss 0.5119\n",
      "[epoch 006/010] step 150/1244 loss 0.5050\n",
      "[epoch 006/010] step 200/1244 loss 0.4687\n",
      "[epoch 006/010] step 250/1244 loss 0.6130\n",
      "[epoch 006/010] step 300/1244 loss 0.5564\n",
      "[epoch 006/010] step 350/1244 loss 0.5579\n",
      "[epoch 006/010] step 400/1244 loss 0.5767\n",
      "[epoch 006/010] step 450/1244 loss 0.4680\n",
      "[epoch 006/010] step 500/1244 loss 0.5745\n",
      "[epoch 006/010] step 550/1244 loss 0.5591\n",
      "[epoch 006/010] step 600/1244 loss 0.5709\n",
      "[epoch 006/010] step 650/1244 loss 0.5164\n",
      "[epoch 006/010] step 700/1244 loss 0.5065\n",
      "[epoch 006/010] step 750/1244 loss 0.5509\n",
      "[epoch 006/010] step 800/1244 loss 0.6283\n",
      "[epoch 006/010] step 850/1244 loss 0.4649\n",
      "[epoch 006/010] step 900/1244 loss 0.5325\n",
      "[epoch 006/010] step 950/1244 loss 0.6283\n",
      "[epoch 006/010] step 1000/1244 loss 0.5010\n",
      "[epoch 006/010] step 1050/1244 loss 0.5097\n",
      "[epoch 006/010] step 1100/1244 loss 0.5329\n",
      "[epoch 006/010] step 1150/1244 loss 0.4906\n",
      "[epoch 006/010] step 1200/1244 loss 0.6072\n",
      "[epoch 006/010] step 1244/1244 loss 0.4254\n",
      "epoch 006/010  train=0.5367  val=0.5947\n",
      "[epoch 007/010] step 50/1244 loss 0.6346\n",
      "[epoch 007/010] step 100/1244 loss 0.4684\n",
      "[epoch 007/010] step 150/1244 loss 0.3742\n",
      "[epoch 007/010] step 200/1244 loss 0.4162\n",
      "[epoch 007/010] step 250/1244 loss 0.4669\n",
      "[epoch 007/010] step 300/1244 loss 0.8897\n",
      "[epoch 007/010] step 350/1244 loss 0.6948\n",
      "[epoch 007/010] step 400/1244 loss 0.6143\n",
      "[epoch 007/010] step 450/1244 loss 0.4236\n",
      "[epoch 007/010] step 500/1244 loss 0.5579\n",
      "[epoch 007/010] step 550/1244 loss 0.4492\n",
      "[epoch 007/010] step 600/1244 loss 0.4889\n",
      "[epoch 007/010] step 650/1244 loss 0.6017\n",
      "[epoch 007/010] step 700/1244 loss 0.5328\n",
      "[epoch 007/010] step 750/1244 loss 0.7392\n",
      "[epoch 007/010] step 800/1244 loss 0.4964\n",
      "[epoch 007/010] step 850/1244 loss 0.8250\n",
      "[epoch 007/010] step 900/1244 loss 0.4986\n",
      "[epoch 007/010] step 950/1244 loss 0.5137\n",
      "[epoch 007/010] step 1000/1244 loss 0.5527\n",
      "[epoch 007/010] step 1050/1244 loss 0.4686\n",
      "[epoch 007/010] step 1100/1244 loss 0.6853\n",
      "[epoch 007/010] step 1150/1244 loss 0.6746\n",
      "[epoch 007/010] step 1200/1244 loss 0.5719\n",
      "[epoch 007/010] step 1244/1244 loss 0.5220\n",
      "epoch 007/010  train=0.5219  val=0.6317\n",
      "[epoch 008/010] step 50/1244 loss 0.3691\n",
      "[epoch 008/010] step 100/1244 loss 0.5282\n",
      "[epoch 008/010] step 150/1244 loss 0.6648\n",
      "[epoch 008/010] step 200/1244 loss 0.4267\n",
      "[epoch 008/010] step 250/1244 loss 0.4465\n",
      "[epoch 008/010] step 300/1244 loss 0.4312\n",
      "[epoch 008/010] step 350/1244 loss 0.5268\n",
      "[epoch 008/010] step 400/1244 loss 0.6173\n",
      "[epoch 008/010] step 450/1244 loss 0.4119\n",
      "[epoch 008/010] step 500/1244 loss 0.5069\n",
      "[epoch 008/010] step 550/1244 loss 0.6051\n",
      "[epoch 008/010] step 600/1244 loss 0.4272\n",
      "[epoch 008/010] step 650/1244 loss 0.7173\n",
      "[epoch 008/010] step 700/1244 loss 0.4039\n",
      "[epoch 008/010] step 750/1244 loss 0.4538\n",
      "[epoch 008/010] step 800/1244 loss 0.5647\n",
      "[epoch 008/010] step 850/1244 loss 0.4572\n",
      "[epoch 008/010] step 900/1244 loss 0.4937\n",
      "[epoch 008/010] step 950/1244 loss 0.5323\n",
      "[epoch 008/010] step 1000/1244 loss 0.6268\n",
      "[epoch 008/010] step 1050/1244 loss 0.4836\n",
      "[epoch 008/010] step 1100/1244 loss 0.5121\n",
      "[epoch 008/010] step 1150/1244 loss 0.5241\n",
      "[epoch 008/010] step 1200/1244 loss 0.4605\n",
      "[epoch 008/010] step 1244/1244 loss 0.4211\n",
      "epoch 008/010  train=0.5094  val=0.5765\n",
      "[epoch 009/010] step 50/1244 loss 0.5204\n",
      "[epoch 009/010] step 100/1244 loss 0.4540\n",
      "[epoch 009/010] step 150/1244 loss 0.4756\n",
      "[epoch 009/010] step 200/1244 loss 0.7286\n",
      "[epoch 009/010] step 250/1244 loss 0.5236\n",
      "[epoch 009/010] step 300/1244 loss 0.5512\n",
      "[epoch 009/010] step 350/1244 loss 0.7521\n",
      "[epoch 009/010] step 400/1244 loss 0.5322\n",
      "[epoch 009/010] step 450/1244 loss 0.5402\n",
      "[epoch 009/010] step 500/1244 loss 0.5528\n",
      "[epoch 009/010] step 550/1244 loss 0.7005\n",
      "[epoch 009/010] step 600/1244 loss 0.5797\n",
      "[epoch 009/010] step 650/1244 loss 0.4307\n",
      "[epoch 009/010] step 700/1244 loss 0.5928\n",
      "[epoch 009/010] step 750/1244 loss 0.4095\n",
      "[epoch 009/010] step 800/1244 loss 0.4449\n",
      "[epoch 009/010] step 850/1244 loss 0.4166\n",
      "[epoch 009/010] step 900/1244 loss 0.5793\n",
      "[epoch 009/010] step 950/1244 loss 0.5020\n",
      "[epoch 009/010] step 1000/1244 loss 0.6331\n",
      "[epoch 009/010] step 1050/1244 loss 0.4058\n",
      "[epoch 009/010] step 1100/1244 loss 0.4574\n",
      "[epoch 009/010] step 1150/1244 loss 0.4781\n",
      "[epoch 009/010] step 1200/1244 loss 0.4238\n",
      "[epoch 009/010] step 1244/1244 loss 0.5129\n",
      "epoch 009/010  train=0.4973  val=0.5916\n",
      "[epoch 010/010] step 50/1244 loss 0.4236\n",
      "[epoch 010/010] step 100/1244 loss 0.5463\n",
      "[epoch 010/010] step 150/1244 loss 0.3604\n",
      "[epoch 010/010] step 200/1244 loss 0.4002\n",
      "[epoch 010/010] step 250/1244 loss 0.3672\n",
      "[epoch 010/010] step 300/1244 loss 0.5717\n",
      "[epoch 010/010] step 350/1244 loss 0.5854\n",
      "[epoch 010/010] step 400/1244 loss 0.5770\n",
      "[epoch 010/010] step 450/1244 loss 0.4776\n",
      "[epoch 010/010] step 500/1244 loss 0.4786\n",
      "[epoch 010/010] step 550/1244 loss 0.5698\n",
      "[epoch 010/010] step 600/1244 loss 0.5610\n",
      "[epoch 010/010] step 650/1244 loss 0.4806\n",
      "[epoch 010/010] step 700/1244 loss 0.5669\n",
      "[epoch 010/010] step 750/1244 loss 0.4989\n",
      "[epoch 010/010] step 800/1244 loss 0.5608\n",
      "[epoch 010/010] step 850/1244 loss 0.5349\n",
      "[epoch 010/010] step 900/1244 loss 0.4758\n",
      "[epoch 010/010] step 950/1244 loss 0.4551\n",
      "[epoch 010/010] step 1000/1244 loss 0.5682\n",
      "[epoch 010/010] step 1050/1244 loss 0.8160\n",
      "[epoch 010/010] step 1100/1244 loss 0.5884\n",
      "[epoch 010/010] step 1150/1244 loss 0.6358\n",
      "[epoch 010/010] step 1200/1244 loss 0.5068\n",
      "[epoch 010/010] step 1244/1244 loss 0.5194\n",
      "epoch 010/010  train=0.4878  val=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/12 14:58:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conf = TrainConfig()\n",
    "conf.num_epochs = FINETUNE_EPOCHS\n",
    "conf.batch_size = BATCH_SIZE\n",
    "conf.num_workers = NUM_WORKERS\n",
    "conf.lr = LR_FINETUNE\n",
    "conf.weight_decay = WEIGHT_DECAY\n",
    "conf.momentum = MOMENTUM\n",
    "\n",
    "trainer = Trainer(model, conf)\n",
    "hist_ft = trainer.run(ab_train_loader, ab_val_loader, experiment_name=\"Att_FT2_Train6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98216c0-e163-42d0-b008-f8c66ada5810",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./weights/maskrcnn_attfpn_warmB_ft_Bmasks_Aboxes.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), \"./weights/maskrcnn_attfpn_warmB_ft_Bmasks_Aboxes.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
