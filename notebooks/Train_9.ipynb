{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71cdd8a-fc30-46d2-803c-b7ee6eb49cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b298fb1b-3194-4ffb-a389-5b4a6339e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from models.models import build_model     \n",
    "from datasets.loader import DataModule, DataConfig  \n",
    "from train.trainer_v2 import Trainer, TrainConfig  \n",
    "from train.eval import Evaluator             \n",
    "from datasets.base import collate_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991aa36b-ed88-41b8-885c-808b77f4962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///media/sdb1/mlflow\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = 1 + 24\n",
    "model_uri = \"file:///media/sdb1/mlflow/753485487056022103/a7b0ebbbad47442c841112c6bfb35e16/artifacts/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "def allow_missing_masks(model):\n",
    "    orig_forward = model.forward\n",
    "    def forward(images, targets=None):\n",
    "        if model.training and targets is not None and not all((\"masks\" in t) for t in targets):\n",
    "            rh = model.roi_heads\n",
    "            saved = (rh.mask_roi_pool, rh.mask_head, rh.mask_predictor)\n",
    "            try:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = None, None, None\n",
    "                return orig_forward(images, targets)\n",
    "            finally:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = saved\n",
    "        return orig_forward(images, targets)\n",
    "    model.forward = forward\n",
    "    return model\n",
    "model = allow_missing_masks(model)\n",
    "\n",
    "conf = TrainConfig.from_json(\"./train_9.json\")\n",
    "trainer = Trainer(model, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5203de-16bc-4bd5-8917-4f69b533ae68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infinite(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "class AlternatingLoader:\n",
    "    def __init__(self, loader_a, loader_b, steps=None, start=\"a\"):\n",
    "        self.a = loader_a\n",
    "        self.b = loader_b\n",
    "        self.steps = steps if steps is not None else 2 * max(len(loader_a), len(loader_b))\n",
    "        self.start = start\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        ia, ib = infinite(self.a), infinite(self.b)\n",
    "        for i in range(self.steps):\n",
    "            if (i % 2 == 0) == (self.start == \"a\"):\n",
    "                yield next(ia)\n",
    "            else:\n",
    "                yield next(ib)\n",
    "\n",
    "dm = DataModule(DataConfig(val_frac=0.1, batch_size=conf.batch_size, num_workers=conf.num_workers), with_masks = False)\n",
    "b_train_loader, b_val_loader = dm.make_loaders_b()\n",
    "\n",
    "a_train_loader = DataLoader(dm.ds_a_train, batch_size=conf.batch_size, shuffle=True, num_workers=conf.num_workers, collate_fn=collate_bb)\n",
    "a_val_loader   = DataLoader(dm.ds_a_val,   batch_size=conf.batch_size, shuffle=False, num_workers=conf.num_workers, collate_fn=collate_bb)\n",
    "\n",
    "mix_train = AlternatingLoader(a_train_loader, b_train_loader)\n",
    "mix_val   = AlternatingLoader(a_val_loader,   b_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f974f7-7f87-476b-aebb-9673010e8a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/19 06:01:58 INFO mlflow.tracking.fluent: Experiment with name 'Att_FT2_Train9' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/040] step 50/2250 loss 0.9260\n",
      "[epoch 001/040] step 100/2250 loss 0.5300\n",
      "[epoch 001/040] step 150/2250 loss 0.6465\n",
      "[epoch 001/040] step 200/2250 loss 0.4262\n",
      "[epoch 001/040] step 250/2250 loss 0.3665\n",
      "[epoch 001/040] step 300/2250 loss 0.3969\n",
      "[epoch 001/040] step 350/2250 loss 0.7200\n",
      "[epoch 001/040] step 400/2250 loss 0.6539\n",
      "[epoch 001/040] step 450/2250 loss 0.4258\n",
      "[epoch 001/040] step 500/2250 loss 0.4117\n",
      "[epoch 001/040] step 550/2250 loss 0.5626\n",
      "[epoch 001/040] step 600/2250 loss 0.3577\n",
      "[epoch 001/040] step 650/2250 loss 0.4470\n",
      "[epoch 001/040] step 700/2250 loss 0.3162\n",
      "[epoch 001/040] step 750/2250 loss 0.5005\n",
      "[epoch 001/040] step 800/2250 loss 0.4036\n",
      "[epoch 001/040] step 850/2250 loss 0.4890\n",
      "[epoch 001/040] step 900/2250 loss 0.6818\n",
      "[epoch 001/040] step 950/2250 loss 0.4634\n",
      "[epoch 001/040] step 1000/2250 loss 0.4617\n",
      "[epoch 001/040] step 1050/2250 loss 0.4653\n",
      "[epoch 001/040] step 1100/2250 loss 0.4600\n",
      "[epoch 001/040] step 1150/2250 loss 0.5563\n",
      "[epoch 001/040] step 1200/2250 loss 0.4922\n",
      "[epoch 001/040] step 1250/2250 loss 0.4620\n",
      "[epoch 001/040] step 1300/2250 loss 0.5688\n",
      "[epoch 001/040] step 1350/2250 loss 0.3257\n",
      "[epoch 001/040] step 1400/2250 loss 0.4611\n",
      "[epoch 001/040] step 1450/2250 loss 0.3932\n",
      "[epoch 001/040] step 1500/2250 loss 0.4613\n",
      "[epoch 001/040] step 1550/2250 loss 0.3705\n",
      "[epoch 001/040] step 1600/2250 loss 0.3916\n",
      "[epoch 001/040] step 1650/2250 loss 0.4068\n",
      "[epoch 001/040] step 1700/2250 loss 0.3627\n",
      "[epoch 001/040] step 1750/2250 loss 0.4544\n",
      "[epoch 001/040] step 1800/2250 loss 0.3977\n",
      "[epoch 001/040] step 1850/2250 loss 0.4966\n",
      "[epoch 001/040] step 1900/2250 loss 0.4226\n",
      "[epoch 001/040] step 1950/2250 loss 0.4433\n",
      "[epoch 001/040] step 2000/2250 loss 0.3820\n",
      "[epoch 001/040] step 2050/2250 loss 0.3595\n",
      "[epoch 001/040] step 2100/2250 loss 0.3494\n",
      "[epoch 001/040] step 2150/2250 loss 0.6073\n",
      "[epoch 001/040] step 2200/2250 loss 0.3949\n",
      "[epoch 001/040] step 2250/2250 loss 0.3370\n",
      "[epoch 001/040] train=0.4707  val=0.4758  lr=0.00499757\n",
      "[epoch 002/040] step 50/2250 loss 0.4888\n",
      "[epoch 002/040] step 100/2250 loss 0.3949\n",
      "[epoch 002/040] step 150/2250 loss 0.3821\n",
      "[epoch 002/040] step 200/2250 loss 0.5103\n",
      "[epoch 002/040] step 250/2250 loss 0.5543\n",
      "[epoch 002/040] step 300/2250 loss 0.3921\n",
      "[epoch 002/040] step 350/2250 loss 0.4370\n",
      "[epoch 002/040] step 400/2250 loss 0.5132\n",
      "[epoch 002/040] step 450/2250 loss 0.3859\n",
      "[epoch 002/040] step 500/2250 loss 0.4852\n",
      "[epoch 002/040] step 550/2250 loss 0.3722\n",
      "[epoch 002/040] step 600/2250 loss 0.4203\n",
      "[epoch 002/040] step 650/2250 loss 0.5315\n",
      "[epoch 002/040] step 700/2250 loss 0.5574\n",
      "[epoch 002/040] step 750/2250 loss 0.3662\n",
      "[epoch 002/040] step 800/2250 loss 0.3740\n",
      "[epoch 002/040] step 850/2250 loss 0.3148\n",
      "[epoch 002/040] step 900/2250 loss 0.4043\n",
      "[epoch 002/040] step 950/2250 loss 0.3342\n",
      "[epoch 002/040] step 1000/2250 loss 0.4553\n",
      "[epoch 002/040] step 1050/2250 loss 0.4859\n",
      "[epoch 002/040] step 1100/2250 loss 0.3493\n",
      "[epoch 002/040] step 1150/2250 loss 0.4010\n",
      "[epoch 002/040] step 1200/2250 loss 0.3816\n",
      "[epoch 002/040] step 1250/2250 loss 0.4153\n",
      "[epoch 002/040] step 1300/2250 loss 0.4400\n",
      "[epoch 002/040] step 1350/2250 loss 0.4737\n",
      "[epoch 002/040] step 1400/2250 loss 0.4251\n",
      "[epoch 002/040] step 1450/2250 loss 0.3461\n",
      "[epoch 002/040] step 1500/2250 loss 0.4136\n",
      "[epoch 002/040] step 1550/2250 loss 0.3361\n",
      "[epoch 002/040] step 1600/2250 loss 0.4356\n",
      "[epoch 002/040] step 1650/2250 loss 0.4387\n",
      "[epoch 002/040] step 1700/2250 loss 0.3720\n",
      "[epoch 002/040] step 1750/2250 loss 0.3671\n",
      "[epoch 002/040] step 1800/2250 loss 0.4260\n",
      "[epoch 002/040] step 1850/2250 loss 0.4104\n",
      "[epoch 002/040] step 1900/2250 loss 0.3842\n",
      "[epoch 002/040] step 1950/2250 loss 0.5521\n",
      "[epoch 002/040] step 2000/2250 loss 0.5156\n",
      "[epoch 002/040] step 2050/2250 loss 0.3935\n",
      "[epoch 002/040] step 2100/2250 loss 0.4167\n",
      "[epoch 002/040] step 2150/2250 loss 0.3363\n",
      "[epoch 002/040] step 2200/2250 loss 0.4856\n",
      "[epoch 002/040] step 2250/2250 loss 0.4018\n",
      "[epoch 002/040] train=0.4457  val=0.4674  lr=0.00498095\n",
      "[epoch 003/040] step 50/2250 loss 0.3579\n",
      "[epoch 003/040] step 100/2250 loss 0.3971\n",
      "[epoch 003/040] step 150/2250 loss 0.4201\n",
      "[epoch 003/040] step 200/2250 loss 0.4320\n",
      "[epoch 003/040] step 250/2250 loss 0.5415\n",
      "[epoch 003/040] step 300/2250 loss 0.3566\n",
      "[epoch 003/040] step 350/2250 loss 0.3579\n",
      "[epoch 003/040] step 400/2250 loss 0.4677\n",
      "[epoch 003/040] step 450/2250 loss 0.3406\n",
      "[epoch 003/040] step 500/2250 loss 0.5617\n",
      "[epoch 003/040] step 550/2250 loss 0.3343\n",
      "[epoch 003/040] step 600/2250 loss 0.3681\n",
      "[epoch 003/040] step 650/2250 loss 0.3516\n",
      "[epoch 003/040] step 700/2250 loss 0.5129\n",
      "[epoch 003/040] step 750/2250 loss 0.4345\n",
      "[epoch 003/040] step 800/2250 loss 0.7143\n",
      "[epoch 003/040] step 850/2250 loss 0.3840\n",
      "[epoch 003/040] step 900/2250 loss 0.5810\n",
      "[epoch 003/040] step 950/2250 loss 0.3684\n",
      "[epoch 003/040] step 1000/2250 loss 0.3998\n",
      "[epoch 003/040] step 1050/2250 loss 0.5444\n",
      "[epoch 003/040] step 1100/2250 loss 0.4081\n",
      "[epoch 003/040] step 1150/2250 loss 0.4271\n",
      "[epoch 003/040] step 1200/2250 loss 0.4507\n",
      "[epoch 003/040] step 1250/2250 loss 0.4348\n",
      "[epoch 003/040] step 1300/2250 loss 0.4446\n",
      "[epoch 003/040] step 1350/2250 loss 0.4580\n",
      "[epoch 003/040] step 1400/2250 loss 0.3832\n",
      "[epoch 003/040] step 1450/2250 loss 0.3644\n",
      "[epoch 003/040] step 1500/2250 loss 0.5459\n",
      "[epoch 003/040] step 1550/2250 loss 0.4316\n",
      "[epoch 003/040] step 1600/2250 loss 0.3455\n",
      "[epoch 003/040] step 1650/2250 loss 0.4041\n",
      "[epoch 003/040] step 1700/2250 loss 0.4008\n",
      "[epoch 003/040] step 1750/2250 loss 0.4524\n",
      "[epoch 003/040] step 1800/2250 loss 0.4429\n",
      "[epoch 003/040] step 1850/2250 loss 0.3789\n",
      "[epoch 003/040] step 1900/2250 loss 0.4272\n",
      "[epoch 003/040] step 1950/2250 loss 0.3820\n",
      "[epoch 003/040] step 2000/2250 loss 0.3892\n",
      "[epoch 003/040] step 2050/2250 loss 0.4172\n",
      "[epoch 003/040] step 2100/2250 loss 0.5437\n",
      "[epoch 003/040] step 2150/2250 loss 0.4141\n",
      "[epoch 003/040] step 2200/2250 loss 0.3848\n",
      "[epoch 003/040] step 2250/2250 loss 0.3473\n",
      "[epoch 003/040] train=0.4393  val=0.4587  lr=0.00494869\n",
      "[epoch 004/040] step 50/2250 loss 0.5158\n",
      "[epoch 004/040] step 100/2250 loss 0.3850\n",
      "[epoch 004/040] step 150/2250 loss 0.3429\n",
      "[epoch 004/040] step 200/2250 loss 0.5373\n",
      "[epoch 004/040] step 250/2250 loss 0.4289\n",
      "[epoch 004/040] step 300/2250 loss 0.4200\n",
      "[epoch 004/040] step 350/2250 loss 0.3420\n",
      "[epoch 004/040] step 400/2250 loss 0.3761\n",
      "[epoch 004/040] step 450/2250 loss 0.3699\n",
      "[epoch 004/040] step 500/2250 loss 0.4103\n",
      "[epoch 004/040] step 550/2250 loss 0.3786\n",
      "[epoch 004/040] step 600/2250 loss 0.3849\n",
      "[epoch 004/040] step 650/2250 loss 0.4048\n",
      "[epoch 004/040] step 700/2250 loss 0.4698\n",
      "[epoch 004/040] step 750/2250 loss 0.3485\n",
      "[epoch 004/040] step 800/2250 loss 0.3678\n",
      "[epoch 004/040] step 850/2250 loss 0.5362\n",
      "[epoch 004/040] step 900/2250 loss 0.3628\n",
      "[epoch 004/040] step 950/2250 loss 0.4404\n",
      "[epoch 004/040] step 1000/2250 loss 0.3928\n",
      "[epoch 004/040] step 1050/2250 loss 0.3898\n",
      "[epoch 004/040] step 1100/2250 loss 0.5262\n",
      "[epoch 004/040] step 1150/2250 loss 0.5217\n",
      "[epoch 004/040] step 1200/2250 loss 0.4264\n",
      "[epoch 004/040] step 1250/2250 loss 0.3224\n",
      "[epoch 004/040] step 1300/2250 loss 0.3839\n",
      "[epoch 004/040] step 1350/2250 loss 0.4074\n",
      "[epoch 004/040] step 1400/2250 loss 0.4427\n",
      "[epoch 004/040] step 1450/2250 loss 0.3454\n",
      "[epoch 004/040] step 1500/2250 loss 0.3630\n",
      "[epoch 004/040] step 1550/2250 loss 0.3566\n",
      "[epoch 004/040] step 1600/2250 loss 0.4680\n",
      "[epoch 004/040] step 1650/2250 loss 0.4454\n",
      "[epoch 004/040] step 1700/2250 loss 0.4457\n",
      "[epoch 004/040] step 1750/2250 loss 0.3766\n",
      "[epoch 004/040] step 1800/2250 loss 0.2566\n",
      "[epoch 004/040] step 1850/2250 loss 0.3432\n",
      "[epoch 004/040] step 1900/2250 loss 0.3711\n",
      "[epoch 004/040] step 1950/2250 loss 0.3943\n",
      "[epoch 004/040] step 2000/2250 loss 0.4013\n",
      "[epoch 004/040] step 2050/2250 loss 0.2974\n",
      "[epoch 004/040] step 2100/2250 loss 0.4813\n",
      "[epoch 004/040] step 2150/2250 loss 0.4220\n",
      "[epoch 004/040] step 2200/2250 loss 0.3145\n",
      "[epoch 004/040] step 2250/2250 loss 0.4083\n",
      "[epoch 004/040] train=0.4269  val=0.4528  lr=0.004901\n",
      "[epoch 005/040] step 50/2250 loss 0.3454\n",
      "[epoch 005/040] step 100/2250 loss 0.3097\n",
      "[epoch 005/040] step 150/2250 loss 0.3729\n",
      "[epoch 005/040] step 200/2250 loss 0.4194\n",
      "[epoch 005/040] step 250/2250 loss 0.3751\n",
      "[epoch 005/040] step 300/2250 loss 0.3535\n",
      "[epoch 005/040] step 350/2250 loss 0.3895\n",
      "[epoch 005/040] step 400/2250 loss 0.3938\n",
      "[epoch 005/040] step 450/2250 loss 0.4554\n",
      "[epoch 005/040] step 500/2250 loss 0.4706\n",
      "[epoch 005/040] step 550/2250 loss 0.4050\n",
      "[epoch 005/040] step 600/2250 loss 0.4185\n",
      "[epoch 005/040] step 650/2250 loss 0.2982\n",
      "[epoch 005/040] step 700/2250 loss 0.3861\n",
      "[epoch 005/040] step 750/2250 loss 0.3794\n",
      "[epoch 005/040] step 800/2250 loss 0.3839\n",
      "[epoch 005/040] step 850/2250 loss 0.3801\n",
      "[epoch 005/040] step 900/2250 loss 0.3487\n",
      "[epoch 005/040] step 950/2250 loss 0.3920\n",
      "[epoch 005/040] step 1000/2250 loss 0.3887\n",
      "[epoch 005/040] step 1050/2250 loss 0.3421\n",
      "[epoch 005/040] step 1100/2250 loss 0.3918\n",
      "[epoch 005/040] step 1150/2250 loss 0.4480\n",
      "[epoch 005/040] step 1200/2250 loss 0.4455\n",
      "[epoch 005/040] step 1250/2250 loss 0.3701\n",
      "[epoch 005/040] step 1300/2250 loss 0.3874\n",
      "[epoch 005/040] step 1350/2250 loss 0.3453\n",
      "[epoch 005/040] step 1400/2250 loss 0.3858\n",
      "[epoch 005/040] step 1450/2250 loss 0.4272\n",
      "[epoch 005/040] step 1500/2250 loss 0.3949\n",
      "[epoch 005/040] step 1550/2250 loss 0.3780\n",
      "[epoch 005/040] step 1600/2250 loss 0.4158\n",
      "[epoch 005/040] step 1650/2250 loss 0.3444\n",
      "[epoch 005/040] step 1700/2250 loss 0.4110\n",
      "[epoch 005/040] step 1750/2250 loss 0.3530\n",
      "[epoch 005/040] step 1800/2250 loss 0.2802\n",
      "[epoch 005/040] step 1850/2250 loss 0.4171\n",
      "[epoch 005/040] step 1900/2250 loss 0.3110\n",
      "[epoch 005/040] step 1950/2250 loss 0.3580\n",
      "[epoch 005/040] step 2000/2250 loss 0.3094\n",
      "[epoch 005/040] step 2050/2250 loss 0.3715\n",
      "[epoch 005/040] step 2100/2250 loss 0.3394\n",
      "[epoch 005/040] step 2150/2250 loss 0.4910\n",
      "[epoch 005/040] step 2200/2250 loss 0.4025\n",
      "[epoch 005/040] step 2250/2250 loss 0.4025\n",
      "[epoch 005/040] train=0.4178  val=0.4472  lr=0.00483817\n",
      "[epoch 006/040] step 50/2250 loss 0.4362\n",
      "[epoch 006/040] step 100/2250 loss 0.3441\n",
      "[epoch 006/040] step 150/2250 loss 0.3803\n",
      "[epoch 006/040] step 200/2250 loss 0.4025\n",
      "[epoch 006/040] step 250/2250 loss 0.4002\n",
      "[epoch 006/040] step 300/2250 loss 0.3718\n",
      "[epoch 006/040] step 350/2250 loss 0.3695\n",
      "[epoch 006/040] step 400/2250 loss 0.3601\n",
      "[epoch 006/040] step 450/2250 loss 0.3730\n",
      "[epoch 006/040] step 500/2250 loss 0.4044\n",
      "[epoch 006/040] step 550/2250 loss 0.3376\n",
      "[epoch 006/040] step 600/2250 loss 0.4716\n",
      "[epoch 006/040] step 650/2250 loss 0.3453\n",
      "[epoch 006/040] step 700/2250 loss 0.4401\n",
      "[epoch 006/040] step 750/2250 loss 0.3503\n",
      "[epoch 006/040] step 800/2250 loss 0.3963\n",
      "[epoch 006/040] step 850/2250 loss 0.3810\n",
      "[epoch 006/040] step 900/2250 loss 0.3593\n",
      "[epoch 006/040] step 950/2250 loss 0.3886\n",
      "[epoch 006/040] step 1000/2250 loss 0.3614\n",
      "[epoch 006/040] step 1050/2250 loss 0.3857\n",
      "[epoch 006/040] step 1100/2250 loss 0.4116\n",
      "[epoch 006/040] step 1150/2250 loss 0.3200\n",
      "[epoch 006/040] step 1200/2250 loss 0.4524\n",
      "[epoch 006/040] step 1250/2250 loss 0.4299\n",
      "[epoch 006/040] step 1300/2250 loss 0.3794\n",
      "[epoch 006/040] step 1350/2250 loss 0.3195\n",
      "[epoch 006/040] step 1400/2250 loss 0.3454\n",
      "[epoch 006/040] step 1450/2250 loss 0.3980\n",
      "[epoch 006/040] step 1500/2250 loss 0.3646\n",
      "[epoch 006/040] step 1550/2250 loss 0.4370\n",
      "[epoch 006/040] step 1600/2250 loss 0.3900\n",
      "[epoch 006/040] step 1650/2250 loss 0.4256\n",
      "[epoch 006/040] step 1700/2250 loss 0.3600\n",
      "[epoch 006/040] step 1750/2250 loss 0.3743\n",
      "[epoch 006/040] step 1800/2250 loss 0.4726\n",
      "[epoch 006/040] step 1850/2250 loss 0.3241\n",
      "[epoch 006/040] step 1900/2250 loss 0.3023\n",
      "[epoch 006/040] step 1950/2250 loss 0.4244\n",
      "[epoch 006/040] step 2000/2250 loss 0.4285\n",
      "[epoch 006/040] step 2050/2250 loss 0.4673\n",
      "[epoch 006/040] step 2100/2250 loss 0.3749\n",
      "[epoch 006/040] step 2150/2250 loss 0.3276\n",
      "[epoch 006/040] step 2200/2250 loss 0.3752\n",
      "[epoch 006/040] step 2250/2250 loss 0.3955\n",
      "[epoch 006/040] train=0.4099  val=0.4432  lr=0.00476061\n",
      "[epoch 007/040] step 50/2250 loss 0.3944\n",
      "[epoch 007/040] step 100/2250 loss 0.4561\n",
      "[epoch 007/040] step 150/2250 loss 0.3227\n",
      "[epoch 007/040] step 200/2250 loss 0.3860\n",
      "[epoch 007/040] step 250/2250 loss 0.3306\n",
      "[epoch 007/040] step 300/2250 loss 0.3943\n",
      "[epoch 007/040] step 350/2250 loss 0.5097\n",
      "[epoch 007/040] step 400/2250 loss 0.4765\n",
      "[epoch 007/040] step 450/2250 loss 0.3374\n",
      "[epoch 007/040] step 500/2250 loss 0.2907\n",
      "[epoch 007/040] step 550/2250 loss 0.3781\n",
      "[epoch 007/040] step 600/2250 loss 0.3701\n",
      "[epoch 007/040] step 650/2250 loss 0.3636\n",
      "[epoch 007/040] step 700/2250 loss 0.3940\n",
      "[epoch 007/040] step 750/2250 loss 0.3769\n",
      "[epoch 007/040] step 800/2250 loss 0.3779\n",
      "[epoch 007/040] step 850/2250 loss 0.4235\n",
      "[epoch 007/040] step 900/2250 loss 0.3511\n",
      "[epoch 007/040] step 950/2250 loss 0.3609\n",
      "[epoch 007/040] step 1000/2250 loss 0.3403\n",
      "[epoch 007/040] step 1050/2250 loss 0.4332\n",
      "[epoch 007/040] step 1100/2250 loss 0.4416\n",
      "[epoch 007/040] step 1150/2250 loss 0.3472\n",
      "[epoch 007/040] step 1200/2250 loss 0.4107\n",
      "[epoch 007/040] step 1250/2250 loss 0.3005\n",
      "[epoch 007/040] step 1300/2250 loss 0.3059\n",
      "[epoch 007/040] step 1350/2250 loss 0.5092\n",
      "[epoch 007/040] step 1400/2250 loss 0.4235\n",
      "[epoch 007/040] step 1450/2250 loss 0.2844\n",
      "[epoch 007/040] step 1500/2250 loss 0.3396\n",
      "[epoch 007/040] step 1550/2250 loss 0.3661\n",
      "[epoch 007/040] step 1600/2250 loss 0.3285\n",
      "[epoch 007/040] step 1650/2250 loss 0.3832\n",
      "[epoch 007/040] step 1700/2250 loss 0.3900\n",
      "[epoch 007/040] step 1750/2250 loss 0.3539\n",
      "[epoch 007/040] step 1800/2250 loss 0.3516\n",
      "[epoch 007/040] step 1850/2250 loss 0.4331\n",
      "[epoch 007/040] step 1900/2250 loss 0.4057\n",
      "[epoch 007/040] step 1950/2250 loss 0.3733\n",
      "[epoch 007/040] step 2000/2250 loss 0.3866\n",
      "[epoch 007/040] step 2050/2250 loss 0.3358\n",
      "[epoch 007/040] step 2100/2250 loss 0.4334\n",
      "[epoch 007/040] step 2150/2250 loss 0.4034\n",
      "[epoch 007/040] step 2200/2250 loss 0.3346\n",
      "[epoch 007/040] step 2250/2250 loss 0.3079\n",
      "[epoch 007/040] train=0.4008  val=0.4408  lr=0.0046688\n",
      "[epoch 008/040] step 50/2250 loss 0.3890\n",
      "[epoch 008/040] step 100/2250 loss 0.4085\n",
      "[epoch 008/040] step 150/2250 loss 0.3413\n",
      "[epoch 008/040] step 200/2250 loss 0.3910\n",
      "[epoch 008/040] step 250/2250 loss 0.4044\n",
      "[epoch 008/040] step 300/2250 loss 0.4149\n",
      "[epoch 008/040] step 350/2250 loss 0.3507\n",
      "[epoch 008/040] step 400/2250 loss 0.3482\n",
      "[epoch 008/040] step 450/2250 loss 0.3201\n",
      "[epoch 008/040] step 500/2250 loss 0.3612\n",
      "[epoch 008/040] step 550/2250 loss 0.4091\n",
      "[epoch 008/040] step 600/2250 loss 0.3382\n",
      "[epoch 008/040] step 650/2250 loss 0.3749\n",
      "[epoch 008/040] step 700/2250 loss 0.3800\n",
      "[epoch 008/040] step 750/2250 loss 0.4163\n",
      "[epoch 008/040] step 800/2250 loss 0.3782\n",
      "[epoch 008/040] step 850/2250 loss 0.3440\n",
      "[epoch 008/040] step 900/2250 loss 0.3884\n",
      "[epoch 008/040] step 950/2250 loss 0.3218\n",
      "[epoch 008/040] step 1000/2250 loss 0.3430\n",
      "[epoch 008/040] step 1050/2250 loss 0.4458\n",
      "[epoch 008/040] step 1100/2250 loss 0.3661\n",
      "[epoch 008/040] step 1150/2250 loss 0.3950\n",
      "[epoch 008/040] step 1200/2250 loss 0.3078\n",
      "[epoch 008/040] step 1250/2250 loss 0.4979\n",
      "[epoch 008/040] step 1300/2250 loss 0.3530\n",
      "[epoch 008/040] step 1350/2250 loss 0.3826\n",
      "[epoch 008/040] step 1400/2250 loss 0.3925\n",
      "[epoch 008/040] step 1450/2250 loss 0.3634\n",
      "[epoch 008/040] step 1500/2250 loss 0.3692\n",
      "[epoch 008/040] step 1550/2250 loss 0.4255\n",
      "[epoch 008/040] step 1600/2250 loss 0.3010\n",
      "[epoch 008/040] step 1650/2250 loss 0.4122\n",
      "[epoch 008/040] step 1700/2250 loss 0.3272\n",
      "[epoch 008/040] step 1750/2250 loss 0.2991\n",
      "[epoch 008/040] step 1800/2250 loss 0.4347\n",
      "[epoch 008/040] step 1850/2250 loss 0.3478\n",
      "[epoch 008/040] step 1900/2250 loss 0.4709\n",
      "[epoch 008/040] step 1950/2250 loss 0.3840\n",
      "[epoch 008/040] step 2000/2250 loss 0.5171\n",
      "[epoch 008/040] step 2050/2250 loss 0.3709\n",
      "[epoch 008/040] step 2100/2250 loss 0.3400\n",
      "[epoch 008/040] step 2150/2250 loss 0.4105\n",
      "[epoch 008/040] step 2200/2250 loss 0.3280\n",
      "[epoch 008/040] step 2250/2250 loss 0.3906\n",
      "[epoch 008/040] train=0.3975  val=0.4368  lr=0.00456331\n",
      "[epoch 009/040] step 50/2250 loss 0.4642\n",
      "[epoch 009/040] step 100/2250 loss 0.4741\n",
      "[epoch 009/040] step 150/2250 loss 0.4469\n",
      "[epoch 009/040] step 200/2250 loss 0.4325\n",
      "[epoch 009/040] step 250/2250 loss 0.3173\n",
      "[epoch 009/040] step 300/2250 loss 0.3580\n",
      "[epoch 009/040] step 350/2250 loss 0.3966\n",
      "[epoch 009/040] step 400/2250 loss 0.3110\n",
      "[epoch 009/040] step 450/2250 loss 0.4399\n",
      "[epoch 009/040] step 500/2250 loss 0.4619\n",
      "[epoch 009/040] step 550/2250 loss 0.4339\n",
      "[epoch 009/040] step 600/2250 loss 0.4663\n",
      "[epoch 009/040] step 650/2250 loss 0.2643\n",
      "[epoch 009/040] step 700/2250 loss 0.3749\n",
      "[epoch 009/040] step 750/2250 loss 0.3692\n",
      "[epoch 009/040] step 800/2250 loss 0.3339\n",
      "[epoch 009/040] step 850/2250 loss 0.3999\n",
      "[epoch 009/040] step 900/2250 loss 0.3463\n",
      "[epoch 009/040] step 950/2250 loss 0.3438\n",
      "[epoch 009/040] step 1000/2250 loss 0.3349\n",
      "[epoch 009/040] step 1050/2250 loss 0.4233\n",
      "[epoch 009/040] step 1100/2250 loss 0.3677\n",
      "[epoch 009/040] step 1150/2250 loss 0.4047\n",
      "[epoch 009/040] step 1200/2250 loss 0.3150\n",
      "[epoch 009/040] step 1250/2250 loss 0.3167\n",
      "[epoch 009/040] step 1300/2250 loss 0.3669\n",
      "[epoch 009/040] step 1350/2250 loss 0.4931\n",
      "[epoch 009/040] step 1400/2250 loss 0.3109\n",
      "[epoch 009/040] step 1450/2250 loss 0.3718\n",
      "[epoch 009/040] step 1500/2250 loss 0.3630\n",
      "[epoch 009/040] step 1550/2250 loss 0.4018\n",
      "[epoch 009/040] step 1600/2250 loss 0.4862\n",
      "[epoch 009/040] step 1650/2250 loss 0.4100\n",
      "[epoch 009/040] step 1700/2250 loss 0.3555\n",
      "[epoch 009/040] step 1750/2250 loss 0.3983\n",
      "[epoch 009/040] step 1800/2250 loss 0.4553\n",
      "[epoch 009/040] step 1850/2250 loss 0.3382\n",
      "[epoch 009/040] step 1900/2250 loss 0.4020\n",
      "[epoch 009/040] step 1950/2250 loss 0.3196\n",
      "[epoch 009/040] step 2000/2250 loss 0.4455\n",
      "[epoch 009/040] step 2050/2250 loss 0.3769\n",
      "[epoch 009/040] step 2100/2250 loss 0.4131\n",
      "[epoch 009/040] step 2150/2250 loss 0.3031\n",
      "[epoch 009/040] step 2200/2250 loss 0.3044\n",
      "[epoch 009/040] step 2250/2250 loss 0.3601\n",
      "[epoch 009/040] train=0.3907  val=0.4329  lr=0.00444483\n",
      "[epoch 010/040] step 50/2250 loss 0.3839\n",
      "[epoch 010/040] step 100/2250 loss 0.3243\n",
      "[epoch 010/040] step 150/2250 loss 0.3896\n",
      "[epoch 010/040] step 200/2250 loss 0.3819\n",
      "[epoch 010/040] step 250/2250 loss 0.3144\n",
      "[epoch 010/040] step 300/2250 loss 0.3212\n",
      "[epoch 010/040] step 350/2250 loss 0.3597\n",
      "[epoch 010/040] step 400/2250 loss 0.3783\n",
      "[epoch 010/040] step 450/2250 loss 0.3143\n",
      "[epoch 010/040] step 500/2250 loss 0.3369\n",
      "[epoch 010/040] step 550/2250 loss 0.4365\n",
      "[epoch 010/040] step 600/2250 loss 0.3943\n",
      "[epoch 010/040] step 650/2250 loss 0.3726\n",
      "[epoch 010/040] step 700/2250 loss 0.4054\n",
      "[epoch 010/040] step 750/2250 loss 0.2685\n",
      "[epoch 010/040] step 800/2250 loss 0.4034\n",
      "[epoch 010/040] step 850/2250 loss 0.3975\n",
      "[epoch 010/040] step 900/2250 loss 0.3911\n",
      "[epoch 010/040] step 950/2250 loss 0.4136\n",
      "[epoch 010/040] step 1000/2250 loss 0.4025\n",
      "[epoch 010/040] step 1050/2250 loss 0.3186\n",
      "[epoch 010/040] step 1100/2250 loss 0.3902\n",
      "[epoch 010/040] step 1150/2250 loss 0.3983\n",
      "[epoch 010/040] step 1200/2250 loss 0.4418\n",
      "[epoch 010/040] step 1250/2250 loss 0.3680\n",
      "[epoch 010/040] step 1300/2250 loss 0.4291\n",
      "[epoch 010/040] step 1350/2250 loss 0.3776\n",
      "[epoch 010/040] step 1400/2250 loss 0.4123\n",
      "[epoch 010/040] step 1450/2250 loss 0.3896\n",
      "[epoch 010/040] step 1500/2250 loss 0.3648\n",
      "[epoch 010/040] step 1550/2250 loss 0.3533\n",
      "[epoch 010/040] step 1600/2250 loss 0.3893\n",
      "[epoch 010/040] step 1650/2250 loss 0.3083\n",
      "[epoch 010/040] step 1700/2250 loss 0.3409\n",
      "[epoch 010/040] step 1750/2250 loss 0.3183\n",
      "[epoch 010/040] step 1800/2250 loss 0.3174\n",
      "[epoch 010/040] step 1850/2250 loss 0.4110\n",
      "[epoch 010/040] step 1900/2250 loss 0.3313\n",
      "[epoch 010/040] step 1950/2250 loss 0.4134\n",
      "[epoch 010/040] step 2000/2250 loss 0.4084\n",
      "[epoch 010/040] step 2050/2250 loss 0.3486\n",
      "[epoch 010/040] step 2100/2250 loss 0.3957\n",
      "[epoch 010/040] step 2150/2250 loss 0.3465\n",
      "[epoch 010/040] step 2200/2250 loss 0.3721\n",
      "[epoch 010/040] step 2250/2250 loss 0.3536\n",
      "[epoch 010/040] train=0.3856  val=0.4303  lr=0.00431408\n",
      "[epoch 011/040] step 50/2250 loss 0.3705\n",
      "[epoch 011/040] step 100/2250 loss 0.3411\n",
      "[epoch 011/040] step 150/2250 loss 0.3907\n",
      "[epoch 011/040] step 200/2250 loss 0.3687\n",
      "[epoch 011/040] step 250/2250 loss 0.3591\n",
      "[epoch 011/040] step 300/2250 loss 0.4553\n",
      "[epoch 011/040] step 350/2250 loss 0.3487\n",
      "[epoch 011/040] step 400/2250 loss 0.4805\n",
      "[epoch 011/040] step 450/2250 loss 0.4134\n",
      "[epoch 011/040] step 500/2250 loss 0.3378\n",
      "[epoch 011/040] step 550/2250 loss 0.3170\n",
      "[epoch 011/040] step 600/2250 loss 0.3582\n",
      "[epoch 011/040] step 650/2250 loss 0.3515\n",
      "[epoch 011/040] step 700/2250 loss 0.4416\n",
      "[epoch 011/040] step 750/2250 loss 0.3277\n",
      "[epoch 011/040] step 800/2250 loss 0.3027\n",
      "[epoch 011/040] step 850/2250 loss 0.4377\n",
      "[epoch 011/040] step 900/2250 loss 0.3336\n",
      "[epoch 011/040] step 950/2250 loss 0.3616\n",
      "[epoch 011/040] step 1000/2250 loss 0.4354\n",
      "[epoch 011/040] step 1050/2250 loss 0.3453\n",
      "[epoch 011/040] step 1100/2250 loss 0.3320\n",
      "[epoch 011/040] step 1150/2250 loss 0.3700\n",
      "[epoch 011/040] step 1200/2250 loss 0.4848\n",
      "[epoch 011/040] step 1250/2250 loss 0.3027\n",
      "[epoch 011/040] step 1300/2250 loss 0.4596\n",
      "[epoch 011/040] step 1350/2250 loss 0.3358\n",
      "[epoch 011/040] step 1400/2250 loss 0.2624\n",
      "[epoch 011/040] step 1450/2250 loss 0.3394\n",
      "[epoch 011/040] step 1500/2250 loss 0.2923\n",
      "[epoch 011/040] step 1550/2250 loss 0.3404\n",
      "[epoch 011/040] step 1600/2250 loss 0.4394\n",
      "[epoch 011/040] step 1650/2250 loss 0.3179\n",
      "[epoch 011/040] step 1700/2250 loss 0.3902\n",
      "[epoch 011/040] step 1750/2250 loss 0.3271\n",
      "[epoch 011/040] step 1800/2250 loss 0.3299\n",
      "[epoch 011/040] step 1850/2250 loss 0.4063\n",
      "[epoch 011/040] step 1900/2250 loss 0.3527\n",
      "[epoch 011/040] step 1950/2250 loss 0.3514\n",
      "[epoch 011/040] step 2000/2250 loss 0.3717\n",
      "[epoch 011/040] step 2050/2250 loss 0.3501\n",
      "[epoch 011/040] step 2100/2250 loss 0.3863\n",
      "[epoch 011/040] step 2150/2250 loss 0.3587\n",
      "[epoch 011/040] step 2200/2250 loss 0.3529\n",
      "[epoch 011/040] step 2250/2250 loss 0.3428\n",
      "[epoch 011/040] train=0.3792  val=0.4302  lr=0.0041719\n",
      "[epoch 012/040] step 50/2250 loss 0.3804\n",
      "[epoch 012/040] step 100/2250 loss 0.3427\n",
      "[epoch 012/040] step 150/2250 loss 0.4273\n",
      "[epoch 012/040] step 200/2250 loss 0.4416\n",
      "[epoch 012/040] step 250/2250 loss 0.2449\n",
      "[epoch 012/040] step 300/2250 loss 0.3915\n",
      "[epoch 012/040] step 350/2250 loss 0.3677\n",
      "[epoch 012/040] step 400/2250 loss 0.3671\n",
      "[epoch 012/040] step 450/2250 loss 0.3928\n",
      "[epoch 012/040] step 500/2250 loss 0.2796\n",
      "[epoch 012/040] step 550/2250 loss 0.4168\n",
      "[epoch 012/040] step 600/2250 loss 0.2876\n",
      "[epoch 012/040] step 650/2250 loss 0.2927\n",
      "[epoch 012/040] step 700/2250 loss 0.3135\n",
      "[epoch 012/040] step 750/2250 loss 0.3283\n",
      "[epoch 012/040] step 800/2250 loss 0.3779\n",
      "[epoch 012/040] step 850/2250 loss 0.3131\n",
      "[epoch 012/040] step 900/2250 loss 0.3608\n",
      "[epoch 012/040] step 950/2250 loss 0.4054\n",
      "[epoch 012/040] step 1000/2250 loss 0.3281\n",
      "[epoch 012/040] step 1050/2250 loss 0.3036\n",
      "[epoch 012/040] step 1100/2250 loss 0.2993\n",
      "[epoch 012/040] step 1150/2250 loss 0.3369\n",
      "[epoch 012/040] step 1200/2250 loss 0.3221\n",
      "[epoch 012/040] step 1250/2250 loss 0.2914\n",
      "[epoch 012/040] step 1300/2250 loss 0.3263\n",
      "[epoch 012/040] step 1350/2250 loss 0.4149\n",
      "[epoch 012/040] step 1400/2250 loss 0.3692\n",
      "[epoch 012/040] step 1450/2250 loss 0.3426\n",
      "[epoch 012/040] step 1500/2250 loss 0.3389\n",
      "[epoch 012/040] step 1550/2250 loss 0.3935\n",
      "[epoch 012/040] step 1600/2250 loss 0.3705\n",
      "[epoch 012/040] step 1650/2250 loss 0.2951\n",
      "[epoch 012/040] step 1700/2250 loss 0.3427\n",
      "[epoch 012/040] step 1750/2250 loss 0.3902\n",
      "[epoch 012/040] step 1800/2250 loss 0.4134\n",
      "[epoch 012/040] step 1850/2250 loss 0.3483\n",
      "[epoch 012/040] step 1900/2250 loss 0.3892\n",
      "[epoch 012/040] step 1950/2250 loss 0.4026\n",
      "[epoch 012/040] step 2000/2250 loss 0.4135\n",
      "[epoch 012/040] step 2050/2250 loss 0.4066\n",
      "[epoch 012/040] step 2100/2250 loss 0.3753\n",
      "[epoch 012/040] step 2150/2250 loss 0.3063\n",
      "[epoch 012/040] step 2200/2250 loss 0.3236\n",
      "[epoch 012/040] step 2250/2250 loss 0.2983\n",
      "[epoch 012/040] train=0.3741  val=0.4278  lr=0.00401918\n",
      "[epoch 013/040] step 50/2250 loss 0.4903\n",
      "[epoch 013/040] step 100/2250 loss 0.3062\n",
      "[epoch 013/040] step 150/2250 loss 0.3735\n",
      "[epoch 013/040] step 200/2250 loss 0.4234\n",
      "[epoch 013/040] step 250/2250 loss 0.3251\n",
      "[epoch 013/040] step 300/2250 loss 0.4101\n",
      "[epoch 013/040] step 350/2250 loss 0.3884\n",
      "[epoch 013/040] step 400/2250 loss 0.3877\n",
      "[epoch 013/040] step 450/2250 loss 0.3695\n",
      "[epoch 013/040] step 500/2250 loss 0.3914\n",
      "[epoch 013/040] step 550/2250 loss 0.3564\n",
      "[epoch 013/040] step 600/2250 loss 0.2962\n",
      "[epoch 013/040] step 650/2250 loss 0.2871\n",
      "[epoch 013/040] step 700/2250 loss 0.3594\n",
      "[epoch 013/040] step 750/2250 loss 0.3637\n",
      "[epoch 013/040] step 800/2250 loss 0.4211\n",
      "[epoch 013/040] step 850/2250 loss 0.3310\n",
      "[epoch 013/040] step 900/2250 loss 0.3322\n",
      "[epoch 013/040] step 950/2250 loss 0.4818\n",
      "[epoch 013/040] step 1000/2250 loss 0.3920\n",
      "[epoch 013/040] step 1050/2250 loss 0.4367\n",
      "[epoch 013/040] step 1100/2250 loss 0.3607\n",
      "[epoch 013/040] step 1150/2250 loss 0.3813\n",
      "[epoch 013/040] step 1200/2250 loss 0.2867\n",
      "[epoch 013/040] step 1250/2250 loss 0.3196\n",
      "[epoch 013/040] step 1300/2250 loss 0.3055\n",
      "[epoch 013/040] step 1350/2250 loss 0.2768\n",
      "[epoch 013/040] step 1400/2250 loss 0.3471\n",
      "[epoch 013/040] step 1450/2250 loss 0.3839\n",
      "[epoch 013/040] step 1500/2250 loss 0.2920\n",
      "[epoch 013/040] step 1550/2250 loss 0.3568\n",
      "[epoch 013/040] step 1600/2250 loss 0.3564\n",
      "[epoch 013/040] step 1650/2250 loss 0.3416\n",
      "[epoch 013/040] step 1700/2250 loss 0.3448\n",
      "[epoch 013/040] step 1750/2250 loss 0.3593\n",
      "[epoch 013/040] step 1800/2250 loss 0.3393\n",
      "[epoch 013/040] step 1850/2250 loss 0.3870\n",
      "[epoch 013/040] step 1900/2250 loss 0.3143\n",
      "[epoch 013/040] step 1950/2250 loss 0.3465\n",
      "[epoch 013/040] step 2000/2250 loss 0.3134\n",
      "[epoch 013/040] step 2050/2250 loss 0.3742\n",
      "[epoch 013/040] step 2100/2250 loss 0.2623\n",
      "[epoch 013/040] step 2150/2250 loss 0.3248\n",
      "[epoch 013/040] step 2200/2250 loss 0.3070\n",
      "[epoch 013/040] step 2250/2250 loss 0.3382\n",
      "[epoch 013/040] train=0.3693  val=0.4247  lr=0.00385689\n",
      "[epoch 014/040] step 50/2250 loss 0.3881\n",
      "[epoch 014/040] step 100/2250 loss 0.2353\n",
      "[epoch 014/040] step 150/2250 loss 0.4436\n",
      "[epoch 014/040] step 200/2250 loss 0.3305\n",
      "[epoch 014/040] step 250/2250 loss 0.3114\n",
      "[epoch 014/040] step 300/2250 loss 0.3396\n",
      "[epoch 014/040] step 350/2250 loss 0.3068\n",
      "[epoch 014/040] step 400/2250 loss 0.2913\n",
      "[epoch 014/040] step 450/2250 loss 0.3924\n",
      "[epoch 014/040] step 500/2250 loss 0.2658\n",
      "[epoch 014/040] step 550/2250 loss 0.3843\n",
      "[epoch 014/040] step 600/2250 loss 0.3483\n",
      "[epoch 014/040] step 650/2250 loss 0.3192\n",
      "[epoch 014/040] step 700/2250 loss 0.2778\n",
      "[epoch 014/040] step 750/2250 loss 0.4493\n",
      "[epoch 014/040] step 800/2250 loss 0.3455\n",
      "[epoch 014/040] step 850/2250 loss 0.3556\n",
      "[epoch 014/040] step 900/2250 loss 0.2839\n",
      "[epoch 014/040] step 950/2250 loss 0.3493\n",
      "[epoch 014/040] step 1000/2250 loss 0.4203\n",
      "[epoch 014/040] step 1050/2250 loss 0.2871\n",
      "[epoch 014/040] step 1100/2250 loss 0.4260\n",
      "[epoch 014/040] step 1150/2250 loss 0.2820\n",
      "[epoch 014/040] step 1200/2250 loss 0.2891\n",
      "[epoch 014/040] step 1250/2250 loss 0.4114\n",
      "[epoch 014/040] step 1300/2250 loss 0.3633\n",
      "[epoch 014/040] step 1350/2250 loss 0.2957\n",
      "[epoch 014/040] step 1400/2250 loss 0.3793\n",
      "[epoch 014/040] step 1450/2250 loss 0.3749\n",
      "[epoch 014/040] step 1500/2250 loss 0.4233\n",
      "[epoch 014/040] step 1550/2250 loss 0.3320\n",
      "[epoch 014/040] step 1600/2250 loss 0.4985\n",
      "[epoch 014/040] step 1650/2250 loss 0.3752\n",
      "[epoch 014/040] step 1700/2250 loss 0.3419\n",
      "[epoch 014/040] step 1750/2250 loss 0.2439\n",
      "[epoch 014/040] step 1800/2250 loss 0.3032\n",
      "[epoch 014/040] step 1850/2250 loss 0.2965\n",
      "[epoch 014/040] step 1900/2250 loss 0.3228\n",
      "[epoch 014/040] step 1950/2250 loss 0.2934\n",
      "[epoch 014/040] step 2000/2250 loss 0.3339\n",
      "[epoch 014/040] step 2050/2250 loss 0.3146\n",
      "[epoch 014/040] step 2100/2250 loss 0.3398\n",
      "[epoch 014/040] step 2150/2250 loss 0.3439\n",
      "[epoch 014/040] step 2200/2250 loss 0.3620\n",
      "[epoch 014/040] step 2250/2250 loss 0.3450\n",
      "[epoch 014/040] train=0.3652  val=0.4257  lr=0.00368604\n",
      "[epoch 015/040] step 50/2250 loss 0.3669\n",
      "[epoch 015/040] step 100/2250 loss 0.3128\n",
      "[epoch 015/040] step 150/2250 loss 0.3373\n",
      "[epoch 015/040] step 200/2250 loss 0.2802\n",
      "[epoch 015/040] step 250/2250 loss 0.2944\n",
      "[epoch 015/040] step 300/2250 loss 0.2704\n",
      "[epoch 015/040] step 350/2250 loss 0.3909\n",
      "[epoch 015/040] step 400/2250 loss 0.3678\n",
      "[epoch 015/040] step 450/2250 loss 0.3403\n",
      "[epoch 015/040] step 500/2250 loss 0.3270\n",
      "[epoch 015/040] step 550/2250 loss 0.3136\n",
      "[epoch 015/040] step 600/2250 loss 0.2412\n",
      "[epoch 015/040] step 650/2250 loss 0.3406\n",
      "[epoch 015/040] step 700/2250 loss 0.3723\n",
      "[epoch 015/040] step 750/2250 loss 0.3788\n",
      "[epoch 015/040] step 800/2250 loss 0.3818\n",
      "[epoch 015/040] step 850/2250 loss 0.2955\n",
      "[epoch 015/040] step 900/2250 loss 0.4215\n",
      "[epoch 015/040] step 950/2250 loss 0.3855\n",
      "[epoch 015/040] step 1000/2250 loss 0.3558\n",
      "[epoch 015/040] step 1050/2250 loss 0.3444\n",
      "[epoch 015/040] step 1100/2250 loss 0.2996\n",
      "[epoch 015/040] step 1150/2250 loss 0.3023\n",
      "[epoch 015/040] step 1200/2250 loss 0.3321\n",
      "[epoch 015/040] step 1250/2250 loss 0.3882\n",
      "[epoch 015/040] step 1300/2250 loss 0.2700\n",
      "[epoch 015/040] step 1350/2250 loss 0.2735\n",
      "[epoch 015/040] step 1400/2250 loss 0.3740\n",
      "[epoch 015/040] step 1450/2250 loss 0.4305\n",
      "[epoch 015/040] step 1500/2250 loss 0.3181\n",
      "[epoch 015/040] step 1550/2250 loss 0.3075\n",
      "[epoch 015/040] step 1600/2250 loss 0.3650\n",
      "[epoch 015/040] step 1650/2250 loss 0.3060\n",
      "[epoch 015/040] step 1700/2250 loss 0.3098\n",
      "[epoch 015/040] step 1750/2250 loss 0.3030\n",
      "[epoch 015/040] step 1800/2250 loss 0.4404\n",
      "[epoch 015/040] step 1850/2250 loss 0.4379\n",
      "[epoch 015/040] step 1900/2250 loss 0.3333\n",
      "[epoch 015/040] step 1950/2250 loss 0.3388\n",
      "[epoch 015/040] step 2000/2250 loss 0.2877\n",
      "[epoch 015/040] step 2050/2250 loss 0.2961\n",
      "[epoch 015/040] step 2100/2250 loss 0.3064\n",
      "[epoch 015/040] step 2150/2250 loss 0.3021\n",
      "[epoch 015/040] step 2200/2250 loss 0.2696\n",
      "[epoch 015/040] step 2250/2250 loss 0.3757\n",
      "[epoch 015/040] train=0.3612  val=0.4244  lr=0.00350773\n",
      "[epoch 016/040] step 50/2250 loss 0.3573\n",
      "[epoch 016/040] step 100/2250 loss 0.3403\n",
      "[epoch 016/040] step 150/2250 loss 0.3350\n",
      "[epoch 016/040] step 200/2250 loss 0.3947\n",
      "[epoch 016/040] step 250/2250 loss 0.3502\n",
      "[epoch 016/040] step 300/2250 loss 0.3467\n",
      "[epoch 016/040] step 350/2250 loss 0.3052\n",
      "[epoch 016/040] step 400/2250 loss 0.3532\n",
      "[epoch 016/040] step 450/2250 loss 0.2677\n",
      "[epoch 016/040] step 500/2250 loss 0.3212\n",
      "[epoch 016/040] step 550/2250 loss 0.3352\n",
      "[epoch 016/040] step 600/2250 loss 0.3451\n",
      "[epoch 016/040] step 650/2250 loss 0.3675\n",
      "[epoch 016/040] step 700/2250 loss 0.3185\n",
      "[epoch 016/040] step 750/2250 loss 0.4967\n",
      "[epoch 016/040] step 800/2250 loss 0.3837\n",
      "[epoch 016/040] step 850/2250 loss 0.3011\n",
      "[epoch 016/040] step 900/2250 loss 0.3525\n",
      "[epoch 016/040] step 950/2250 loss 0.2845\n",
      "[epoch 016/040] step 1000/2250 loss 0.3377\n",
      "[epoch 016/040] step 1050/2250 loss 0.3791\n",
      "[epoch 016/040] step 1100/2250 loss 0.3887\n",
      "[epoch 016/040] step 1150/2250 loss 0.2600\n",
      "[epoch 016/040] step 1200/2250 loss 0.3517\n",
      "[epoch 016/040] step 1250/2250 loss 0.4031\n",
      "[epoch 016/040] step 1300/2250 loss 0.3288\n",
      "[epoch 016/040] step 1350/2250 loss 0.3571\n",
      "[epoch 016/040] step 1400/2250 loss 0.2811\n",
      "[epoch 016/040] step 1450/2250 loss 0.3675\n",
      "[epoch 016/040] step 1500/2250 loss 0.2729\n",
      "[epoch 016/040] step 1550/2250 loss 0.3866\n",
      "[epoch 016/040] step 1600/2250 loss 0.3699\n",
      "[epoch 016/040] step 1650/2250 loss 0.3197\n",
      "[epoch 016/040] step 1700/2250 loss 0.3216\n",
      "[epoch 016/040] step 1750/2250 loss 0.4069\n",
      "[epoch 016/040] step 1800/2250 loss 0.3533\n",
      "[epoch 016/040] step 1850/2250 loss 0.3193\n",
      "[epoch 016/040] step 1900/2250 loss 0.4105\n",
      "[epoch 016/040] step 1950/2250 loss 0.3599\n",
      "[epoch 016/040] step 2000/2250 loss 0.2814\n",
      "[epoch 016/040] step 2050/2250 loss 0.3751\n",
      "[epoch 016/040] step 2100/2250 loss 0.3602\n",
      "[epoch 016/040] step 2150/2250 loss 0.3266\n",
      "[epoch 016/040] step 2200/2250 loss 0.3183\n",
      "[epoch 016/040] step 2250/2250 loss 0.2768\n",
      "[epoch 016/040] train=0.3565  val=0.4221  lr=0.00332306\n",
      "[epoch 017/040] step 50/2250 loss 0.3677\n",
      "[epoch 017/040] step 100/2250 loss 0.2944\n",
      "[epoch 017/040] step 150/2250 loss 0.3173\n",
      "[epoch 017/040] step 200/2250 loss 0.3573\n",
      "[epoch 017/040] step 250/2250 loss 0.4129\n",
      "[epoch 017/040] step 300/2250 loss 0.3266\n",
      "[epoch 017/040] step 350/2250 loss 0.3118\n",
      "[epoch 017/040] step 400/2250 loss 0.3171\n",
      "[epoch 017/040] step 450/2250 loss 0.3322\n",
      "[epoch 017/040] step 500/2250 loss 0.3381\n",
      "[epoch 017/040] step 550/2250 loss 0.4042\n",
      "[epoch 017/040] step 600/2250 loss 0.3273\n",
      "[epoch 017/040] step 650/2250 loss 0.2812\n",
      "[epoch 017/040] step 700/2250 loss 0.2820\n",
      "[epoch 017/040] step 750/2250 loss 0.4101\n",
      "[epoch 017/040] step 800/2250 loss 0.3451\n",
      "[epoch 017/040] step 850/2250 loss 0.3691\n",
      "[epoch 017/040] step 900/2250 loss 0.3308\n",
      "[epoch 017/040] step 950/2250 loss 0.3073\n",
      "[epoch 017/040] step 1000/2250 loss 0.3103\n",
      "[epoch 017/040] step 1050/2250 loss 0.3004\n",
      "[epoch 017/040] step 1100/2250 loss 0.3548\n",
      "[epoch 017/040] step 1150/2250 loss 0.2822\n",
      "[epoch 017/040] step 1200/2250 loss 0.3989\n",
      "[epoch 017/040] step 1250/2250 loss 0.2654\n",
      "[epoch 017/040] step 1300/2250 loss 0.3103\n",
      "[epoch 017/040] step 1350/2250 loss 0.3563\n",
      "[epoch 017/040] step 1400/2250 loss 0.3172\n",
      "[epoch 017/040] step 1450/2250 loss 0.2729\n",
      "[epoch 017/040] step 1500/2250 loss 0.2837\n",
      "[epoch 017/040] step 1550/2250 loss 0.3226\n",
      "[epoch 017/040] step 1600/2250 loss 0.3481\n",
      "[epoch 017/040] step 1650/2250 loss 0.2974\n",
      "[epoch 017/040] step 1700/2250 loss 0.3320\n",
      "[epoch 017/040] step 1750/2250 loss 0.3050\n",
      "[epoch 017/040] step 1800/2250 loss 0.2873\n",
      "[epoch 017/040] step 1850/2250 loss 0.3149\n",
      "[epoch 017/040] step 1900/2250 loss 0.3011\n",
      "[epoch 017/040] step 1950/2250 loss 0.2804\n",
      "[epoch 017/040] step 2000/2250 loss 0.3565\n",
      "[epoch 017/040] step 2050/2250 loss 0.3714\n",
      "[epoch 017/040] step 2100/2250 loss 0.3648\n",
      "[epoch 017/040] step 2150/2250 loss 0.3788\n",
      "[epoch 017/040] step 2200/2250 loss 0.3658\n",
      "[epoch 017/040] step 2250/2250 loss 0.4183\n",
      "[epoch 017/040] train=0.3527  val=0.4195  lr=0.0031332\n",
      "[epoch 018/040] step 50/2250 loss 0.3548\n",
      "[epoch 018/040] step 100/2250 loss 0.3255\n",
      "[epoch 018/040] step 150/2250 loss 0.3185\n",
      "[epoch 018/040] step 200/2250 loss 0.3219\n",
      "[epoch 018/040] step 250/2250 loss 0.2881\n",
      "[epoch 018/040] step 300/2250 loss 0.3090\n",
      "[epoch 018/040] step 350/2250 loss 0.3046\n",
      "[epoch 018/040] step 400/2250 loss 0.2841\n",
      "[epoch 018/040] step 450/2250 loss 0.3718\n",
      "[epoch 018/040] step 500/2250 loss 0.2890\n",
      "[epoch 018/040] step 550/2250 loss 0.3553\n",
      "[epoch 018/040] step 600/2250 loss 0.3286\n",
      "[epoch 018/040] step 650/2250 loss 0.4659\n",
      "[epoch 018/040] step 700/2250 loss 0.2834\n",
      "[epoch 018/040] step 750/2250 loss 0.3668\n",
      "[epoch 018/040] step 800/2250 loss 0.3904\n",
      "[epoch 018/040] step 850/2250 loss 0.2612\n",
      "[epoch 018/040] step 900/2250 loss 0.3247\n",
      "[epoch 018/040] step 950/2250 loss 0.3790\n",
      "[epoch 018/040] step 1000/2250 loss 0.3257\n",
      "[epoch 018/040] step 1050/2250 loss 0.3310\n",
      "[epoch 018/040] step 1100/2250 loss 0.2440\n",
      "[epoch 018/040] step 1150/2250 loss 0.4071\n",
      "[epoch 018/040] step 1200/2250 loss 0.3002\n",
      "[epoch 018/040] step 1250/2250 loss 0.3201\n",
      "[epoch 018/040] step 1300/2250 loss 0.4312\n",
      "[epoch 018/040] step 1350/2250 loss 0.3301\n",
      "[epoch 018/040] step 1400/2250 loss 0.2979\n",
      "[epoch 018/040] step 1450/2250 loss 0.3854\n",
      "[epoch 018/040] step 1500/2250 loss 0.3243\n",
      "[epoch 018/040] step 1550/2250 loss 0.3612\n",
      "[epoch 018/040] step 1600/2250 loss 0.2862\n",
      "[epoch 018/040] step 1650/2250 loss 0.2613\n",
      "[epoch 018/040] step 1700/2250 loss 0.2876\n",
      "[epoch 018/040] step 1750/2250 loss 0.2792\n",
      "[epoch 018/040] step 1800/2250 loss 0.4141\n",
      "[epoch 018/040] step 1850/2250 loss 0.2906\n",
      "[epoch 018/040] step 1900/2250 loss 0.2613\n",
      "[epoch 018/040] step 1950/2250 loss 0.3111\n",
      "[epoch 018/040] step 2000/2250 loss 0.4866\n",
      "[epoch 018/040] step 2050/2250 loss 0.3298\n",
      "[epoch 018/040] step 2100/2250 loss 0.3042\n",
      "[epoch 018/040] step 2150/2250 loss 0.3338\n",
      "[epoch 018/040] step 2200/2250 loss 0.2981\n",
      "[epoch 018/040] step 2250/2250 loss 0.3121\n",
      "[epoch 018/040] train=0.3485  val=0.4187  lr=0.00293936\n",
      "[epoch 019/040] step 50/2250 loss 0.3009\n",
      "[epoch 019/040] step 100/2250 loss 0.4084\n",
      "[epoch 019/040] step 150/2250 loss 0.2487\n",
      "[epoch 019/040] step 200/2250 loss 0.2882\n",
      "[epoch 019/040] step 250/2250 loss 0.2668\n",
      "[epoch 019/040] step 300/2250 loss 0.3178\n",
      "[epoch 019/040] step 350/2250 loss 0.2825\n",
      "[epoch 019/040] step 400/2250 loss 0.2818\n",
      "[epoch 019/040] step 450/2250 loss 0.3586\n",
      "[epoch 019/040] step 500/2250 loss 0.2871\n",
      "[epoch 019/040] step 550/2250 loss 0.2986\n",
      "[epoch 019/040] step 600/2250 loss 0.2730\n",
      "[epoch 019/040] step 650/2250 loss 0.3514\n",
      "[epoch 019/040] step 700/2250 loss 0.3302\n",
      "[epoch 019/040] step 750/2250 loss 0.3620\n",
      "[epoch 019/040] step 800/2250 loss 0.4243\n",
      "[epoch 019/040] step 850/2250 loss 0.3600\n",
      "[epoch 019/040] step 900/2250 loss 0.4344\n",
      "[epoch 019/040] step 950/2250 loss 0.2771\n",
      "[epoch 019/040] step 1000/2250 loss 0.3859\n",
      "[epoch 019/040] step 1050/2250 loss 0.3018\n",
      "[epoch 019/040] step 1100/2250 loss 0.2885\n",
      "[epoch 019/040] step 1150/2250 loss 0.3126\n",
      "[epoch 019/040] step 1200/2250 loss 0.2916\n",
      "[epoch 019/040] step 1250/2250 loss 0.2870\n",
      "[epoch 019/040] step 1300/2250 loss 0.2687\n",
      "[epoch 019/040] step 1350/2250 loss 0.3191\n",
      "[epoch 019/040] step 1400/2250 loss 0.3473\n",
      "[epoch 019/040] step 1450/2250 loss 0.3419\n",
      "[epoch 019/040] step 1500/2250 loss 0.3003\n",
      "[epoch 019/040] step 1550/2250 loss 0.2925\n",
      "[epoch 019/040] step 1600/2250 loss 0.3297\n",
      "[epoch 019/040] step 1650/2250 loss 0.2688\n",
      "[epoch 019/040] step 1700/2250 loss 0.3650\n",
      "[epoch 019/040] step 1750/2250 loss 0.3644\n",
      "[epoch 019/040] step 1800/2250 loss 0.2755\n",
      "[epoch 019/040] step 1850/2250 loss 0.3815\n",
      "[epoch 019/040] step 1900/2250 loss 0.3281\n",
      "[epoch 019/040] step 1950/2250 loss 0.3027\n",
      "[epoch 019/040] step 2000/2250 loss 0.2843\n",
      "[epoch 019/040] step 2050/2250 loss 0.3046\n",
      "[epoch 019/040] step 2100/2250 loss 0.2789\n",
      "[epoch 019/040] step 2150/2250 loss 0.3978\n",
      "[epoch 019/040] step 2200/2250 loss 0.2792\n",
      "[epoch 019/040] step 2250/2250 loss 0.3198\n",
      "[epoch 019/040] train=0.3443  val=0.4196  lr=0.00274275\n",
      "[epoch 020/040] step 50/2250 loss 0.2952\n",
      "[epoch 020/040] step 100/2250 loss 0.4451\n",
      "[epoch 020/040] step 150/2250 loss 0.2454\n",
      "[epoch 020/040] step 200/2250 loss 0.4200\n",
      "[epoch 020/040] step 250/2250 loss 0.2831\n",
      "[epoch 020/040] step 300/2250 loss 0.3343\n",
      "[epoch 020/040] step 350/2250 loss 0.2861\n",
      "[epoch 020/040] step 400/2250 loss 0.4162\n",
      "[epoch 020/040] step 450/2250 loss 0.3296\n",
      "[epoch 020/040] step 500/2250 loss 0.3835\n",
      "[epoch 020/040] step 550/2250 loss 0.3205\n",
      "[epoch 020/040] step 600/2250 loss 0.2806\n",
      "[epoch 020/040] step 650/2250 loss 0.3491\n",
      "[epoch 020/040] step 700/2250 loss 0.3154\n",
      "[epoch 020/040] step 750/2250 loss 0.3087\n",
      "[epoch 020/040] step 800/2250 loss 0.2986\n",
      "[epoch 020/040] step 850/2250 loss 0.2975\n",
      "[epoch 020/040] step 900/2250 loss 0.3155\n",
      "[epoch 020/040] step 950/2250 loss 0.3371\n",
      "[epoch 020/040] step 1000/2250 loss 0.5364\n",
      "[epoch 020/040] step 1050/2250 loss 0.2840\n",
      "[epoch 020/040] step 1100/2250 loss 0.3365\n",
      "[epoch 020/040] step 1150/2250 loss 0.3205\n",
      "[epoch 020/040] step 1200/2250 loss 0.3263\n",
      "[epoch 020/040] step 1250/2250 loss 0.3288\n",
      "[epoch 020/040] step 1300/2250 loss 0.3751\n",
      "[epoch 020/040] step 1350/2250 loss 0.2922\n",
      "[epoch 020/040] step 1400/2250 loss 0.2718\n",
      "[epoch 020/040] step 1450/2250 loss 0.3486\n",
      "[epoch 020/040] step 1500/2250 loss 0.3157\n",
      "[epoch 020/040] step 1550/2250 loss 0.3111\n",
      "[epoch 020/040] step 1600/2250 loss 0.3099\n",
      "[epoch 020/040] step 1650/2250 loss 0.3341\n",
      "[epoch 020/040] step 1700/2250 loss 0.3606\n",
      "[epoch 020/040] step 1750/2250 loss 0.4772\n",
      "[epoch 020/040] step 1800/2250 loss 0.2585\n",
      "[epoch 020/040] step 1850/2250 loss 0.3186\n",
      "[epoch 020/040] step 1900/2250 loss 0.2763\n",
      "[epoch 020/040] step 1950/2250 loss 0.3110\n",
      "[epoch 020/040] step 2000/2250 loss 0.3499\n",
      "[epoch 020/040] step 2050/2250 loss 0.3246\n",
      "[epoch 020/040] step 2100/2250 loss 0.2593\n",
      "[epoch 020/040] step 2150/2250 loss 0.2657\n",
      "[epoch 020/040] step 2200/2250 loss 0.3325\n",
      "[epoch 020/040] step 2250/2250 loss 0.3354\n",
      "[epoch 020/040] train=0.3408  val=0.4180  lr=0.00254461\n",
      "[epoch 021/040] step 50/2250 loss 0.3772\n",
      "[epoch 021/040] step 100/2250 loss 0.3433\n",
      "[epoch 021/040] step 150/2250 loss 0.3195\n",
      "[epoch 021/040] step 200/2250 loss 0.2644\n",
      "[epoch 021/040] step 250/2250 loss 0.3170\n",
      "[epoch 021/040] step 300/2250 loss 0.2696\n",
      "[epoch 021/040] step 350/2250 loss 0.2934\n",
      "[epoch 021/040] step 400/2250 loss 0.3334\n",
      "[epoch 021/040] step 450/2250 loss 0.2827\n",
      "[epoch 021/040] step 500/2250 loss 0.3638\n",
      "[epoch 021/040] step 550/2250 loss 0.2642\n",
      "[epoch 021/040] step 600/2250 loss 0.3461\n",
      "[epoch 021/040] step 650/2250 loss 0.2919\n",
      "[epoch 021/040] step 700/2250 loss 0.2629\n",
      "[epoch 021/040] step 750/2250 loss 0.3422\n",
      "[epoch 021/040] step 800/2250 loss 0.2630\n",
      "[epoch 021/040] step 850/2250 loss 0.3501\n",
      "[epoch 021/040] step 900/2250 loss 0.2794\n",
      "[epoch 021/040] step 950/2250 loss 0.2422\n",
      "[epoch 021/040] step 1000/2250 loss 0.2981\n",
      "[epoch 021/040] step 1050/2250 loss 0.3411\n",
      "[epoch 021/040] step 1100/2250 loss 0.3170\n",
      "[epoch 021/040] step 1150/2250 loss 0.2808\n",
      "[epoch 021/040] step 1200/2250 loss 0.3296\n",
      "[epoch 021/040] step 1250/2250 loss 0.2798\n",
      "[epoch 021/040] step 1300/2250 loss 0.4384\n",
      "[epoch 021/040] step 1350/2250 loss 0.2656\n",
      "[epoch 021/040] step 1400/2250 loss 0.3343\n",
      "[epoch 021/040] step 1450/2250 loss 0.3179\n",
      "[epoch 021/040] step 1500/2250 loss 0.4040\n",
      "[epoch 021/040] step 1550/2250 loss 0.3487\n",
      "[epoch 021/040] step 1600/2250 loss 0.3203\n",
      "[epoch 021/040] step 1650/2250 loss 0.2644\n",
      "[epoch 021/040] step 1700/2250 loss 0.2898\n",
      "[epoch 021/040] step 1750/2250 loss 0.2863\n",
      "[epoch 021/040] step 1800/2250 loss 0.3929\n",
      "[epoch 021/040] step 1850/2250 loss 0.3005\n",
      "[epoch 021/040] step 1900/2250 loss 0.3386\n",
      "[epoch 021/040] step 1950/2250 loss 0.2796\n",
      "[epoch 021/040] step 2000/2250 loss 0.2612\n",
      "[epoch 021/040] step 2050/2250 loss 0.3941\n",
      "[epoch 021/040] step 2100/2250 loss 0.3312\n",
      "[epoch 021/040] step 2150/2250 loss 0.3204\n",
      "[epoch 021/040] step 2200/2250 loss 0.4023\n",
      "[epoch 021/040] step 2250/2250 loss 0.2819\n",
      "[epoch 021/040] train=0.3381  val=0.4149  lr=0.0023462\n",
      "[epoch 022/040] step 50/2250 loss 0.3528\n",
      "[epoch 022/040] step 100/2250 loss 0.2384\n",
      "[epoch 022/040] step 150/2250 loss 0.3458\n",
      "[epoch 022/040] step 200/2250 loss 0.2860\n",
      "[epoch 022/040] step 250/2250 loss 0.2922\n",
      "[epoch 022/040] step 300/2250 loss 0.3341\n",
      "[epoch 022/040] step 350/2250 loss 0.2582\n",
      "[epoch 022/040] step 400/2250 loss 0.2417\n",
      "[epoch 022/040] step 450/2250 loss 0.3425\n",
      "[epoch 022/040] step 500/2250 loss 0.2731\n",
      "[epoch 022/040] step 550/2250 loss 0.3439\n",
      "[epoch 022/040] step 600/2250 loss 0.2878\n",
      "[epoch 022/040] step 650/2250 loss 0.3139\n",
      "[epoch 022/040] step 700/2250 loss 0.2765\n",
      "[epoch 022/040] step 750/2250 loss 0.3123\n",
      "[epoch 022/040] step 800/2250 loss 0.2839\n",
      "[epoch 022/040] step 850/2250 loss 0.4528\n",
      "[epoch 022/040] step 900/2250 loss 0.2810\n",
      "[epoch 022/040] step 950/2250 loss 0.3401\n",
      "[epoch 022/040] step 1000/2250 loss 0.3226\n",
      "[epoch 022/040] step 1050/2250 loss 0.3717\n",
      "[epoch 022/040] step 1100/2250 loss 0.3204\n",
      "[epoch 022/040] step 1150/2250 loss 0.3270\n",
      "[epoch 022/040] step 1200/2250 loss 0.3125\n",
      "[epoch 022/040] step 1250/2250 loss 0.3671\n",
      "[epoch 022/040] step 1300/2250 loss 0.2641\n",
      "[epoch 022/040] step 1350/2250 loss 0.3340\n",
      "[epoch 022/040] step 1400/2250 loss 0.3101\n",
      "[epoch 022/040] step 1450/2250 loss 0.2539\n",
      "[epoch 022/040] step 1500/2250 loss 0.3049\n",
      "[epoch 022/040] step 1550/2250 loss 0.2983\n",
      "[epoch 022/040] step 1600/2250 loss 0.3507\n",
      "[epoch 022/040] step 1650/2250 loss 0.3252\n",
      "[epoch 022/040] step 1700/2250 loss 0.3849\n",
      "[epoch 022/040] step 1750/2250 loss 0.2808\n",
      "[epoch 022/040] step 1800/2250 loss 0.2948\n",
      "[epoch 022/040] step 1850/2250 loss 0.4126\n",
      "[epoch 022/040] step 1900/2250 loss 0.3158\n",
      "[epoch 022/040] step 1950/2250 loss 0.2992\n",
      "[epoch 022/040] step 2000/2250 loss 0.3439\n",
      "[epoch 022/040] step 2050/2250 loss 0.4678\n",
      "[epoch 022/040] step 2100/2250 loss 0.2999\n",
      "[epoch 022/040] step 2150/2250 loss 0.2975\n",
      "[epoch 022/040] step 2200/2250 loss 0.3034\n",
      "[epoch 022/040] step 2250/2250 loss 0.4022\n",
      "[epoch 022/040] train=0.3355  val=0.4186  lr=0.00214875\n",
      "[epoch 023/040] step 50/2250 loss 0.4254\n",
      "[epoch 023/040] step 100/2250 loss 0.3085\n",
      "[epoch 023/040] step 150/2250 loss 0.2345\n",
      "[epoch 023/040] step 200/2250 loss 0.2708\n",
      "[epoch 023/040] step 250/2250 loss 0.3567\n",
      "[epoch 023/040] step 300/2250 loss 0.2717\n",
      "[epoch 023/040] step 350/2250 loss 0.2971\n",
      "[epoch 023/040] step 400/2250 loss 0.3978\n",
      "[epoch 023/040] step 450/2250 loss 0.2891\n",
      "[epoch 023/040] step 500/2250 loss 0.2368\n",
      "[epoch 023/040] step 550/2250 loss 0.3138\n",
      "[epoch 023/040] step 600/2250 loss 0.4384\n",
      "[epoch 023/040] step 650/2250 loss 0.2989\n",
      "[epoch 023/040] step 700/2250 loss 0.3067\n",
      "[epoch 023/040] step 750/2250 loss 0.2885\n",
      "[epoch 023/040] step 800/2250 loss 0.3173\n",
      "[epoch 023/040] step 850/2250 loss 0.2779\n",
      "[epoch 023/040] step 900/2250 loss 0.3172\n",
      "[epoch 023/040] step 950/2250 loss 0.3268\n",
      "[epoch 023/040] step 1000/2250 loss 0.3141\n",
      "[epoch 023/040] step 1050/2250 loss 0.3533\n",
      "[epoch 023/040] step 1100/2250 loss 0.3452\n",
      "[epoch 023/040] step 1150/2250 loss 0.2941\n",
      "[epoch 023/040] step 1200/2250 loss 0.3043\n",
      "[epoch 023/040] step 1250/2250 loss 0.2684\n",
      "[epoch 023/040] step 1300/2250 loss 0.3985\n",
      "[epoch 023/040] step 1350/2250 loss 0.3800\n",
      "[epoch 023/040] step 1400/2250 loss 0.3778\n",
      "[epoch 023/040] step 1450/2250 loss 0.2862\n",
      "[epoch 023/040] step 1500/2250 loss 0.3959\n",
      "[epoch 023/040] step 1550/2250 loss 0.3068\n",
      "[epoch 023/040] step 1600/2250 loss 0.3124\n",
      "[epoch 023/040] step 1650/2250 loss 0.3598\n",
      "[epoch 023/040] step 1700/2250 loss 0.3151\n",
      "[epoch 023/040] step 1750/2250 loss 0.4342\n",
      "[epoch 023/040] step 1800/2250 loss 0.3094\n",
      "[epoch 023/040] step 1850/2250 loss 0.3383\n",
      "[epoch 023/040] step 1900/2250 loss 0.3140\n",
      "[epoch 023/040] step 1950/2250 loss 0.2962\n",
      "[epoch 023/040] step 2000/2250 loss 0.2555\n",
      "[epoch 023/040] step 2050/2250 loss 0.2741\n",
      "[epoch 023/040] step 2100/2250 loss 0.2569\n",
      "[epoch 023/040] step 2150/2250 loss 0.3894\n",
      "[epoch 023/040] step 2200/2250 loss 0.3343\n",
      "[epoch 023/040] step 2250/2250 loss 0.3260\n",
      "[epoch 023/040] train=0.3322  val=0.4174  lr=0.00195353\n",
      "[epoch 024/040] step 50/2250 loss 0.3420\n",
      "[epoch 024/040] step 100/2250 loss 0.2878\n",
      "[epoch 024/040] step 150/2250 loss 0.2871\n",
      "[epoch 024/040] step 200/2250 loss 0.4761\n",
      "[epoch 024/040] step 250/2250 loss 0.2538\n",
      "[epoch 024/040] step 300/2250 loss 0.4437\n",
      "[epoch 024/040] step 350/2250 loss 0.2911\n",
      "[epoch 024/040] step 400/2250 loss 0.2665\n",
      "[epoch 024/040] step 450/2250 loss 0.2877\n",
      "[epoch 024/040] step 500/2250 loss 0.3056\n",
      "[epoch 024/040] step 550/2250 loss 0.2571\n",
      "[epoch 024/040] step 600/2250 loss 0.2679\n",
      "[epoch 024/040] step 650/2250 loss 0.3432\n",
      "[epoch 024/040] step 700/2250 loss 0.2825\n",
      "[epoch 024/040] step 750/2250 loss 0.3156\n",
      "[epoch 024/040] step 800/2250 loss 0.2978\n",
      "[epoch 024/040] step 850/2250 loss 0.2427\n",
      "[epoch 024/040] step 900/2250 loss 0.3439\n",
      "[epoch 024/040] step 950/2250 loss 0.2769\n",
      "[epoch 024/040] step 1000/2250 loss 0.2701\n",
      "[epoch 024/040] step 1050/2250 loss 0.3574\n",
      "[epoch 024/040] step 1100/2250 loss 0.2991\n",
      "[epoch 024/040] step 1150/2250 loss 0.2957\n",
      "[epoch 024/040] step 1200/2250 loss 0.3415\n",
      "[epoch 024/040] step 1250/2250 loss 0.2797\n",
      "[epoch 024/040] step 1300/2250 loss 0.2671\n",
      "[epoch 024/040] step 1350/2250 loss 0.2772\n",
      "[epoch 024/040] step 1400/2250 loss 0.3695\n",
      "[epoch 024/040] step 1450/2250 loss 0.2754\n",
      "[epoch 024/040] step 1500/2250 loss 0.4115\n",
      "[epoch 024/040] step 1550/2250 loss 0.3102\n",
      "[epoch 024/040] step 1600/2250 loss 0.3145\n",
      "[epoch 024/040] step 1650/2250 loss 0.3400\n",
      "[epoch 024/040] step 1700/2250 loss 0.2995\n",
      "[epoch 024/040] step 1750/2250 loss 0.2935\n",
      "[epoch 024/040] step 1800/2250 loss 0.3589\n",
      "[epoch 024/040] step 1850/2250 loss 0.3604\n",
      "[epoch 024/040] step 1900/2250 loss 0.2783\n",
      "[epoch 024/040] step 1950/2250 loss 0.2587\n",
      "[epoch 024/040] step 2000/2250 loss 0.2717\n",
      "[epoch 024/040] step 2050/2250 loss 0.2740\n",
      "[epoch 024/040] step 2100/2250 loss 0.3381\n",
      "[epoch 024/040] step 2150/2250 loss 0.3776\n",
      "[epoch 024/040] step 2200/2250 loss 0.2683\n",
      "[epoch 024/040] step 2250/2250 loss 0.3063\n",
      "[epoch 024/040] train=0.3282  val=0.4167  lr=0.00176175\n",
      "[epoch 025/040] step 50/2250 loss 0.2664\n",
      "[epoch 025/040] step 100/2250 loss 0.2716\n",
      "[epoch 025/040] step 150/2250 loss 0.3298\n",
      "[epoch 025/040] step 200/2250 loss 0.2823\n",
      "[epoch 025/040] step 250/2250 loss 0.2937\n",
      "[epoch 025/040] step 300/2250 loss 0.2630\n",
      "[epoch 025/040] step 350/2250 loss 0.3053\n",
      "[epoch 025/040] step 400/2250 loss 0.3187\n",
      "[epoch 025/040] step 450/2250 loss 0.2764\n",
      "[epoch 025/040] step 500/2250 loss 0.4090\n",
      "[epoch 025/040] step 550/2250 loss 0.4464\n",
      "[epoch 025/040] step 600/2250 loss 0.3438\n",
      "[epoch 025/040] step 650/2250 loss 0.4074\n",
      "[epoch 025/040] step 700/2250 loss 0.2797\n",
      "[epoch 025/040] step 750/2250 loss 0.2812\n",
      "[epoch 025/040] step 800/2250 loss 0.2278\n",
      "[epoch 025/040] step 850/2250 loss 0.2597\n",
      "[epoch 025/040] step 900/2250 loss 0.3498\n",
      "[epoch 025/040] step 950/2250 loss 0.2968\n",
      "[epoch 025/040] step 1000/2250 loss 0.2586\n",
      "[epoch 025/040] step 1050/2250 loss 0.2984\n",
      "[epoch 025/040] step 1100/2250 loss 0.2508\n",
      "[epoch 025/040] step 1150/2250 loss 0.2568\n",
      "[epoch 025/040] step 1200/2250 loss 0.4140\n",
      "[epoch 025/040] step 1250/2250 loss 0.3240\n",
      "[epoch 025/040] step 1300/2250 loss 0.3193\n",
      "[epoch 025/040] step 1350/2250 loss 0.3699\n",
      "[epoch 025/040] step 1400/2250 loss 0.2520\n",
      "[epoch 025/040] step 1450/2250 loss 0.2954\n",
      "[epoch 025/040] step 1500/2250 loss 0.2513\n",
      "[epoch 025/040] step 1550/2250 loss 0.2539\n",
      "[epoch 025/040] step 1600/2250 loss 0.3687\n",
      "[epoch 025/040] step 1650/2250 loss 0.2879\n",
      "[epoch 025/040] step 1700/2250 loss 0.4633\n",
      "[epoch 025/040] step 1750/2250 loss 0.2624\n",
      "[epoch 025/040] step 1800/2250 loss 0.4011\n",
      "[epoch 025/040] step 1850/2250 loss 0.2665\n",
      "[epoch 025/040] step 1900/2250 loss 0.2581\n",
      "[epoch 025/040] step 1950/2250 loss 0.3200\n",
      "[epoch 025/040] step 2000/2250 loss 0.3314\n",
      "[epoch 025/040] step 2050/2250 loss 0.2604\n",
      "[epoch 025/040] step 2100/2250 loss 0.2700\n",
      "[epoch 025/040] step 2150/2250 loss 0.2873\n",
      "[epoch 025/040] step 2200/2250 loss 0.2523\n",
      "[epoch 025/040] step 2250/2250 loss 0.3159\n",
      "[epoch 025/040] train=0.3260  val=0.4168  lr=0.00157463\n",
      "[epoch 026/040] step 50/2250 loss 0.3446\n",
      "[epoch 026/040] step 100/2250 loss 0.2937\n",
      "[epoch 026/040] step 150/2250 loss 0.4160\n",
      "[epoch 026/040] step 200/2250 loss 0.3039\n",
      "[epoch 026/040] step 250/2250 loss 0.2670\n",
      "[epoch 026/040] step 300/2250 loss 0.3464\n",
      "[epoch 026/040] step 350/2250 loss 0.4035\n",
      "[epoch 026/040] step 400/2250 loss 0.4028\n",
      "[epoch 026/040] step 450/2250 loss 0.3951\n",
      "[epoch 026/040] step 500/2250 loss 0.3442\n",
      "[epoch 026/040] step 550/2250 loss 0.3063\n",
      "[epoch 026/040] step 600/2250 loss 0.3453\n",
      "[epoch 026/040] step 650/2250 loss 0.2800\n",
      "[epoch 026/040] step 700/2250 loss 0.2584\n",
      "[epoch 026/040] step 750/2250 loss 0.3238\n",
      "[epoch 026/040] step 800/2250 loss 0.2952\n",
      "[epoch 026/040] step 850/2250 loss 0.3191\n",
      "[epoch 026/040] step 900/2250 loss 0.2775\n",
      "[epoch 026/040] step 950/2250 loss 0.2700\n",
      "[epoch 026/040] step 1000/2250 loss 0.3507\n",
      "[epoch 026/040] step 1050/2250 loss 0.2623\n",
      "[epoch 026/040] step 1100/2250 loss 0.2849\n",
      "[epoch 026/040] step 1150/2250 loss 0.2870\n",
      "[epoch 026/040] step 1200/2250 loss 0.3331\n",
      "[epoch 026/040] step 1250/2250 loss 0.3073\n",
      "[epoch 026/040] step 1300/2250 loss 0.3049\n",
      "[epoch 026/040] step 1350/2250 loss 0.2793\n",
      "[epoch 026/040] step 1400/2250 loss 0.2692\n",
      "[epoch 026/040] step 1450/2250 loss 0.2814\n",
      "[epoch 026/040] step 1500/2250 loss 0.2601\n",
      "[epoch 026/040] step 1550/2250 loss 0.2234\n",
      "[epoch 026/040] step 1600/2250 loss 0.3535\n",
      "[epoch 026/040] step 1650/2250 loss 0.2923\n",
      "[epoch 026/040] step 1700/2250 loss 0.3135\n",
      "[epoch 026/040] step 1750/2250 loss 0.2965\n",
      "[epoch 026/040] step 1800/2250 loss 0.2665\n",
      "[epoch 026/040] step 1850/2250 loss 0.2916\n",
      "[epoch 026/040] step 1900/2250 loss 0.3730\n",
      "[epoch 026/040] step 1950/2250 loss 0.3112\n",
      "[epoch 026/040] step 2000/2250 loss 0.3253\n",
      "[epoch 026/040] step 2050/2250 loss 0.2886\n",
      "[epoch 026/040] step 2100/2250 loss 0.3844\n",
      "[epoch 026/040] step 2150/2250 loss 0.3215\n",
      "[epoch 026/040] step 2200/2250 loss 0.4108\n",
      "[epoch 026/040] step 2250/2250 loss 0.3260\n",
      "[epoch 026/040] train=0.3236  val=0.4201  lr=0.00139335\n",
      "[epoch 027/040] step 50/2250 loss 0.2553\n",
      "[epoch 027/040] step 100/2250 loss 0.2791\n",
      "[epoch 027/040] step 150/2250 loss 0.3602\n",
      "[epoch 027/040] step 200/2250 loss 0.2678\n",
      "[epoch 027/040] step 250/2250 loss 0.2472\n",
      "[epoch 027/040] step 300/2250 loss 0.2907\n",
      "[epoch 027/040] step 350/2250 loss 0.2892\n",
      "[epoch 027/040] step 400/2250 loss 0.3314\n",
      "[epoch 027/040] step 450/2250 loss 0.2779\n",
      "[epoch 027/040] step 500/2250 loss 0.3476\n",
      "[epoch 027/040] step 550/2250 loss 0.2475\n",
      "[epoch 027/040] step 600/2250 loss 0.4013\n",
      "[epoch 027/040] step 650/2250 loss 0.2740\n",
      "[epoch 027/040] step 700/2250 loss 0.2852\n",
      "[epoch 027/040] step 750/2250 loss 0.2899\n",
      "[epoch 027/040] step 800/2250 loss 0.2999\n",
      "[epoch 027/040] step 850/2250 loss 0.2417\n",
      "[epoch 027/040] step 900/2250 loss 0.2702\n",
      "[epoch 027/040] step 950/2250 loss 0.2851\n",
      "[epoch 027/040] step 1000/2250 loss 0.2810\n",
      "[epoch 027/040] step 1050/2250 loss 0.3221\n",
      "[epoch 027/040] step 1100/2250 loss 0.2753\n",
      "[epoch 027/040] step 1150/2250 loss 0.2920\n",
      "[epoch 027/040] step 1200/2250 loss 0.3519\n",
      "[epoch 027/040] step 1250/2250 loss 0.3178\n",
      "[epoch 027/040] step 1300/2250 loss 0.3237\n",
      "[epoch 027/040] step 1350/2250 loss 0.2428\n",
      "[epoch 027/040] step 1400/2250 loss 0.3030\n",
      "[epoch 027/040] step 1450/2250 loss 0.2857\n",
      "[epoch 027/040] step 1500/2250 loss 0.2732\n",
      "[epoch 027/040] step 1550/2250 loss 0.2767\n",
      "[epoch 027/040] step 1600/2250 loss 0.2525\n",
      "[epoch 027/040] step 1650/2250 loss 0.3097\n",
      "[epoch 027/040] step 1700/2250 loss 0.2982\n",
      "[epoch 027/040] step 1750/2250 loss 0.2868\n",
      "[epoch 027/040] step 1800/2250 loss 0.3749\n",
      "[epoch 027/040] step 1850/2250 loss 0.2631\n",
      "[epoch 027/040] step 1900/2250 loss 0.2800\n",
      "[epoch 027/040] step 1950/2250 loss 0.3325\n",
      "[epoch 027/040] step 2000/2250 loss 0.3245\n",
      "[epoch 027/040] step 2050/2250 loss 0.2876\n",
      "[epoch 027/040] step 2100/2250 loss 0.2731\n",
      "[epoch 027/040] step 2150/2250 loss 0.3293\n",
      "[epoch 027/040] step 2200/2250 loss 0.3423\n",
      "[epoch 027/040] step 2250/2250 loss 0.3299\n",
      "[epoch 027/040] train=0.3205  val=0.4147  lr=0.00121905\n",
      "[epoch 028/040] step 50/2250 loss 0.3029\n",
      "[epoch 028/040] step 100/2250 loss 0.2772\n",
      "[epoch 028/040] step 150/2250 loss 0.3003\n",
      "[epoch 028/040] step 200/2250 loss 0.4191\n",
      "[epoch 028/040] step 250/2250 loss 0.2656\n",
      "[epoch 028/040] step 300/2250 loss 0.2665\n",
      "[epoch 028/040] step 350/2250 loss 0.2901\n",
      "[epoch 028/040] step 400/2250 loss 0.2696\n",
      "[epoch 028/040] step 450/2250 loss 0.2989\n",
      "[epoch 028/040] step 500/2250 loss 0.3301\n",
      "[epoch 028/040] step 550/2250 loss 0.3016\n",
      "[epoch 028/040] step 600/2250 loss 0.2651\n",
      "[epoch 028/040] step 650/2250 loss 0.2644\n",
      "[epoch 028/040] step 700/2250 loss 0.4706\n",
      "[epoch 028/040] step 750/2250 loss 0.2936\n",
      "[epoch 028/040] step 800/2250 loss 0.2920\n",
      "[epoch 028/040] step 850/2250 loss 0.3205\n",
      "[epoch 028/040] step 900/2250 loss 0.2408\n",
      "[epoch 028/040] step 950/2250 loss 0.3046\n",
      "[epoch 028/040] step 1000/2250 loss 0.2551\n",
      "[epoch 028/040] step 1050/2250 loss 0.3259\n",
      "[epoch 028/040] step 1100/2250 loss 0.2528\n",
      "[epoch 028/040] step 1150/2250 loss 0.2857\n",
      "[epoch 028/040] step 1200/2250 loss 0.2739\n",
      "[epoch 028/040] step 1250/2250 loss 0.2767\n",
      "[epoch 028/040] step 1300/2250 loss 0.2815\n",
      "[epoch 028/040] step 1350/2250 loss 0.2610\n",
      "[epoch 028/040] step 1400/2250 loss 0.2677\n",
      "[epoch 028/040] step 1450/2250 loss 0.2543\n",
      "[epoch 028/040] step 1500/2250 loss 0.2970\n",
      "[epoch 028/040] step 1550/2250 loss 0.2543\n",
      "[epoch 028/040] step 1600/2250 loss 0.2635\n",
      "[epoch 028/040] step 1650/2250 loss 0.2299\n",
      "[epoch 028/040] step 1700/2250 loss 0.2857\n",
      "[epoch 028/040] step 1750/2250 loss 0.2877\n",
      "[epoch 028/040] step 1800/2250 loss 0.2923\n",
      "[epoch 028/040] step 1850/2250 loss 0.3395\n",
      "[epoch 028/040] step 1900/2250 loss 0.2518\n",
      "[epoch 028/040] step 1950/2250 loss 0.2606\n",
      "[epoch 028/040] step 2000/2250 loss 0.2556\n",
      "[epoch 028/040] step 2050/2250 loss 0.2835\n",
      "[epoch 028/040] step 2100/2250 loss 0.2756\n",
      "[epoch 028/040] step 2150/2250 loss 0.2414\n",
      "[epoch 028/040] step 2200/2250 loss 0.2998\n",
      "[epoch 028/040] step 2250/2250 loss 0.3085\n",
      "[epoch 028/040] train=0.3180  val=0.4175  lr=0.00105283\n",
      "[epoch 029/040] step 50/2250 loss 0.2909\n",
      "[epoch 029/040] step 100/2250 loss 0.2796\n",
      "[epoch 029/040] step 150/2250 loss 0.2399\n",
      "[epoch 029/040] step 200/2250 loss 0.2553\n",
      "[epoch 029/040] step 250/2250 loss 0.2596\n",
      "[epoch 029/040] step 300/2250 loss 0.2302\n",
      "[epoch 029/040] step 350/2250 loss 0.2905\n",
      "[epoch 029/040] step 400/2250 loss 0.3125\n",
      "[epoch 029/040] step 450/2250 loss 0.2377\n",
      "[epoch 029/040] step 500/2250 loss 0.3983\n",
      "[epoch 029/040] step 550/2250 loss 0.3278\n",
      "[epoch 029/040] step 600/2250 loss 0.2636\n",
      "[epoch 029/040] step 650/2250 loss 0.2953\n",
      "[epoch 029/040] step 700/2250 loss 0.2686\n",
      "[epoch 029/040] step 750/2250 loss 0.2748\n",
      "[epoch 029/040] step 800/2250 loss 0.2802\n",
      "[epoch 029/040] step 850/2250 loss 0.2790\n",
      "[epoch 029/040] step 900/2250 loss 0.2699\n",
      "[epoch 029/040] step 950/2250 loss 0.2680\n",
      "[epoch 029/040] step 1000/2250 loss 0.3453\n",
      "[epoch 029/040] step 1050/2250 loss 0.2437\n",
      "[epoch 029/040] step 1100/2250 loss 0.2560\n",
      "[epoch 029/040] step 1150/2250 loss 0.2722\n",
      "[epoch 029/040] step 1200/2250 loss 0.3356\n",
      "[epoch 029/040] step 1250/2250 loss 0.2433\n",
      "[epoch 029/040] step 1300/2250 loss 0.2830\n",
      "[epoch 029/040] step 1350/2250 loss 0.3074\n",
      "[epoch 029/040] step 1400/2250 loss 0.3316\n",
      "[epoch 029/040] step 1450/2250 loss 0.3108\n",
      "[epoch 029/040] step 1500/2250 loss 0.3105\n",
      "[epoch 029/040] step 1550/2250 loss 0.2590\n",
      "[epoch 029/040] step 1600/2250 loss 0.3357\n",
      "[epoch 029/040] step 1650/2250 loss 0.2765\n",
      "[epoch 029/040] step 1700/2250 loss 0.2515\n",
      "[epoch 029/040] step 1750/2250 loss 0.4073\n",
      "[epoch 029/040] step 1800/2250 loss 0.2885\n",
      "[epoch 029/040] step 1850/2250 loss 0.2526\n",
      "[epoch 029/040] step 1900/2250 loss 0.3801\n",
      "[epoch 029/040] step 1950/2250 loss 0.3078\n",
      "[epoch 029/040] step 2000/2250 loss 0.2828\n",
      "[epoch 029/040] step 2050/2250 loss 0.3551\n",
      "[epoch 029/040] step 2100/2250 loss 0.2925\n",
      "[epoch 029/040] step 2150/2250 loss 0.2342\n",
      "[epoch 029/040] step 2200/2250 loss 0.2964\n",
      "[epoch 029/040] step 2250/2250 loss 0.2932\n",
      "[epoch 029/040] train=0.3159  val=0.4171  lr=0.000895731\n",
      "[epoch 030/040] step 50/2250 loss 0.3687\n",
      "[epoch 030/040] step 100/2250 loss 0.2697\n",
      "[epoch 030/040] step 150/2250 loss 0.2425\n",
      "[epoch 030/040] step 200/2250 loss 0.2513\n",
      "[epoch 030/040] step 250/2250 loss 0.3678\n",
      "[epoch 030/040] step 300/2250 loss 0.3387\n",
      "[epoch 030/040] step 350/2250 loss 0.2783\n",
      "[epoch 030/040] step 400/2250 loss 0.3115\n",
      "[epoch 030/040] step 450/2250 loss 0.3676\n",
      "[epoch 030/040] step 500/2250 loss 0.2868\n",
      "[epoch 030/040] step 550/2250 loss 0.3556\n",
      "[epoch 030/040] step 600/2250 loss 0.2800\n",
      "[epoch 030/040] step 650/2250 loss 0.3305\n",
      "[epoch 030/040] step 700/2250 loss 0.2282\n",
      "[epoch 030/040] step 750/2250 loss 0.2892\n",
      "[epoch 030/040] step 800/2250 loss 0.2955\n",
      "[epoch 030/040] step 850/2250 loss 0.3045\n",
      "[epoch 030/040] step 900/2250 loss 0.2959\n",
      "[epoch 030/040] step 950/2250 loss 0.2478\n",
      "[epoch 030/040] step 1000/2250 loss 0.2736\n",
      "[epoch 030/040] step 1050/2250 loss 0.2587\n",
      "[epoch 030/040] step 1100/2250 loss 0.3073\n",
      "[epoch 030/040] step 1150/2250 loss 0.2867\n",
      "[epoch 030/040] step 1200/2250 loss 0.3002\n",
      "[epoch 030/040] step 1250/2250 loss 0.3106\n",
      "[epoch 030/040] step 1300/2250 loss 0.2805\n",
      "[epoch 030/040] step 1350/2250 loss 0.2567\n",
      "[epoch 030/040] step 1400/2250 loss 0.2774\n",
      "[epoch 030/040] step 1450/2250 loss 0.3336\n",
      "[epoch 030/040] step 1500/2250 loss 0.2885\n",
      "[epoch 030/040] step 1550/2250 loss 0.3250\n",
      "[epoch 030/040] step 1600/2250 loss 0.3027\n",
      "[epoch 030/040] step 1650/2250 loss 0.2765\n",
      "[epoch 030/040] step 1700/2250 loss 0.2656\n",
      "[epoch 030/040] step 1750/2250 loss 0.3295\n",
      "[epoch 030/040] step 1800/2250 loss 0.2774\n",
      "[epoch 030/040] step 1850/2250 loss 0.2718\n",
      "[epoch 030/040] step 1900/2250 loss 0.3634\n",
      "[epoch 030/040] step 1950/2250 loss 0.2634\n",
      "[epoch 030/040] step 2000/2250 loss 0.2440\n",
      "[epoch 030/040] step 2050/2250 loss 0.2321\n",
      "[epoch 030/040] step 2100/2250 loss 0.3258\n",
      "[epoch 030/040] step 2150/2250 loss 0.2599\n",
      "[epoch 030/040] step 2200/2250 loss 0.3142\n",
      "[epoch 030/040] step 2250/2250 loss 0.2254\n",
      "[epoch 030/040] train=0.3152  val=0.4182  lr=0.000748752\n",
      "[epoch 031/040] step 50/2250 loss 0.3061\n",
      "[epoch 031/040] step 100/2250 loss 0.2616\n",
      "[epoch 031/040] step 150/2250 loss 0.2791\n",
      "[epoch 031/040] step 200/2250 loss 0.4078\n",
      "[epoch 031/040] step 250/2250 loss 0.2711\n",
      "[epoch 031/040] step 300/2250 loss 0.3308\n",
      "[epoch 031/040] step 350/2250 loss 0.3186\n",
      "[epoch 031/040] step 400/2250 loss 0.3224\n",
      "[epoch 031/040] step 450/2250 loss 0.2525\n",
      "[epoch 031/040] step 500/2250 loss 0.2844\n",
      "[epoch 031/040] step 550/2250 loss 0.2758\n",
      "[epoch 031/040] step 600/2250 loss 0.3292\n",
      "[epoch 031/040] step 650/2250 loss 0.2540\n",
      "[epoch 031/040] step 700/2250 loss 0.2926\n",
      "[epoch 031/040] step 750/2250 loss 0.2635\n",
      "[epoch 031/040] step 800/2250 loss 0.2862\n",
      "[epoch 031/040] step 850/2250 loss 0.2255\n",
      "[epoch 031/040] step 900/2250 loss 0.3138\n",
      "[epoch 031/040] step 950/2250 loss 0.2620\n",
      "[epoch 031/040] step 1000/2250 loss 0.2973\n",
      "[epoch 031/040] step 1050/2250 loss 0.2792\n",
      "[epoch 031/040] step 1100/2250 loss 0.3048\n",
      "[epoch 031/040] step 1150/2250 loss 0.2766\n",
      "[epoch 031/040] step 1200/2250 loss 0.2726\n",
      "[epoch 031/040] step 1250/2250 loss 0.3011\n",
      "[epoch 031/040] step 1300/2250 loss 0.3196\n",
      "[epoch 031/040] step 1350/2250 loss 0.2819\n",
      "[epoch 031/040] step 1400/2250 loss 0.2775\n",
      "[epoch 031/040] step 1450/2250 loss 0.2320\n",
      "[epoch 031/040] step 1500/2250 loss 0.2861\n",
      "[epoch 031/040] step 1550/2250 loss 0.2238\n",
      "[epoch 031/040] step 1600/2250 loss 0.2202\n",
      "[epoch 031/040] step 1650/2250 loss 0.2578\n",
      "[epoch 031/040] step 1700/2250 loss 0.2582\n",
      "[epoch 031/040] step 1750/2250 loss 0.2539\n",
      "[epoch 031/040] step 1800/2250 loss 0.2600\n",
      "[epoch 031/040] step 1850/2250 loss 0.2466\n",
      "[epoch 031/040] step 1900/2250 loss 0.2237\n",
      "[epoch 031/040] step 1950/2250 loss 0.2354\n",
      "[epoch 031/040] step 2000/2250 loss 0.3403\n",
      "[epoch 031/040] step 2050/2250 loss 0.2624\n",
      "[epoch 031/040] step 2100/2250 loss 0.3261\n",
      "[epoch 031/040] step 2150/2250 loss 0.2366\n",
      "[epoch 031/040] step 2200/2250 loss 0.3637\n",
      "[epoch 031/040] step 2250/2250 loss 0.2865\n",
      "[epoch 031/040] train=0.3120  val=0.4169  lr=0.000612818\n",
      "[epoch 032/040] step 50/2250 loss 0.2127\n",
      "[epoch 032/040] step 100/2250 loss 0.3469\n",
      "[epoch 032/040] step 150/2250 loss 0.3003\n",
      "[epoch 032/040] step 200/2250 loss 0.2931\n",
      "[epoch 032/040] step 250/2250 loss 0.2510\n",
      "[epoch 032/040] step 300/2250 loss 0.2920\n",
      "[epoch 032/040] step 350/2250 loss 0.2854\n",
      "[epoch 032/040] step 400/2250 loss 0.2603\n",
      "[epoch 032/040] step 450/2250 loss 0.2765\n",
      "[epoch 032/040] step 500/2250 loss 0.3575\n",
      "[epoch 032/040] step 550/2250 loss 0.2529\n",
      "[epoch 032/040] step 600/2250 loss 0.2443\n",
      "[epoch 032/040] step 650/2250 loss 0.3641\n",
      "[epoch 032/040] step 700/2250 loss 0.2705\n",
      "[epoch 032/040] step 750/2250 loss 0.3003\n",
      "[epoch 032/040] step 800/2250 loss 0.2533\n",
      "[epoch 032/040] step 850/2250 loss 0.2489\n",
      "[epoch 032/040] step 900/2250 loss 0.2323\n",
      "[epoch 032/040] step 950/2250 loss 0.2375\n",
      "[epoch 032/040] step 1000/2250 loss 0.3651\n",
      "[epoch 032/040] step 1050/2250 loss 0.4158\n",
      "[epoch 032/040] step 1100/2250 loss 0.2817\n",
      "[epoch 032/040] step 1150/2250 loss 0.2919\n",
      "[epoch 032/040] step 1200/2250 loss 0.2355\n",
      "[epoch 032/040] step 1250/2250 loss 0.2529\n",
      "[epoch 032/040] step 1300/2250 loss 0.2689\n",
      "[epoch 032/040] step 1350/2250 loss 0.3229\n",
      "[epoch 032/040] step 1400/2250 loss 0.3583\n",
      "[epoch 032/040] step 1450/2250 loss 0.3089\n",
      "[epoch 032/040] step 1500/2250 loss 0.2785\n",
      "[epoch 032/040] step 1550/2250 loss 0.2565\n",
      "[epoch 032/040] step 1600/2250 loss 0.3186\n",
      "[epoch 032/040] step 1650/2250 loss 0.2993\n",
      "[epoch 032/040] step 1700/2250 loss 0.3407\n",
      "[epoch 032/040] step 1750/2250 loss 0.2673\n",
      "[epoch 032/040] step 1800/2250 loss 0.2431\n",
      "[epoch 032/040] step 1850/2250 loss 0.2744\n",
      "[epoch 032/040] step 1900/2250 loss 0.2767\n",
      "[epoch 032/040] step 1950/2250 loss 0.2839\n",
      "[epoch 032/040] step 2000/2250 loss 0.2837\n",
      "[epoch 032/040] step 2050/2250 loss 0.2930\n",
      "[epoch 032/040] step 2100/2250 loss 0.2624\n",
      "[epoch 032/040] step 2150/2250 loss 0.2287\n",
      "[epoch 032/040] step 2200/2250 loss 0.2646\n",
      "[epoch 032/040] step 2250/2250 loss 0.2691\n",
      "[epoch 032/040] train=0.3102  val=0.4219  lr=0.000488784\n",
      "[epoch 033/040] step 50/2250 loss 0.3355\n",
      "[epoch 033/040] step 100/2250 loss 0.3084\n",
      "[epoch 033/040] step 150/2250 loss 0.2348\n",
      "[epoch 033/040] step 200/2250 loss 0.3393\n",
      "[epoch 033/040] step 250/2250 loss 0.2420\n",
      "[epoch 033/040] step 300/2250 loss 0.2965\n",
      "[epoch 033/040] step 350/2250 loss 0.2954\n",
      "[epoch 033/040] step 400/2250 loss 0.3401\n",
      "[epoch 033/040] step 450/2250 loss 0.2866\n",
      "[epoch 033/040] step 500/2250 loss 0.3210\n",
      "[epoch 033/040] step 550/2250 loss 0.2780\n",
      "[epoch 033/040] step 600/2250 loss 0.3513\n",
      "[epoch 033/040] step 650/2250 loss 0.2418\n",
      "[epoch 033/040] step 700/2250 loss 0.2108\n",
      "[epoch 033/040] step 750/2250 loss 0.3260\n",
      "[epoch 033/040] step 800/2250 loss 0.2483\n",
      "[epoch 033/040] step 850/2250 loss 0.3400\n",
      "[epoch 033/040] step 900/2250 loss 0.2730\n",
      "[epoch 033/040] step 950/2250 loss 0.3069\n",
      "[epoch 033/040] step 1000/2250 loss 0.2465\n",
      "[epoch 033/040] step 1050/2250 loss 0.2882\n",
      "[epoch 033/040] step 1100/2250 loss 0.2855\n",
      "[epoch 033/040] step 1150/2250 loss 0.2571\n",
      "[epoch 033/040] step 1200/2250 loss 0.3106\n",
      "[epoch 033/040] step 1250/2250 loss 0.2591\n",
      "[epoch 033/040] step 1300/2250 loss 0.3021\n",
      "[epoch 033/040] step 1350/2250 loss 0.2287\n",
      "[epoch 033/040] step 1400/2250 loss 0.4026\n",
      "[epoch 033/040] step 1450/2250 loss 0.2853\n",
      "[epoch 033/040] step 1500/2250 loss 0.2698\n",
      "[epoch 033/040] step 1550/2250 loss 0.2790\n",
      "[epoch 033/040] step 1600/2250 loss 0.2237\n",
      "[epoch 033/040] step 1650/2250 loss 0.2673\n",
      "[epoch 033/040] step 1700/2250 loss 0.2417\n",
      "[epoch 033/040] step 1750/2250 loss 0.3366\n",
      "[epoch 033/040] step 1800/2250 loss 0.3046\n",
      "[epoch 033/040] step 1850/2250 loss 0.2581\n",
      "[epoch 033/040] step 1900/2250 loss 0.2939\n",
      "[epoch 033/040] step 1950/2250 loss 0.2588\n",
      "[epoch 033/040] step 2000/2250 loss 0.3119\n",
      "[epoch 033/040] step 2050/2250 loss 0.2670\n",
      "[epoch 033/040] step 2100/2250 loss 0.3128\n",
      "[epoch 033/040] step 2150/2250 loss 0.2457\n",
      "[epoch 033/040] step 2200/2250 loss 0.2506\n",
      "[epoch 033/040] step 2250/2250 loss 0.2566\n",
      "[epoch 033/040] train=0.3093  val=0.4185  lr=0.000377434\n",
      "[epoch 034/040] step 50/2250 loss 0.2960\n",
      "[epoch 034/040] step 100/2250 loss 0.2891\n",
      "[epoch 034/040] step 150/2250 loss 0.3156\n",
      "[epoch 034/040] step 200/2250 loss 0.2795\n",
      "[epoch 034/040] step 250/2250 loss 0.2488\n",
      "[epoch 034/040] step 300/2250 loss 0.2954\n",
      "[epoch 034/040] step 350/2250 loss 0.3041\n",
      "[epoch 034/040] step 400/2250 loss 0.4296\n",
      "[epoch 034/040] step 450/2250 loss 0.2894\n",
      "[epoch 034/040] step 500/2250 loss 0.2314\n",
      "[epoch 034/040] step 550/2250 loss 0.3046\n",
      "[epoch 034/040] step 600/2250 loss 0.2931\n",
      "[epoch 034/040] step 650/2250 loss 0.2570\n",
      "[epoch 034/040] step 700/2250 loss 0.2667\n",
      "[epoch 034/040] step 750/2250 loss 0.3002\n",
      "[epoch 034/040] step 800/2250 loss 0.3202\n",
      "[epoch 034/040] step 850/2250 loss 0.3139\n",
      "[epoch 034/040] step 900/2250 loss 0.2401\n",
      "[epoch 034/040] step 950/2250 loss 0.3088\n",
      "[epoch 034/040] step 1000/2250 loss 0.2456\n",
      "[epoch 034/040] step 1050/2250 loss 0.3248\n",
      "[epoch 034/040] step 1100/2250 loss 0.2837\n",
      "[epoch 034/040] step 1150/2250 loss 0.2576\n",
      "[epoch 034/040] step 1200/2250 loss 0.2680\n",
      "[epoch 034/040] step 1250/2250 loss 0.4259\n",
      "[epoch 034/040] step 1300/2250 loss 0.2370\n",
      "[epoch 034/040] step 1350/2250 loss 0.2403\n",
      "[epoch 034/040] step 1400/2250 loss 0.3191\n",
      "[epoch 034/040] step 1450/2250 loss 0.2443\n",
      "[epoch 034/040] step 1500/2250 loss 0.2896\n",
      "[epoch 034/040] step 1550/2250 loss 0.3003\n",
      "[epoch 034/040] step 1600/2250 loss 0.2956\n",
      "[epoch 034/040] step 1650/2250 loss 0.2761\n",
      "[epoch 034/040] step 1700/2250 loss 0.2449\n",
      "[epoch 034/040] step 1750/2250 loss 0.2350\n",
      "[epoch 034/040] step 1800/2250 loss 0.2551\n",
      "[epoch 034/040] step 1850/2250 loss 0.2754\n",
      "[epoch 034/040] step 1900/2250 loss 0.2953\n",
      "[epoch 034/040] step 1950/2250 loss 0.2895\n",
      "[epoch 034/040] step 2000/2250 loss 0.2770\n",
      "[epoch 034/040] step 2050/2250 loss 0.2375\n",
      "[epoch 034/040] step 2100/2250 loss 0.2598\n",
      "[epoch 034/040] step 2150/2250 loss 0.3086\n",
      "[epoch 034/040] step 2200/2250 loss 0.3279\n",
      "[epoch 034/040] step 2250/2250 loss 0.2790\n",
      "[epoch 034/040] train=0.3079  val=0.4193  lr=0.000279469\n",
      "[epoch 035/040] step 50/2250 loss 0.2723\n",
      "[epoch 035/040] step 100/2250 loss 0.2976\n",
      "[epoch 035/040] step 150/2250 loss 0.2753\n",
      "[epoch 035/040] step 200/2250 loss 0.2660\n",
      "[epoch 035/040] step 250/2250 loss 0.2955\n",
      "[epoch 035/040] step 300/2250 loss 0.2455\n",
      "[epoch 035/040] step 350/2250 loss 0.3197\n",
      "[epoch 035/040] step 400/2250 loss 0.2846\n",
      "[epoch 035/040] step 450/2250 loss 0.2518\n",
      "[epoch 035/040] step 500/2250 loss 0.2757\n",
      "[epoch 035/040] step 550/2250 loss 0.2794\n",
      "[epoch 035/040] step 600/2250 loss 0.2513\n",
      "[epoch 035/040] step 650/2250 loss 0.2903\n",
      "[epoch 035/040] step 700/2250 loss 0.3410\n",
      "[epoch 035/040] step 750/2250 loss 0.2560\n",
      "[epoch 035/040] step 800/2250 loss 0.2992\n",
      "[epoch 035/040] step 850/2250 loss 0.3159\n",
      "[epoch 035/040] step 900/2250 loss 0.3485\n",
      "[epoch 035/040] step 950/2250 loss 0.2684\n",
      "[epoch 035/040] step 1000/2250 loss 0.2978\n",
      "[epoch 035/040] step 1050/2250 loss 0.3550\n",
      "[epoch 035/040] step 1100/2250 loss 0.3175\n",
      "[epoch 035/040] step 1150/2250 loss 0.2921\n",
      "[epoch 035/040] step 1200/2250 loss 0.2191\n",
      "[epoch 035/040] step 1250/2250 loss 0.2179\n",
      "[epoch 035/040] step 1300/2250 loss 0.2962\n",
      "[epoch 035/040] step 1350/2250 loss 0.2716\n",
      "[epoch 035/040] step 1400/2250 loss 0.3577\n",
      "[epoch 035/040] step 1450/2250 loss 0.2833\n",
      "[epoch 035/040] step 1500/2250 loss 0.2500\n",
      "[epoch 035/040] step 1550/2250 loss 0.2559\n",
      "[epoch 035/040] step 1600/2250 loss 0.2738\n",
      "[epoch 035/040] step 1650/2250 loss 0.2615\n",
      "[epoch 035/040] step 1700/2250 loss 0.3276\n",
      "[epoch 035/040] step 1750/2250 loss 0.2659\n",
      "[epoch 035/040] step 1800/2250 loss 0.2927\n",
      "[epoch 035/040] step 1850/2250 loss 0.2658\n",
      "[epoch 035/040] step 1900/2250 loss 0.2973\n",
      "[epoch 035/040] step 1950/2250 loss 0.2586\n",
      "[epoch 035/040] step 2000/2250 loss 0.2382\n",
      "[epoch 035/040] step 2050/2250 loss 0.3414\n",
      "[epoch 035/040] step 2100/2250 loss 0.3751\n",
      "[epoch 035/040] step 2150/2250 loss 0.3009\n",
      "[epoch 035/040] step 2200/2250 loss 0.2567\n",
      "[epoch 035/040] step 2250/2250 loss 0.2474\n",
      "[epoch 035/040] train=0.3078  val=0.4161  lr=0.000195506\n",
      "[epoch 036/040] step 50/2250 loss 0.2277\n",
      "[epoch 036/040] step 100/2250 loss 0.2631\n",
      "[epoch 036/040] step 150/2250 loss 0.2876\n",
      "[epoch 036/040] step 200/2250 loss 0.3079\n",
      "[epoch 036/040] step 250/2250 loss 0.2392\n",
      "[epoch 036/040] step 300/2250 loss 0.2828\n",
      "[epoch 036/040] step 350/2250 loss 0.2588\n",
      "[epoch 036/040] step 400/2250 loss 0.2672\n",
      "[epoch 036/040] step 450/2250 loss 0.2172\n",
      "[epoch 036/040] step 500/2250 loss 0.2199\n",
      "[epoch 036/040] step 550/2250 loss 0.2456\n",
      "[epoch 036/040] step 600/2250 loss 0.2634\n",
      "[epoch 036/040] step 650/2250 loss 0.3238\n",
      "[epoch 036/040] step 700/2250 loss 0.2252\n",
      "[epoch 036/040] step 750/2250 loss 0.3164\n",
      "[epoch 036/040] step 800/2250 loss 0.3400\n",
      "[epoch 036/040] step 850/2250 loss 0.3188\n",
      "[epoch 036/040] step 900/2250 loss 0.3778\n",
      "[epoch 036/040] step 950/2250 loss 0.2739\n",
      "[epoch 036/040] step 1000/2250 loss 0.2384\n",
      "[epoch 036/040] step 1050/2250 loss 0.2599\n",
      "[epoch 036/040] step 1100/2250 loss 0.2812\n",
      "[epoch 036/040] step 1150/2250 loss 0.3088\n",
      "[epoch 036/040] step 1200/2250 loss 0.3338\n",
      "[epoch 036/040] step 1250/2250 loss 0.2951\n",
      "[epoch 036/040] step 1300/2250 loss 0.3031\n",
      "[epoch 036/040] step 1350/2250 loss 0.3318\n",
      "[epoch 036/040] step 1400/2250 loss 0.3274\n",
      "[epoch 036/040] step 1450/2250 loss 0.2737\n",
      "[epoch 036/040] step 1500/2250 loss 0.3048\n",
      "[epoch 036/040] step 1550/2250 loss 0.2518\n",
      "[epoch 036/040] step 1600/2250 loss 0.2903\n",
      "[epoch 036/040] step 1650/2250 loss 0.3113\n",
      "[epoch 036/040] step 1700/2250 loss 0.2650\n",
      "[epoch 036/040] step 1750/2250 loss 0.2403\n",
      "[epoch 036/040] step 1800/2250 loss 0.2877\n",
      "[epoch 036/040] step 1850/2250 loss 0.3315\n",
      "[epoch 036/040] step 1900/2250 loss 0.2674\n",
      "[epoch 036/040] step 1950/2250 loss 0.2563\n",
      "[epoch 036/040] step 2000/2250 loss 0.2237\n",
      "[epoch 036/040] step 2050/2250 loss 0.2558\n",
      "[epoch 036/040] step 2100/2250 loss 0.2593\n",
      "[epoch 036/040] step 2150/2250 loss 0.2663\n",
      "[epoch 036/040] step 2200/2250 loss 0.2555\n",
      "[epoch 036/040] step 2250/2250 loss 0.3196\n",
      "[epoch 036/040] train=0.3054  val=0.4170  lr=0.000126075\n",
      "[epoch 037/040] step 50/2250 loss 0.2776\n",
      "[epoch 037/040] step 100/2250 loss 0.2974\n",
      "[epoch 037/040] step 150/2250 loss 0.2858\n",
      "[epoch 037/040] step 200/2250 loss 0.3137\n",
      "[epoch 037/040] step 250/2250 loss 0.2199\n",
      "[epoch 037/040] step 300/2250 loss 0.2749\n",
      "[epoch 037/040] step 350/2250 loss 0.2818\n",
      "[epoch 037/040] step 400/2250 loss 0.2788\n",
      "[epoch 037/040] step 450/2250 loss 0.3397\n",
      "[epoch 037/040] step 500/2250 loss 0.2123\n",
      "[epoch 037/040] step 550/2250 loss 0.2615\n",
      "[epoch 037/040] step 600/2250 loss 0.2904\n",
      "[epoch 037/040] step 650/2250 loss 0.3408\n",
      "[epoch 037/040] step 700/2250 loss 0.4201\n",
      "[epoch 037/040] step 750/2250 loss 0.2577\n",
      "[epoch 037/040] step 800/2250 loss 0.2803\n",
      "[epoch 037/040] step 850/2250 loss 0.2579\n",
      "[epoch 037/040] step 900/2250 loss 0.2966\n",
      "[epoch 037/040] step 950/2250 loss 0.2673\n",
      "[epoch 037/040] step 1000/2250 loss 0.2756\n",
      "[epoch 037/040] step 1050/2250 loss 0.2298\n",
      "[epoch 037/040] step 1100/2250 loss 0.2356\n",
      "[epoch 037/040] step 1150/2250 loss 0.2743\n",
      "[epoch 037/040] step 1200/2250 loss 0.3063\n",
      "[epoch 037/040] step 1250/2250 loss 0.3026\n",
      "[epoch 037/040] step 1300/2250 loss 0.2099\n",
      "[epoch 037/040] step 1350/2250 loss 0.3138\n",
      "[epoch 037/040] step 1400/2250 loss 0.2635\n",
      "[epoch 037/040] step 1450/2250 loss 0.3219\n",
      "[epoch 037/040] step 1500/2250 loss 0.2551\n",
      "[epoch 037/040] step 1550/2250 loss 0.2837\n",
      "[epoch 037/040] step 1600/2250 loss 0.2500\n",
      "[epoch 037/040] step 1650/2250 loss 0.3093\n",
      "[epoch 037/040] step 1700/2250 loss 0.2725\n",
      "[epoch 037/040] step 1750/2250 loss 0.3005\n",
      "[epoch 037/040] step 1800/2250 loss 0.2699\n",
      "[epoch 037/040] step 1850/2250 loss 0.3085\n",
      "[epoch 037/040] step 1900/2250 loss 0.3398\n",
      "[epoch 037/040] step 1950/2250 loss 0.3074\n",
      "[epoch 037/040] step 2000/2250 loss 0.3357\n",
      "[epoch 037/040] step 2050/2250 loss 0.2557\n",
      "[epoch 037/040] step 2100/2250 loss 0.2815\n",
      "[epoch 037/040] step 2150/2250 loss 0.2762\n",
      "[epoch 037/040] step 2200/2250 loss 0.3023\n",
      "[epoch 037/040] step 2250/2250 loss 0.2536\n",
      "[epoch 037/040] train=0.3052  val=0.4172  lr=7.16147e-05\n",
      "[epoch 038/040] step 50/2250 loss 0.3609\n",
      "[epoch 038/040] step 100/2250 loss 0.2625\n",
      "[epoch 038/040] step 150/2250 loss 0.2409\n",
      "[epoch 038/040] step 200/2250 loss 0.2474\n",
      "[epoch 038/040] step 250/2250 loss 0.2906\n",
      "[epoch 038/040] step 300/2250 loss 0.2803\n",
      "[epoch 038/040] step 350/2250 loss 0.3005\n",
      "[epoch 038/040] step 400/2250 loss 0.3064\n",
      "[epoch 038/040] step 450/2250 loss 0.2463\n",
      "[epoch 038/040] step 500/2250 loss 0.3334\n",
      "[epoch 038/040] step 550/2250 loss 0.2638\n",
      "[epoch 038/040] step 600/2250 loss 0.2823\n",
      "[epoch 038/040] step 650/2250 loss 0.2920\n",
      "[epoch 038/040] step 700/2250 loss 0.2719\n",
      "[epoch 038/040] step 750/2250 loss 0.2597\n",
      "[epoch 038/040] step 800/2250 loss 0.2552\n",
      "[epoch 038/040] step 850/2250 loss 0.2493\n",
      "[epoch 038/040] step 900/2250 loss 0.3536\n",
      "[epoch 038/040] step 950/2250 loss 0.3517\n",
      "[epoch 038/040] step 1000/2250 loss 0.2498\n",
      "[epoch 038/040] step 1050/2250 loss 0.2576\n",
      "[epoch 038/040] step 1100/2250 loss 0.2819\n",
      "[epoch 038/040] step 1150/2250 loss 0.3209\n",
      "[epoch 038/040] step 1200/2250 loss 0.2479\n",
      "[epoch 038/040] step 1250/2250 loss 0.2572\n",
      "[epoch 038/040] step 1300/2250 loss 0.3256\n",
      "[epoch 038/040] step 1350/2250 loss 0.2651\n",
      "[epoch 038/040] step 1400/2250 loss 0.2745\n",
      "[epoch 038/040] step 1450/2250 loss 0.2808\n",
      "[epoch 038/040] step 1500/2250 loss 0.2417\n",
      "[epoch 038/040] step 1550/2250 loss 0.2914\n",
      "[epoch 038/040] step 1600/2250 loss 0.2145\n",
      "[epoch 038/040] step 1650/2250 loss 0.2630\n",
      "[epoch 038/040] step 1700/2250 loss 0.2764\n",
      "[epoch 038/040] step 1750/2250 loss 0.2258\n",
      "[epoch 038/040] step 1800/2250 loss 0.2581\n",
      "[epoch 038/040] step 1850/2250 loss 0.2643\n",
      "[epoch 038/040] step 1900/2250 loss 0.2514\n",
      "[epoch 038/040] step 1950/2250 loss 0.2793\n",
      "[epoch 038/040] step 2000/2250 loss 0.2704\n",
      "[epoch 038/040] step 2050/2250 loss 0.2393\n",
      "[epoch 038/040] step 2100/2250 loss 0.2413\n",
      "[epoch 038/040] step 2150/2250 loss 0.2507\n",
      "[epoch 038/040] step 2200/2250 loss 0.2242\n",
      "[epoch 038/040] step 2250/2250 loss 0.2488\n",
      "[epoch 038/040] train=0.3053  val=0.4195  lr=3.24669e-05\n",
      "[epoch 039/040] step 50/2250 loss 0.2530\n",
      "[epoch 039/040] step 100/2250 loss 0.2382\n",
      "[epoch 039/040] step 150/2250 loss 0.2263\n",
      "[epoch 039/040] step 200/2250 loss 0.2507\n",
      "[epoch 039/040] step 250/2250 loss 0.3425\n",
      "[epoch 039/040] step 300/2250 loss 0.2945\n",
      "[epoch 039/040] step 350/2250 loss 0.2448\n",
      "[epoch 039/040] step 400/2250 loss 0.2345\n",
      "[epoch 039/040] step 450/2250 loss 0.2899\n",
      "[epoch 039/040] step 500/2250 loss 0.2284\n",
      "[epoch 039/040] step 550/2250 loss 0.2460\n",
      "[epoch 039/040] step 600/2250 loss 0.3159\n",
      "[epoch 039/040] step 650/2250 loss 0.2958\n",
      "[epoch 039/040] step 700/2250 loss 0.2248\n",
      "[epoch 039/040] step 750/2250 loss 0.3498\n",
      "[epoch 039/040] step 800/2250 loss 0.3037\n",
      "[epoch 039/040] step 850/2250 loss 0.3591\n",
      "[epoch 039/040] step 900/2250 loss 0.2687\n",
      "[epoch 039/040] step 950/2250 loss 0.2541\n",
      "[epoch 039/040] step 1000/2250 loss 0.2514\n",
      "[epoch 039/040] step 1050/2250 loss 0.3134\n",
      "[epoch 039/040] step 1100/2250 loss 0.2628\n",
      "[epoch 039/040] step 1150/2250 loss 0.3147\n",
      "[epoch 039/040] step 1200/2250 loss 0.2762\n",
      "[epoch 039/040] step 1250/2250 loss 0.3336\n",
      "[epoch 039/040] step 1300/2250 loss 0.2752\n",
      "[epoch 039/040] step 1350/2250 loss 0.2650\n",
      "[epoch 039/040] step 1400/2250 loss 0.2918\n",
      "[epoch 039/040] step 1450/2250 loss 0.2831\n",
      "[epoch 039/040] step 1500/2250 loss 0.2327\n",
      "[epoch 039/040] step 1550/2250 loss 0.2848\n",
      "[epoch 039/040] step 1600/2250 loss 0.2937\n",
      "[epoch 039/040] step 1650/2250 loss 0.3266\n",
      "[epoch 039/040] step 1700/2250 loss 0.3494\n",
      "[epoch 039/040] step 1750/2250 loss 0.2563\n",
      "[epoch 039/040] step 1800/2250 loss 0.2967\n",
      "[epoch 039/040] step 1850/2250 loss 0.2604\n",
      "[epoch 039/040] step 1900/2250 loss 0.2333\n",
      "[epoch 039/040] step 1950/2250 loss 0.2924\n",
      "[epoch 039/040] step 2000/2250 loss 0.2859\n",
      "[epoch 039/040] step 2050/2250 loss 0.2570\n",
      "[epoch 039/040] step 2100/2250 loss 0.2729\n",
      "[epoch 039/040] step 2150/2250 loss 0.2946\n",
      "[epoch 039/040] step 2200/2250 loss 0.3289\n",
      "[epoch 039/040] step 2250/2250 loss 0.2276\n",
      "[epoch 039/040] train=0.3045  val=0.4197  lr=8.87915e-06\n",
      "[epoch 040/040] step 50/2250 loss 0.3090\n",
      "[epoch 040/040] step 100/2250 loss 0.2779\n",
      "[epoch 040/040] step 150/2250 loss 0.2944\n",
      "[epoch 040/040] step 200/2250 loss 0.3173\n",
      "[epoch 040/040] step 250/2250 loss 0.3296\n",
      "[epoch 040/040] step 300/2250 loss 0.2632\n",
      "[epoch 040/040] step 350/2250 loss 0.2531\n",
      "[epoch 040/040] step 400/2250 loss 0.2261\n",
      "[epoch 040/040] step 450/2250 loss 0.2745\n",
      "[epoch 040/040] step 500/2250 loss 0.2396\n",
      "[epoch 040/040] step 550/2250 loss 0.2623\n",
      "[epoch 040/040] step 600/2250 loss 0.2654\n",
      "[epoch 040/040] step 650/2250 loss 0.2649\n",
      "[epoch 040/040] step 700/2250 loss 0.2807\n",
      "[epoch 040/040] step 750/2250 loss 0.2426\n",
      "[epoch 040/040] step 800/2250 loss 0.3585\n",
      "[epoch 040/040] step 850/2250 loss 0.2827\n",
      "[epoch 040/040] step 900/2250 loss 0.2536\n",
      "[epoch 040/040] step 950/2250 loss 0.3128\n",
      "[epoch 040/040] step 1000/2250 loss 0.2070\n",
      "[epoch 040/040] step 1050/2250 loss 0.3246\n",
      "[epoch 040/040] step 1100/2250 loss 0.2691\n",
      "[epoch 040/040] step 1150/2250 loss 0.2936\n",
      "[epoch 040/040] step 1200/2250 loss 0.2238\n",
      "[epoch 040/040] step 1250/2250 loss 0.2994\n",
      "[epoch 040/040] step 1300/2250 loss 0.2478\n",
      "[epoch 040/040] step 1350/2250 loss 0.2801\n",
      "[epoch 040/040] step 1400/2250 loss 0.3147\n",
      "[epoch 040/040] step 1450/2250 loss 0.2970\n",
      "[epoch 040/040] step 1500/2250 loss 0.2580\n",
      "[epoch 040/040] step 1550/2250 loss 0.3092\n",
      "[epoch 040/040] step 1600/2250 loss 0.3278\n",
      "[epoch 040/040] step 1650/2250 loss 0.2390\n",
      "[epoch 040/040] step 1700/2250 loss 0.2646\n",
      "[epoch 040/040] step 1750/2250 loss 0.2998\n",
      "[epoch 040/040] step 1800/2250 loss 0.2286\n",
      "[epoch 040/040] step 1850/2250 loss 0.2189\n",
      "[epoch 040/040] step 1900/2250 loss 0.2693\n",
      "[epoch 040/040] step 1950/2250 loss 0.3006\n",
      "[epoch 040/040] step 2000/2250 loss 0.3724\n",
      "[epoch 040/040] step 2050/2250 loss 0.2095\n",
      "[epoch 040/040] step 2100/2250 loss 0.3521\n",
      "[epoch 040/040] step 2150/2250 loss 0.2935\n",
      "[epoch 040/040] step 2200/2250 loss 0.2706\n",
      "[epoch 040/040] step 2250/2250 loss 0.3738\n",
      "[epoch 040/040] train=0.3048  val=0.4154  lr=1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/19 15:47:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hist_ft = trainer.run(mix_train, mix_val, experiment_name=\"Att_FT2_Train9\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98216c0-e163-42d0-b008-f8c66ada5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), \"../weights/maskrcnn_attfpn_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276566d-26a3-4892-a51d-da0c794bbea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
