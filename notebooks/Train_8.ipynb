{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71cdd8a-fc30-46d2-803c-b7ee6eb49cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991aa36b-ed88-41b8-885c-808b77f4962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///media/sdb1/mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424d6e82-8c48-4970-8a97-703b6385b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from models.models import build_model     \n",
    "from datasets.loader import DataModule, DataConfig  \n",
    "from train.trainer import Trainer, TrainConfig  \n",
    "from train.eval import Evaluator             \n",
    "from datasets.base import collate_bb\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = 1 + 24\n",
    "model_uri = \"file:///media/sdb1/mlflow/753485487056022103/2e19afb3d8e34c7fa8b50505a7dd259e/artifacts/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "\n",
    "def allow_missing_masks(model):\n",
    "    orig_forward = model.forward\n",
    "    def forward(images, targets=None):\n",
    "        if model.training and targets is not None and not all((\"masks\" in t) for t in targets):\n",
    "            rh = model.roi_heads\n",
    "            saved = (rh.mask_roi_pool, rh.mask_head, rh.mask_predictor)\n",
    "            try:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = None, None, None\n",
    "                return orig_forward(images, targets)\n",
    "            finally:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = saved\n",
    "        return orig_forward(images, targets)\n",
    "    model.forward = forward\n",
    "    return model\n",
    "model = allow_missing_masks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5203de-16bc-4bd5-8917-4f69b533ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/2250 loss 0.5184\n",
      "[epoch 001/010] step 100/2250 loss 0.4444\n",
      "[epoch 001/010] step 150/2250 loss 0.7280\n",
      "[epoch 001/010] step 200/2250 loss 0.4851\n",
      "[epoch 001/010] step 250/2250 loss 0.5214\n",
      "[epoch 001/010] step 300/2250 loss 0.4425\n",
      "[epoch 001/010] step 350/2250 loss 0.5715\n",
      "[epoch 001/010] step 400/2250 loss 0.4132\n",
      "[epoch 001/010] step 450/2250 loss 0.4593\n",
      "[epoch 001/010] step 500/2250 loss 0.4837\n",
      "[epoch 001/010] step 550/2250 loss 0.4271\n",
      "[epoch 001/010] step 600/2250 loss 0.4830\n",
      "[epoch 001/010] step 650/2250 loss 0.4529\n",
      "[epoch 001/010] step 700/2250 loss 0.4823\n",
      "[epoch 001/010] step 750/2250 loss 0.5911\n",
      "[epoch 001/010] step 800/2250 loss 0.4443\n",
      "[epoch 001/010] step 850/2250 loss 0.4036\n",
      "[epoch 001/010] step 900/2250 loss 0.5260\n",
      "[epoch 001/010] step 950/2250 loss 0.4160\n",
      "[epoch 001/010] step 1000/2250 loss 0.4628\n",
      "[epoch 001/010] step 1050/2250 loss 0.4035\n",
      "[epoch 001/010] step 1100/2250 loss 0.4547\n",
      "[epoch 001/010] step 1150/2250 loss 0.4061\n",
      "[epoch 001/010] step 1200/2250 loss 0.4715\n",
      "[epoch 001/010] step 1250/2250 loss 0.4913\n"
     ]
    }
   ],
   "source": [
    "conf = TrainConfig() \n",
    "conf.num_epochs = 10\n",
    "conf.batch_size = 4\n",
    "conf.num_workers = 4\n",
    "conf.lr = 5e-4\n",
    "conf.weight_decay = 1e-4\n",
    "conf.momentum = 0.9\n",
    "\n",
    "def infinite(loader): # re-iterate a DataLoader foreve\n",
    "    while True: \n",
    "        for batch in loader:\n",
    "            yield batch \n",
    "\n",
    "class AlternatingLoader:                      # alternates between two loaders\n",
    "    def __init__(self, loader_a, loader_b, steps=None, start=\"a\"): \n",
    "        self.a = loader_a                      # dataset A (box-only)\n",
    "        self.b = loader_b                      # dataset B (box+mask)\n",
    "        self.steps = steps if steps is not None else 2 * max(len(loader_a), len(loader_b))\n",
    "        self.start = start\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps \n",
    "\n",
    "    def __iter__(self):\n",
    "        ia, ib = infinite(self.a), infinite(self.b)\n",
    "        for i in range(self.steps): \n",
    "            if (i % 2 == 0) == (self.start == \"a\"):  # even steps from a, odd steps from b\n",
    "                yield next(ia) \n",
    "            else:                              \n",
    "                yield next(ib) \n",
    "\n",
    "dm = DataModule(\n",
    "    DataConfig(\n",
    "        val_frac=0.1,                          #val split in A\n",
    "        batch_size=conf.batch_size, \n",
    "        num_workers=conf.num_workers\n",
    "    ),\n",
    "    with_masks=False #this disables fake masks for DatasetA; DatasetB still has real masks\n",
    ")\n",
    "\n",
    "b_train_loader, b_val_loader = dm.make_loaders_b() \n",
    "a_train_loader = DataLoader(dm.ds_a_train,batch_size=conf.batch_size,shuffle=True, num_workers=conf.num_workers,collate_fn=collate_bb )\n",
    "a_val_loader = DataLoader(dm.ds_a_val,batch_size=conf.batch_size,shuffle=False,num_workers=conf.num_workers,collate_fn=collate_bb)\n",
    "model = allow_missing_masks(model) # disables mask branch only for those A steps\n",
    "\n",
    "# A batch (no masks) -> mask head disabled for that step by allow_missing_masks()\n",
    "# B batch (has masks) -> mask head enabled and trained on that step\n",
    "mix_train = AlternatingLoader(a_train_loader,b_train_loader) \n",
    "mix_val = AlternatingLoader(a_val_loader, b_val_loader)\n",
    "trainer = Trainer(model, conf) \n",
    "hist_ft = trainer.run(mix_train,mix_val,  experiment_name=\"Att_FT2_Train6\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f974f7-7f87-476b-aebb-9673010e8a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98216c0-e163-42d0-b008-f8c66ada5810",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./weights/maskrcnn_attfpn_warmB_ft_Bmasks_Aboxes.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), \"./weights/maskrcnn_attfpn_warmB_ft_Bmasks_Aboxes.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
