{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424d6e82-8c48-4970-8a97-703b6385b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1 + 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f410a5-3715-4000-b3dc-b1726f2e754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/neoph/dev/Train/.tenv312/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from models.models import build_model     \n",
    "from datasets.loader import DataModule, DataConfig  \n",
    "from train.trainer import Trainer, TrainConfig  \n",
    "from train.eval import Evaluator             \n",
    "from datasets.base import collate_bb\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = 25\n",
    "B_CKPT = \"./weights/maskrcnn_B_ep40.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f974f7-7f87-476b-aebb-9673010e8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_EPOCHS = 3\n",
    "FINETUNE_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "LR_WARMUP = 1e-4\n",
    "LR_FINETUNE = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "FREEZE_MASK_HEAD_IN_FINETUNE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a576b-a6eb-4928-8a85-e37ddf6f3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\"maskrcnn_attfpn\", NUM_CLASSES).to(DEVICE)\n",
    "sd = torch.load(B_CKPT, map_location=\"cpu\")\n",
    "model.load_state_dict(sd, strict=False)\n",
    "\n",
    "\n",
    "def allow_missing_masks(model):\n",
    "    orig_forward = model.forward\n",
    "    def forward(images, targets=None):\n",
    "        if model.training and targets is not None and not all((\"masks\" in t) for t in targets):\n",
    "            rh = model.roi_heads\n",
    "            saved = (rh.mask_roi_pool, rh.mask_head, rh.mask_predictor)\n",
    "            try:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = None, None, None\n",
    "                return orig_forward(images, targets)\n",
    "            finally:\n",
    "                rh.mask_roi_pool, rh.mask_head, rh.mask_predictor = saved\n",
    "        return orig_forward(images, targets)\n",
    "    model.forward = forward\n",
    "    return model\n",
    "allow_missing_masks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c13918-00f5-4827-a234-e1c28d62a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def req(mod, flag: bool):\n",
    "    for p in mod.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba0195c-c650-49de-99d1-c6247e64c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(DataConfig(val_frac=0.1, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS), with_masks = False)\n",
    "b_train_loader, b_val_loader = dm.make_loaders_b()\n",
    "a_train_box = dm.ds_a_train\n",
    "a_val_box   = dm.ds_a_val\n",
    "ab_train_ds = ConcatDataset([a_train_box, dm.ds_b_train])\n",
    "ab_val_ds   = ConcatDataset([a_val_box, dm.ds_b_val])\n",
    "\n",
    "ab_train_loader = DataLoader(ab_train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_bb)\n",
    "ab_val_loader = DataLoader(ab_val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_bb)\n",
    "\n",
    "b_test_loader = dm.make_loader_b_test()\n",
    "c_test_loader = dm.make_loader_c_test()\n",
    "d_test_loader = dm.make_loader_d_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add42581-528d-4a18-8a54-72432811d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///media/sdb1/mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99be1fa9-d030-4b34-b507-f235dddbc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "req(model, False)\n",
    "req(model.backbone.ca, True)\n",
    "req(model.backbone.sa, True)\n",
    "\n",
    "conf = TrainConfig()\n",
    "conf.num_epochs = WARMUP_EPOCHS\n",
    "conf.batch_size = BATCH_SIZE\n",
    "conf.num_workers = NUM_WORKERS\n",
    "conf.lr = LR_WARMUP\n",
    "conf.weight_decay = WEIGHT_DECAY\n",
    "conf.momentum = MOMENTUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f7baba-f9bc-4eb0-a762-ad7b20ad4f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/003] step 50/119 loss 1.0387\n",
      "[epoch 001/003] step 100/119 loss 0.9133\n",
      "[epoch 001/003] step 119/119 loss 1.1002\n",
      "epoch 001/003  train=1.1486  val=1.1030\n",
      "[epoch 002/003] step 50/119 loss 1.0594\n",
      "[epoch 002/003] step 100/119 loss 0.9256\n",
      "[epoch 002/003] step 119/119 loss 1.0038\n",
      "epoch 002/003  train=0.9435  val=1.0371\n",
      "[epoch 003/003] step 50/119 loss 0.8514\n",
      "[epoch 003/003] step 100/119 loss 0.9803\n",
      "[epoch 003/003] step 119/119 loss 0.9091\n",
      "epoch 003/003  train=0.8965  val=1.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/12 13:03:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, conf)\n",
    "hist_warm = trainer.run(b_train_loader, b_val_loader, experiment_name=\"Att_Train6\")\n",
    "\n",
    "req(model, True)\n",
    "if FREEZE_MASK_HEAD_IN_FINETUNE:\n",
    "    req(model.roi_heads.mask_head, False)\n",
    "    req(model.roi_heads.mask_predictor, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23f7165-2c15-439a-808e-edd452d03e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabd2ab-58f3-4392-a5b4-ba6af69d749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001/010] step 50/1244 loss 1.0411\n",
      "[epoch 001/010] step 100/1244 loss 1.1805\n"
     ]
    }
   ],
   "source": [
    "conf = TrainConfig()\n",
    "conf.num_epochs = FINETUNE_EPOCHS\n",
    "conf.batch_size = BATCH_SIZE\n",
    "conf.num_workers = NUM_WORKERS\n",
    "conf.lr = LR_FINETUNE\n",
    "conf.weight_decay = WEIGHT_DECAY\n",
    "conf.momentum = MOMENTUM\n",
    "\n",
    "trainer = Trainer(model, conf)\n",
    "hist_ft = trainer.run(ab_train_loader, ab_val_loader, experiment_name=\"Att_FT2_Train6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76dc085-5f9c-4bfd-a5e7-b7333cddf95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "ev = Evaluator(DEVICE)\n",
    "\n",
    "print(\"B test map50:\", ev.map50(model, b_test_loader))\n",
    "print(\"B test mask metrics:\", ev.metrics_masks(model, b_test_loader, num_classes=NUM_CLASSES))\n",
    "print(\"C sanity:\", ev.sanity(model, c_test_loader))\n",
    "print(\"D sanity:\", ev.sanity(model, d_test_loader))\n",
    "\n",
    "ev.show_examples(dm.ds_b_test, model, n=3, score_thresh=0.5, title=\"B test\", show_random=True)\n",
    "\n",
    "# %% [9] save\n",
    "torch.save(model.state_dict(), \"./weights/maskrcnn_attfpn_warmB_ft_Bmasks_Aboxes.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad9cdeb-b6c1-42f7-bf31-86a0559cb76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3961781/3934626380.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(B_CKPT, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone.ca.mlp.0.weight', 'backbone.ca.mlp.0.bias', 'backbone.ca.mlp.2.weight', 'backbone.ca.mlp.2.bias', 'backbone.sa.conv.weight', 'backbone.sa.conv.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_CKPT = \"./weights/maskrcnn_B_ep40.pth\"  \n",
    "model = build_model(\"maskrcnn_attfpn\", NUM_CLASSES).to(DEVICE)\n",
    "sd = torch.load(B_CKPT, map_location=\"cpu\") \n",
    "model.load_state_dict(sd, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cea5ad-49b7-4e7e-9e59-bd62c6721562",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conf = DataConfig()\n",
    "data = DataModule(data_conf)\n",
    "train_conf = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de97b2-d23b-4c49-aa4c-d32d20ee3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    imgs, targs = zip(*batch)\n",
    "    return list(imgs), list(targs)\n",
    "\n",
    "class BoxOnly(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        img, t = self.ds[i]\n",
    "        t = dict(t)\n",
    "        t.pop(\"masks\", None)\n",
    "        return img, t\n",
    "\n",
    "def set_requires_grad(module, flag: bool):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def train_one_epoch(model, loader, optim):\n",
    "    model.train()\n",
    "    s = 0.0\n",
    "    n = 0\n",
    "    for imgs, targs in loader:\n",
    "        imgs = [x.to(DEVICE) for x in imgs]\n",
    "        targs = [{k: v.to(DEVICE) for k, v in t.items()} for t in targs]\n",
    "\n",
    "        loss_dict = model(imgs, targs)\n",
    "        loss = sum(loss_dict.values())\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        s += float(loss.item())\n",
    "        n += 1\n",
    "    return s / max(n, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    s = 0.0\n",
    "    n = 0\n",
    "    for imgs, targs in loader:\n",
    "        imgs = [x.to(DEVICE) for x in imgs]\n",
    "        targs = [{k: v.to(DEVICE) for k, v in t.items()} for t in targs]\n",
    "        loss_dict = model(imgs, targs)\n",
    "        loss = sum(loss_dict.values())\n",
    "        s += float(loss.item())\n",
    "        n += 1\n",
    "    return s / max(n, 1)\n",
    "\n",
    "# %% [4] datasets\n",
    "ds_b_train = DatasetB(B_ROOT, \"train\", LABEL_MAP, MAX_SIZE, NUM_CHANNELS)\n",
    "ds_b_val   = DatasetB(B_ROOT, \"test\",  LABEL_MAP, MAX_SIZE, NUM_CHANNELS)\n",
    "\n",
    "ds_a_train = DatasetA(A_XML, A_IMG, LABEL_MAP, MAX_SIZE, NUM_CHANNELS)\n",
    "ds_a_box   = BoxOnly(ds_a_train)\n",
    "\n",
    "dl_b_train = DataLoader(ds_b_train, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "dl_b_val   = DataLoader(ds_b_val, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "\n",
    "ds_mix = ConcatDataset([ds_b_train, ds_a_box])\n",
    "dl_mix = DataLoader(ds_mix, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "\n",
    "# %% [5] model: attention + load B checkpoint\n",
    "\n",
    "\n",
    "# %% [6] warmup: B-only, train attention blocks (optional but fast)\n",
    "set_requires_grad(model, False)\n",
    "set_requires_grad(model.backbone.ca, True)\n",
    "set_requires_grad(model.backbone.sa, True)\n",
    "\n",
    "opt = torch.optim.SGD(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr=LR_WARMUP, momentum=0.9, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "for e in range(WARMUP_EPOCHS):\n",
    "    tr = train_one_epoch(model, dl_b_train, opt)\n",
    "    va = eval_one_epoch(model, dl_b_val)\n",
    "    print(\"warmup\", e, tr, va)\n",
    "\n",
    "# %% [7] finetune: B(masks) + A(boxes), masks dropped for A\n",
    "set_requires_grad(model, True)\n",
    "\n",
    "if FREEZE_MASK_HEAD_IN_FINETUNE:\n",
    "    set_requires_grad(model.roi_heads.mask_head, False)\n",
    "    set_requires_grad(model.roi_heads.mask_predictor, False)\n",
    "\n",
    "opt = torch.optim.SGD(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr=LR_FINETUNE, momentum=0.9, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "for e in range(FINETUNE_EPOCHS):\n",
    "    tr = train_one_epoch(model, dl_mix, opt)\n",
    "    va = eval_one_epoch(model, dl_b_val)\n",
    "    print(\"finetune\", e, tr, va)\n",
    "\n",
    "# %% [8] save\n",
    "torch.save(model.state_dict(), \"maskrcnn_attfpn_Bwarmup_Aboxes_finetune.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
